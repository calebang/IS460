{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"6\" > 1. Exploratory Data Analysis (EDA) </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Days_left is a categorical!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"5\" > Import Data and Packages </font>\n",
    "<li> Removing index column</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uqjIUng-QB5U"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline   flight source_city departure_time stops   arrival_time  \\\n",
       "0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
       "1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
       "2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
       "3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
       "4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
       "\n",
       "  destination_city    class  duration  days_left  price  \n",
       "0           Mumbai  Economy      2.17          1   5953  \n",
       "1           Mumbai  Economy      2.33          1   5953  \n",
       "2           Mumbai  Economy      2.17          1   5956  \n",
       "3           Mumbai  Economy      2.25          1   5955  \n",
       "4           Mumbai  Economy      2.33          1   5955  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/Clean_Dataset.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"5\" > Summary Statistics </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "sGIn2st9QivC",
    "outputId": "8922f3f6-f34a-4174-85c6-7df2353e711a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153.000000</td>\n",
       "      <td>300153.000000</td>\n",
       "      <td>300153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>1561</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-706</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>127859</td>\n",
       "      <td>3235</td>\n",
       "      <td>61343</td>\n",
       "      <td>71146</td>\n",
       "      <td>250863</td>\n",
       "      <td>91538</td>\n",
       "      <td>59097</td>\n",
       "      <td>206666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.221021</td>\n",
       "      <td>26.004751</td>\n",
       "      <td>20889.660523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.191997</td>\n",
       "      <td>13.561004</td>\n",
       "      <td>22697.767366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.830000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>42521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.830000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>123071.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airline  flight source_city departure_time   stops arrival_time  \\\n",
       "count    300153  300153      300153         300153  300153       300153   \n",
       "unique        6    1561           6              6       3            6   \n",
       "top     Vistara  UK-706       Delhi        Morning     one        Night   \n",
       "freq     127859    3235       61343          71146  250863        91538   \n",
       "mean        NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "std         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "min         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "25%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "50%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "75%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "max         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "\n",
       "       destination_city    class       duration      days_left          price  \n",
       "count            300153   300153  300153.000000  300153.000000  300153.000000  \n",
       "unique                6        2            NaN            NaN            NaN  \n",
       "top              Mumbai  Economy            NaN            NaN            NaN  \n",
       "freq              59097   206666            NaN            NaN            NaN  \n",
       "mean                NaN      NaN      12.221021      26.004751   20889.660523  \n",
       "std                 NaN      NaN       7.191997      13.561004   22697.767366  \n",
       "min                 NaN      NaN       0.830000       1.000000    1105.000000  \n",
       "25%                 NaN      NaN       6.830000      15.000000    4783.000000  \n",
       "50%                 NaN      NaN      11.250000      26.000000    7425.000000  \n",
       "75%                 NaN      NaN      16.170000      38.000000   42521.000000  \n",
       "max                 NaN      NaN      49.830000      49.000000  123071.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w52Y43r5SjXL",
    "outputId": "5d87fcfd-5590-4992-93ff-a3105b37c1ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline             0\n",
       "flight              0\n",
       "source_city         0\n",
       "departure_time      0\n",
       "stops               0\n",
       "arrival_time        0\n",
       "destination_city    0\n",
       "class               0\n",
       "duration            0\n",
       "days_left           0\n",
       "price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T3-yfEYFqEL0"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "0IbJ-cfSSIKP",
    "outputId": "b5599c92-1fb5-438b-989a-7d392d47c8cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153</td>\n",
       "      <td>300153.000000</td>\n",
       "      <td>300153.000000</td>\n",
       "      <td>300153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>1561</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-706</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>127859</td>\n",
       "      <td>3235</td>\n",
       "      <td>61343</td>\n",
       "      <td>71146</td>\n",
       "      <td>250863</td>\n",
       "      <td>91538</td>\n",
       "      <td>59097</td>\n",
       "      <td>206666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.221021</td>\n",
       "      <td>26.004751</td>\n",
       "      <td>20889.660523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.191997</td>\n",
       "      <td>13.561004</td>\n",
       "      <td>22697.767366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.830000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>42521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.670000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>57920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.830000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>123071.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airline  flight source_city departure_time   stops arrival_time  \\\n",
       "count    300153  300153      300153         300153  300153       300153   \n",
       "unique        6    1561           6              6       3            6   \n",
       "top     Vistara  UK-706       Delhi        Morning     one        Night   \n",
       "freq     127859    3235       61343          71146  250863        91538   \n",
       "mean        NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "std         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "min         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "10%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "25%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "50%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "75%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "90%         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "max         NaN     NaN         NaN            NaN     NaN          NaN   \n",
       "\n",
       "       destination_city    class       duration      days_left          price  \n",
       "count            300153   300153  300153.000000  300153.000000  300153.000000  \n",
       "unique                6        2            NaN            NaN            NaN  \n",
       "top              Mumbai  Economy            NaN            NaN            NaN  \n",
       "freq              59097   206666            NaN            NaN            NaN  \n",
       "mean                NaN      NaN      12.221021      26.004751   20889.660523  \n",
       "std                 NaN      NaN       7.191997      13.561004   22697.767366  \n",
       "min                 NaN      NaN       0.830000       1.000000    1105.000000  \n",
       "10%                 NaN      NaN       2.750000       7.000000    3389.000000  \n",
       "25%                 NaN      NaN       6.830000      15.000000    4783.000000  \n",
       "50%                 NaN      NaN      11.250000      26.000000    7425.000000  \n",
       "75%                 NaN      NaN      16.170000      38.000000   42521.000000  \n",
       "90%                 NaN      NaN      23.670000      45.000000   57920.000000  \n",
       "max                 NaN      NaN      49.830000      49.000000  123071.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9], include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"6\" > 2. Data visualization </font>\n",
    "<li>Checking whethere there are any outliers</li>\n",
    "<li>Getting the distribution of numerical data </li>\n",
    "<li> Checking if there is a relationship between variables </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "-28PQzuwTEGU",
    "outputId": "34217150-a8c1-4002-f96f-cacee7b4bffa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh10lEQVR4nO3df1BVdR7/8dcV4srPu0l6LwQqIbUV6Kb2JSkTK2hs25WhJss2c/qx7lJuaIqZW0tuC7uSQrOMzeg2pdvYLzPbsdZgppVsKL+kOatuW2qYuEIka4CI3ID7/cMvd7tB6pV7P5cLz8fMnZVzPpz7tpmNZx/OvdficrlcAgAAMGRYoAcAAABDC/EBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo0IDPcD3dXd36+jRo4qOjpbFYgn0OAAA4By4XC61trYqPj5ew4adeW9jwMXH0aNHlZiYGOgxAADAeairq1NCQsIZ1wy4+IiOjpZ0eviYmJgATwMAAM5FS0uLEhMT3T/Hz2TAxUfPr1piYmKIDwAAgsy53DLBDacAAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGeRUfhYWFslgsHg+Hw+E+73K5VFhYqPj4eIWHhyszM1P79u3z+dAAgo/T6VRZWZnmz5+vsrIyOZ3OQI8EIEC83vm48sorVV9f737s2bPHfW7FihVatWqVysvLVVNTI4fDoaysLLW2tvp0aADBpaCgQJGRkVqwYIHKy8u1YMECRUZGqqCgINCjAQgAr+MjNDRUDofD/Rg5cqSk07seZWVlWrZsmXJzc5Wamqp169bp5MmT2rBhg88HBxAcCgoKVFJSotjYWK1du1b19fVau3atYmNjVVJSQoAAQ5DX8bF//37Fx8crKSlJd955p7744gtJUm1trRoaGpSdne1ea7VaNW3aNFVXV//g9To6OtTS0uLxADA4OJ1OlZaWym6368iRI3rggQfkcDj0wAMP6MiRI7Lb7SotLeVXMMAQ41V8pKena/369Xr33Xe1du1aNTQ0KCMjQ01NTWpoaJAk2e12j++x2+3uc30pLi6WzWZzPxITE8/jrwFgIFq9erU6Ozv19NNPKzTU83MsQ0NDtXz5cnV2dmr16tUBmhBAIHgVHzNmzNBtt92mtLQ03XTTTXr77bclSevWrXOv+f6n2blcrjN+wt3SpUvV3NzsftTV1XkzEoAB7ODBg5KkW2+9tc/zPcd71gEYGvr1UtvIyEilpaVp//797le9fH+Xo7GxsdduyHdZrVbFxMR4PAAMDsnJyZKkLVu29Hm+53jPOgBDQ7/io6OjQ59++qni4uKUlJQkh8OhyspK93mn06mqqiplZGT0e1AAwScvL0+hoaH67W9/q87OTo9znZ2devLJJxUaGqq8vLwATQggELyKj0WLFqmqqkq1tbXasWOHbr/9drW0tOjee++VxWJRfn6+ioqK9Oabb2rv3r2aO3euIiIiNHv2bH/ND2AACwsL04IFC/TVV18pISFBa9as0dGjR7VmzRolJCToq6++0oIFCxQWFhboUQEYFHr2Jf9z5MgR3XXXXTp27JhGjhypa665Rh999JHGjBkj6fRL6trb25WXl6fjx48rPT1dFRUVio6O9svwAAa+FStWSJJKS0s1b9489/HQ0FAtXrzYfR7A0GFxuVyuQA/xXS0tLbLZbGpubub+D2AQcTqdWr16tQ4ePKjk5GTl5eWx4wEMIt78/CY+AABAv3nz85sPlgMAAEYRHwAAwCjiAwAAGOXVq10A4HxxwymAHsQHAL8rKChQaWmpxxuNLV68WAsWLOCltsAQxK9dAPhVQUGBSkpKFBsbq7Vr16q+vl5r165VbGysSkpKVFBQEOgRARjGS20B+I3T6VRkZKRiY2N15MgRj0+27ezsVEJCgpqamtTW1savYIAgx0ttAQwIq1evVmdnp55++mlZLBZt27ZNL7/8srZt2yaLxaLly5ers7NTq1evDvSoAAzing8AfnPw4EFJksVi0bhx43To0CH3ubFjx2rZsmUe6wAMDex8APCb5ORkSdIDDzygtLQ0ffjhh2ptbdWHH36otLQ0Pfjggx7rAAwN3PMBwG/a29sVERGhsLAwtba2etzX4XQ6FR0dLafTqZMnTyo8PDyAkwLoL+75ADAg7NixQ9Lp0Bg9erTWrFmjo0ePas2aNRo9erScTqfHOgBDA/EBwG/q6+slSY888oiampo0b948XXzxxZo3b56ampr0yCOPeKwDMDQQHwD8Ji4uTpJ05513qq2tTaWlpXr44YdVWlqqtrY2zZo1y2MdgKGBez4A+E1XV5fGjRuntLQ0bd68WcOG/e+/d7q7u5WTk6O9e/dq//79CgkJCeCkAPqLez4ADAghISFauXKltmzZopycHI9Xu+Tk5GjLli165plnCA9giOF9PgD4VW5urjZu3Kj8/HxlZGS4j48ePVobN25Ubm5uAKcDEAjsfADwu/Xr16uurs7j2OHDh7V+/foATQQgkIgPAH6Vk5Ojt956S2FhYXrsscd04MABPfbYYwoLC9Nbb72lnJycQI8IwDBuOAXgN7zJGDB0cMMpgAFh8eLFkqSFCxf2+tTasLAw5efne6wDMDQQHwD8Zv/+/ZJOf7ZLX+6//36PdQCGBuIDgN+kpKRIkv7yl7/0ef7555/3WAdgaOCeDwB+wz0fwNDBPR8ABoTw8HDNnDnTHRpLlizR559/riVLlrjDY+bMmYQHMMSw8wHA73pebvt9M2fO1ObNm80PBMDn2PkAMKDMmTNHo0eP9jg2evRozZkzJ0ATAQgk4gOAX23atEm33367JkyY4PHZLhMmTNDtt9+uTZs2BXpEAIbxaxcAfsOn2gJDB792ATAgbN++XYcOHdLjjz/uER6SNGzYMC1dulS1tbXavn17gCYEEAjEBwC/qa+vlySlpqb2eb7neM86AEMD8QHAb+Li4iRJe/fu7fN8z/GedQCGBuIDgN9MnTpVY8eOVVFRkbq7uz3OdXd3q7i4WElJSZo6dWqAJgQQCMQHAL8JCQnRypUrtWXLFuXk5Hi82iUnJ0dbtmzRM888w82mwBATGugBAAxuubm52rhxox599FFlZGS4jyclJWnjxo3Kzc0N4HQAAoGX2gIwoqurS9u3b1d9fb3i4uI0depUdjyAQcSbn9/sfAAwIiQkRJmZmYEeA8AAwD0fAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIzi1S4AjOCltgB6sPMBwO82bdqk5ORkTZ8+XbNnz9b06dOVnJysTZs2BXo0AAFAfADwq02bNum2227T4cOHPY4fPnxYt912GwECDEG8wykAv+nq6lJsbKyam5s1atQozZkzR5dccom++OILrV+/Xo2NjbLZbGpqauJXMECQ4x1OAQwI7733npqbmxUZGSmr1apnnnnGfS4xMVGRkZFqbm7We++9p6ysrABOCsAkfu0CwG/++te/SpLa2tp07Ngxj3PHjh1TW1ubxzoAQwM7HwD8pqWlxf3nG264QbfccovCw8PV3t6ud955R2+//XavdQAGP+IDgN84HA5JktVq1d69e92xIUljxoxRWFiYnE6nex2AoYH4AOA3I0aMkCR1dHSovb1dd9xxhyIjI9XW1qZt27bJ6XR6rAMwNBAfAPzGYrG4/9zY2KjXXnvtrOsADH7ccArAb851R4OdD2BoIT4A+M1FF13k03UABgfiA4DffPDBBz5dB2BwID4A+E1FRYVP1wEYHIgPAH5TX1/v/vPEiRM1bNjpf+UMGzZMEydO7HMdgMGvX/FRXFwsi8Wi/Px89zGXy6XCwkLFx8crPDxcmZmZ2rdvX3/nBBCEvv32W/efd+3ape7ubklSd3e3du3a1ec6AIPfecdHTU2N1qxZo/Hjx3scX7FihVatWqXy8nLV1NTI4XAoKytLra2t/R4WAAAEv/OKjxMnTujuu+/W2rVrdeGFF7qPu1wulZWVadmyZcrNzVVqaqrWrVunkydPasOGDT4bGgAABK/zio+HHnpIP/3pT3XTTTd5HK+trVVDQ4Oys7Pdx6xWq6ZNm6bq6uo+r9XR0aGWlhaPB4DBISQkxKfrAAwOXr/D6SuvvKJdu3appqam17mGhgZJkt1u9zhut9v15Zdf9nm94uJiPfXUU96OASAIdHV1+XQdgMHBq52Puro6PfLII3rppZc0fPjwH1z3/bdKdrlcP/j2yUuXLlVzc7P7UVdX581IAAAgyHi187Fz5041NjZq0qRJ7mNdXV16//33VV5ers8++0zS6R2QuLg495rGxsZeuyE9rFarrFbr+cwOAACCkFc7HzfeeKP27Nmj3bt3ux+TJ0/W3Xffrd27d+uSSy6Rw+FQZWWl+3ucTqeqqqqUkZHh8+EBDGyjRo3y6ToAg4NXOx/R0dFKTU31OBYZGanY2Fj38fz8fBUVFSklJUUpKSkqKipSRESEZs+e7bupAQSFq666Su++++45rQMwdHh9w+nZFBQUqL29XXl5eTp+/LjS09NVUVGh6OhoXz8VgAHu4MGDPl0HYHCwuFwuV6CH+K6WlhbZbDY1NzcrJiYm0OMA6IfY2Fj997//Peu6ESNGqKmpycBEAPzFm5/ffLYLAL85efKkT9cBGByIDwB+43Q6fboOwOBAfADwm54PkvPVOgCDA/EBAACMIj4AAIBRxAcAv5k1a5ZP1wEYHHipLQC/sVqt53QzaVhYmDo6OgxMBMBfeKktgAGBV7sA6AvxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjPIqPp577jmNHz9eMTExiomJ0ZQpU/T3v//dfd7lcqmwsFDx8fEKDw9XZmam9u3b5/OhAQBA8PIqPhISEvTHP/5RH3/8sT7++GPdcMMNmjlzpjswVqxYoVWrVqm8vFw1NTVyOBzKyspSa2urX4YHAADBx+JyuVz9ucCIESNUUlKi++67T/Hx8crPz9eSJUskSR0dHbLb7frTn/6kefPmndP1WlpaZLPZ1NzcrJiYmP6MBsBH2p1dOvj1Ca+/Ly3hR+e8ds+Rb7y+viQlj4xSeFjIeX0vAN/x5ud36Pk+SVdXl15//XW1tbVpypQpqq2tVUNDg7Kzs91rrFarpk2bpurq6h+Mj46ODnV0dHgMD2BgOfj1Cd365w/8+hzne/0t869T6sU2H08DwJ+8jo89e/ZoypQpOnXqlKKiovTmm2/qiiuuUHV1tSTJbrd7rLfb7fryyy9/8HrFxcV66qmnvB0DgEHJI6O0Zf51Xn9f2p/Ofe35XF86PRuA4OJ1fFx22WXavXu3vvnmG73xxhu69957VVVV5T5vsVg81rtcrl7Hvmvp0qVauHCh++uWlhYlJiZ6OxYAPwoPCzmv3YWrrrpKn3zyyTmtY/cCGDq8jo+wsDCNGzdOkjR58mTV1NTo2Wefdd/n0dDQoLi4OPf6xsbGXrsh32W1WmW1Wr0dA0AQ2LVr1xn/4+O76wAMHf1+nw+Xy6WOjg4lJSXJ4XCosrLSfc7pdKqqqkoZGRn9fRoAQeps97T38553AEHIq52Pxx9/XDNmzFBiYqJaW1v1yiuvaNu2bdq6dassFovy8/NVVFSklJQUpaSkqKioSBEREZo9e7a/5gcQBFwulyZOnOjxK5irrrqKHQ9giPIqPr766ivdc889qq+vl81m0/jx47V161ZlZWVJkgoKCtTe3q68vDwdP35c6enpqqioUHR0tF+GBxA8du3apb3/adatf/6AV6gAQ1y/3+fD13ifD2DwIj6Awcubn998tgsAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEZ5FR/FxcW6+uqrFR0drVGjRiknJ0efffaZxxqXy6XCwkLFx8crPDxcmZmZ2rdvn0+HBgAAwcur+KiqqtJDDz2kjz76SJWVlers7FR2drba2trca1asWKFVq1apvLxcNTU1cjgcysrKUmtrq8+HBwAAwSfUm8Vbt271+PqFF17QqFGjtHPnTl1//fVyuVwqKyvTsmXLlJubK0lat26d7Ha7NmzYoHnz5vlucgAAEJT6dc9Hc3OzJGnEiBGSpNraWjU0NCg7O9u9xmq1atq0aaquru7zGh0dHWppafF4AACAweu848PlcmnhwoW67rrrlJqaKklqaGiQJNntdo+1drvdfe77iouLZbPZ3I/ExMTzHQkAAASB846Phx9+WP/85z/18ssv9zpnsVg8vna5XL2O9Vi6dKmam5vdj7q6uvMdCQAABAGv7vnoMX/+fP3tb3/T+++/r4SEBPdxh8Mh6fQOSFxcnPt4Y2Njr92QHlarVVar9XzGAAAAQcirnQ+Xy6WHH35YmzZt0nvvvaekpCSP80lJSXI4HKqsrHQfczqdqqqqUkZGhm8mBgAAQc2rnY+HHnpIGzZs0FtvvaXo6Gj3fRw2m03h4eGyWCzKz89XUVGRUlJSlJKSoqKiIkVERGj27Nl++QsAAIDg4lV8PPfcc5KkzMxMj+MvvPCC5s6dK0kqKChQe3u78vLydPz4caWnp6uiokLR0dE+GRgAAAQ3r+LD5XKddY3FYlFhYaEKCwvPdyYAADCI8dkuAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYFRroAQD4T+2xNrV1dAZ6DLcDjSc8/ncgibSGKumiyECPAQwJxAcwSNUea9P0Z7YFeow+5b+6O9Aj9OkfizIJEMAA4gMYpHp2PMpm/UTjRkUFeJrTTn3bpSPH25VwYbiGXxAS6HHcDjSeUP6ruwfULhEwmBEfwCA3blSUUi+2BXoMt8ljAz0BgEDjhlMAAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAqNBADwDAPzq6TmnY8P+otuUzDRseFehxBrTalhMaNvw/6ug6JckW6HGAQY/4AAapo21fKjLpz3r8/wZ6kuAQmSQdbfuJJske6FGAQY/4AAap+Mgxaqudr2dn/UTJo9j5OJODjSf0yKu7FT99TKBHAYYE4gMYpKwhw9V96mIlxVymK2L5VcKZdJ9qVvepr2UNGR7oUYAhgRtOAQCAUV7Hx/vvv6+f/exnio+Pl8Vi0ebNmz3Ou1wuFRYWKj4+XuHh4crMzNS+fft8NS8AAAhyXsdHW1ubJkyYoPLy8j7Pr1ixQqtWrVJ5eblqamrkcDiUlZWl1tbWfg8LAACCn9f3fMyYMUMzZszo85zL5VJZWZmWLVum3NxcSdK6detkt9u1YcMGzZs3r3/TAgCAoOfTez5qa2vV0NCg7Oxs9zGr1app06apurral08FAACClE9f7dLQ0CBJsts9Xydvt9v15Zdf9vk9HR0d6ujocH/d0tLiy5EAAMAA45dXu1gsFo+vXS5Xr2M9iouLZbPZ3I/ExER/jAQAAAYIn8aHw+GQ9L8dkB6NjY29dkN6LF26VM3Nze5HXV2dL0cCAAADjE/jIykpSQ6HQ5WVle5jTqdTVVVVysjI6PN7rFarYmJiPB4AAGDw8vqejxMnTujAgQPur2tra7V7926NGDFCo0ePVn5+voqKipSSkqKUlBQVFRUpIiJCs2fP9ungAAAgOHkdHx9//LGmT5/u/nrhwoWSpHvvvVcvvviiCgoK1N7erry8PB0/flzp6emqqKhQdHS076YGAABBy+v4yMzMlMvl+sHzFotFhYWFKiws7M9cAABgkOKzXQAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjiA8AAGAU8QEAAIwiPgAAgFHEBwAAMIr4AAAARhEfAADAKOIDAAAYRXwAAACjQgM9AAD/aP+2S5K09z/NAZ7kf05926Ujx9uVcGG4hl8QEuhx3A40ngj0CMCQQnwAg9TB//8D9bFNewI8SfCItPKvRMAE/p8GDFLZVzokScmjohQ+QHYZDjSeUP6ru1U26ycaNyoq0ON4iLSGKumiyECPAQwJxAcwSI2IDNOd/2d0oMfo07hRUUq92BboMQAECDecAgAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADCK+AAAAEYRHwAAwCjiAwAAGEV8AAAAo4gPAABgFPEBAACMIj4AAIBRxAcAADAqNNADABj42p1dOvj1iX5f50DjCY//9YXkkVEKDwvx2fUA+B/xAeCsDn59Qrf++QOfXS//1d0+u9aW+dcp9WKbz64HwP+IDwBnlTwySlvmX9fv65z6tktHjrcr4cJwDb/AN7sVySOjfHIdAOb4LT5Wr16tkpIS1dfX68orr1RZWZmmTp3qr6cD4EfhYSE+212YPNYnlwEQxPxyw+mrr76q/Px8LVu2TJ988ommTp2qGTNm6PDhw/54OgAAEEQsLpfL5euLpqena+LEiXruuefcxy6//HLl5OSouLj4jN/b0tIim82m5uZmxcTE+Ho0AADgB978/Pb5zofT6dTOnTuVnZ3tcTw7O1vV1dW91nd0dKilpcXjAQAABi+fx8exY8fU1dUlu93ucdxut6uhoaHX+uLiYtlsNvcjMTHR1yMBAIABxG9vMmaxWDy+drlcvY5J0tKlS9Xc3Ox+1NXV+WskAAAwAPj81S4XXXSRQkJCeu1yNDY29toNkSSr1Sqr1errMQAAwADl852PsLAwTZo0SZWVlR7HKysrlZGR4eunAwAAQcYv7/OxcOFC3XPPPZo8ebKmTJmiNWvW6PDhw/rVr37lj6cDAABBxC/xMWvWLDU1NWn58uWqr69Xamqq3nnnHY0ZM8YfTwcAAIKIX97noz94nw8AAIJPQN/nAwAA4EyIDwAAYBTxAQAAjPLbp9qer55bUHibdQAAgkfPz+1zuZV0wMVHa2urJPE26wAABKHW1lbZbLYzrhlwr3bp7u7W0aNHFR0d3efbsQMIXi0tLUpMTFRdXR2vZgMGGZfLpdbWVsXHx2vYsDPf1THg4gPA4MVL6QFI3HAKAAAMIz4AAIBRxAcAY6xWq373u9/xSdbAEMc9HwAAwCh2PgAAgFHEBwAAMIr4AAAARhEfAPqUmZmp/Pz8gDz3tm3bZLFY9M033wTk+QH4F/EBIKD6ipyMjAzV19ef9S2aAQQn4gOAX3z77bfn/b1hYWFyOBx8xAIwSBEfANTW1qY5c+YoKipKcXFxWrlypcd5i8WizZs3exz70Y9+pBdffFGSdOjQIVksFr322mvKzMzU8OHD9dJLL6mpqUl33XWXEhISFBERobS0NL388svua8ydO1dVVVV69tlnZbFYZLFYdOjQoT5/7fLGG2/oyiuvlNVq1dixY3vNOHbsWBUVFem+++5TdHS0Ro8erTVr1vj0nxMA3yA+AGjx4sX6xz/+oTfffFMVFRXatm2bdu7c6fV1lixZot/85jf69NNPdfPNN+vUqVOaNGmStmzZor179+qXv/yl7rnnHu3YsUOS9Oyzz2rKlCl68MEHVV9fr/r6+j4/0Xrnzp264447dOedd2rPnj0qLCzUE0884Y6fHitXrtTkyZP1ySefKC8vT7/+9a/173//+7z+mQDwn9BADwAgsE6cOKHnn39e69evV1ZWliRp3bp1SkhI8Ppa+fn5ys3N9Ti2aNEi95/nz5+vrVu36vXXX1d6erpsNpvCwsIUEREhh8Pxg9ddtWqVbrzxRj3xxBOSpEsvvVT/+te/VFJSorlz57rX3XLLLcrLy5N0OoRKS0u1bds2/fjHP/b67wLAf9j5AIa4gwcPyul0asqUKe5jI0aM0GWXXeb1tSZPnuzxdVdXl/7whz9o/Pjxio2NVVRUlCoqKnT48GGvrvvpp5/q2muv9Th27bXXav/+/erq6nIfGz9+vPvPFotFDodDjY2NXv89APgXOx/AEHcun7BgsVh6revrhtLIyEiPr1euXKnS0lKVlZUpLS1NkZGRys/Pl9Pp9HrG79982tfcF1xwQa+5u7u7vXouAP7HzgcwxI0bN04XXHCBPvroI/ex48eP6/PPP3d/PXLkSNXX17u/3r9/v06ePHnWa2/fvl0zZ87UL37xC02YMEGXXHKJ9u/f77EmLCzMY/eiL1dccYU++OADj2PV1dW69NJLFRISctY5AAws7HwAQ1xUVJTuv/9+LV68WLGxsbLb7Vq2bJmGDfvff5vccMMNKi8v1zXXXKPu7m4tWbKk1y5DX8aNG6c33nhD1dXVuvDCC7Vq1So1NDTo8ssvd68ZO3asduzYoUOHDikqKkojRozodZ1HH31UV199tX7/+99r1qxZ+vDDD1VeXq7Vq1f75h8CAKPY+QCgkpISXX/99fr5z3+um266Sdddd50mTZrkPr9y5UolJibq+uuv1+zZs7Vo0SJFRESc9bpPPPGEJk6cqJtvvlmZmZlyOBzKycnxWLNo0SKFhIToiiuu0MiRI/u8H2TixIl67bXX9Morryg1NVVPPvmkli9f7nGzKYDgYXGdyy98AQAAfISdDwAAYBTxAQAAjCI+AACAUcQHAAAwivgAAABGER8AAMAo4gMAABhFfAAAAKOIDwAAYBTxAQAAjCI+AACAUcQHAAAw6v8BQfQIghSH684AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['duration']].plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "4K0kvp1fFk_3",
    "outputId": "938bc7b8-ea35-4105-a5d7-f1eff06d6a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwpUlEQVR4nO3dfXRU9YH/8U8SkmGI4ZoQk3EQIQoHsaGFhpUHRUKVoJvA4biu1dBUT13YVgNmBR9g20o9mihQ6i4cBPuHuttKPKeAq0iz4IpoSnhoNCsBQbRAICSGwmQGME9kvr8//HG3QxCjDoTk+36dM6fMvZ+Z+V7OqffD9z7FGGOMAAAALBTb1QMAAADoKhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1enX1AC514XBYR44cUVJSkmJiYrp6OAAAoBOMMTpx4oT8fr9iY7983oci9BWOHDmiAQMGdPUwAADAN3Do0CFdddVVX7qeIvQVkpKSJH3xF9m3b98uHg0AAOiMUCikAQMGuPvxL0MR+gpnDof17duXIgQAQDfzVae1cLI0AACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtbqgIwErt7e167733VFdXpyuvvFLjx49XXFxcVw8LwEXGjBAA66xZs0aDBw/WxIkTlZ+fr4kTJ2rw4MFas2ZNVw8NwEVGEQJglTVr1ujOO+/U8OHDVVFRoRMnTqiiokLDhw/XnXfeSRkCLBNjjDFdPYhLWSgUkuM4CgaDPGsM6Oba29s1ePBgDR8+XK+99ppiY//v34LhcFjTpk1TdXW19u3bx2EyoJvr7P6bGSEA1njvvfd04MABzZ8/P6IESVJsbKzmzZun/fv367333uuiEQK42ChCAKxRV1cnScrMzDzn+jPLz+QA9HwUIQDWuPLKKyVJ1dXV51x/ZvmZHICejyIEwBrjx4/XoEGDVFxcrHA4HLEuHA6rpKREGRkZGj9+fBeNEMDFRhECYI24uDj9+te/1rp16zRt2rSIq8amTZumdevWafHixZwoDViEGyoCsModd9yhP/zhD5ozZ47GjRvnLs/IyNAf/vAH3XHHHV04OgAX29eeEXr33Xc1ZcoU+f1+xcTE6LXXXnPXtbW16bHHHtPw4cOVmJgov9+vH//4xzpy5EjEd7S0tGjWrFlKTU1VYmKipk6dqsOHD0dkAoGACgoK5DiOHMdRQUGBGhsbIzI1NTWaMmWKEhMTlZqaqtmzZ6u1tTUis3PnTk2YMEFer1f9+/fXk08+Ke4YANjtjjvu0CeffKJNmzbplVde0aZNm7Rv3z5KEGChr12ETp06pe9973tatmxZh3Wff/653n//ff3iF7/Q+++/rzVr1ujjjz/W1KlTI3JFRUVau3atSktLVV5erpMnTyovL0/t7e1uJj8/X1VVVSorK1NZWZmqqqpUUFDgrm9vb1dubq5OnTql8vJylZaWavXq1ZozZ46bCYVCmjRpkvx+v3bs2KGlS5dq8eLFWrJkydfdbAA9TFxcnLKzs3XPPfcoOzubw2GArcy3IMmsXbv2vJnt27cbSebgwYPGGGMaGxtNfHy8KS0tdTO1tbUmNjbWlJWVGWOM2b17t5Fktm7d6mYqKiqMJLNnzx5jjDHr1683sbGxpra21s2sWrXKeDweEwwGjTHGLF++3DiOY5qbm91MSUmJ8fv9JhwOd2obg8GgkeR+JwAAuPR1dv99wU+WDgaDiomJ0eWXXy5JqqysVFtbm3JyctyM3+9XZmamtmzZIkmqqKiQ4zgaPXq0mxkzZowcx4nIZGZmyu/3u5nJkyerpaVFlZWVbmbChAnyeDwRmSNHjujAgQPnHG9LS4tCoVDECwAA9EwXtAg1Nzfr8ccfV35+vnt76/r6eiUkJCg5OTkim56ervr6ejeTlpbW4fvS0tIiMunp6RHrk5OTlZCQcN7MmfdnMmcrKSlxz0tyHEcDBgz4upsNAAC6iQtWhNra2nT33XcrHA5r+fLlX5k3xigmJsZ9/7d/jmbG/P8Tpc/1WUmaN2+egsGg+zp06NBXjh0AAHRPF+Ty+ba2Nt11113av3+/3n777YiHnfl8PrW2tioQCETMCjU0NLiXsvp8Pn322Wcdvvfo0aPujI7P59O2bdsi1gcCAbW1tUVkzp75aWhokKQOM0VneDyeiENpAHqm9vZ2vffee6qrq9OVV16p8ePHc8I0YKGozwidKUH79u3TW2+9pX79+kWsz8rKUnx8vDZu3Oguq6urU3V1tVuExo4dq2AwqO3bt7uZbdu2KRgMRmSqq6sjngm0YcMGeTweZWVluZl333034pL6DRs2yO/3a9CgQdHedADdxJo1azR48GBNnDhR+fn5mjhxogYPHqw1a9Z09dAAXGQxxny9m+qcPHlSn3zyiSRp5MiRWrJkiSZOnKiUlBT5/X79wz/8g95//32tW7cuYtYlJSVFCQkJkqSf/exnWrdunV566SWlpKRo7ty5OnbsmCorK91/kd1+++06cuSIVq5cKUmaOXOmBg4cqDfeeEPSF/+aGzFihNLT07Vo0SIdP35c9913n6ZNm6alS5dK+uJE7aFDh+oHP/iB5s+fr3379um+++7TL3/5y4jL7M8nFArJcRwFg8GImS0A3dOaNWt05513Kjc3V7fffru8Xq+ampr0xz/+UW+++SY3VQR6iE7vv7/u5WibNm0ykjq87r33XrN///5zrpNkNm3a5H5HU1OTKSwsNCkpKcbr9Zq8vDxTU1MT8TvHjh0z06dPN0lJSSYpKclMnz7dBAKBiMzBgwdNbm6u8Xq9JiUlxRQWFkZcKm+MMR9++KEZP3688Xg8xufzmQULFnT60nljuHwe6ElOnz5tBg0aZEaNGmUGDhwY8d+ogQMHmlGjRpmMjAxz+vTprh4qgG+ps/vvrz0jZBtmhICe45133tHEiRMlSVOmTNH8+fOVmZmp6upqFRcXuzPOmzZtUnZ2dheOFMC31dn9Nw9dBWCN2tpaSV8cen/ttdc0ZswYXXbZZRozZoxee+013X777RE5AD0fRQiANY4ePSrpi2eNGWP0zjvvaNWqVXrnnXdkjNG0adMicgB6Pp4+D8AaV1xxhSRp+fLlevrppyPuMD9o0CD3lh5ncgB6PooQAGv0799fkvTBBx/oiiuu0LXXXqumpiZ5vV6FQiG3GJ3JAej5OFn6K3CyNNBztLa2KjExUeFwWOFwuMP62NhYxcbG6tSpU+7tPgB0T5wsDQBn2bJli06fPu2WoGHDhmnevHkaNmyYJCkcDuv06dPuw50B9HwcGgNgjU8//dT981VXXaWPPvpIH330kSRpwIAB7rMFP/30Uy6fByzBjBAAazz33HOSpDFjxujAgQPatGmTXnnlFW3atEn79+/XDTfcEJED0PMxIwTAGo2NjZKkXr16KSYmJmLWJxwOq1evXhE5AD0fM0IArDFw4EBJUnl5uaZNm6aKigqdOHFCFRUVmjZtmntu0JkcgJ6Pq8a+AleNAT1HMBjU5ZdfLinynCBJuvrqq1VTUyPpixkhx3G6YogAooSrxgDgLI7j6Nprr5WkiBIkyS1B1157LSUIsAhFCIBVMjMzv9V6AD0Lh8a+AofGgJ6jqalJffr0UVxcnNrb2zusP7P8888/l9fr7YIRAogWDo0BwFkeeeQRSTpnCfrb5WdyAHo+Lp8HYI29e/e6f+7Vq5duvvlm9e/fX7W1tXr33Xd1+vTpDjkAPRtFCIA1Tp486f45HA7r7bffdt/HxsaeMwegZ+PQGABrhEKhqOYAdH8UIQDWaG1tdf8cDod16623qri4WLfeemvE0+j/NgegZ+PQGABrpKam6pNPPnHfv/XWW3rrrbfOmQNgB2aEAFjjiiuuiGoOQPdHEQJgjc7eC4x7hgH2oAgBsMbw4cOjmgPQ/VGEAFijsbExqjkA3R9FCIA1zjxYNVo5AN0fRQiANTp7WTyXzwP2oAgBsMYHH3wQ1RyA7o8iBMAax48fj2oOQPdHEQIAANaiCAGwRlJSUlRzALo/ihAAa6SlpUU1B6D7owgBsMbHH38c1RyA7o8iBMAaoVAoqjkA3R9FCAAAWIsiBMAaHo8nqjkA3R9FCIA1EhISopoD0P1RhAAAgLUoQgCswYwQgLNRhABYIyMjI6o5AN0fRQiANU6ePBnVHIDujyIEwBp79uyJag5A90cRAgAA1qIIAQAAa1GEAACAtb52EXr33Xc1ZcoU+f1+xcTE6LXXXotYb4zRggUL5Pf75fV6lZ2drV27dkVkWlpaNGvWLKWmpioxMVFTp07V4cOHIzKBQEAFBQVyHEeO46igoECNjY0RmZqaGk2ZMkWJiYlKTU3V7Nmz1draGpHZuXOnJkyYIK/Xq/79++vJJ5+UMebrbjYAAOiBvnYROnXqlL73ve9p2bJl51y/cOFCLVmyRMuWLdOOHTvk8/k0adIknThxws0UFRVp7dq1Ki0tVXl5uU6ePKm8vDy1t7e7mfz8fFVVVamsrExlZWWqqqpSQUGBu769vV25ubk6deqUysvLVVpaqtWrV2vOnDluJhQKadKkSfL7/dqxY4eWLl2qxYsXa8mSJV93swH0AL17945qDkAPYL4FSWbt2rXu+3A4bHw+n3nmmWfcZc3NzcZxHLNixQpjjDGNjY0mPj7elJaWupna2loTGxtrysrKjDHG7N6920gyW7dudTMVFRVGktmzZ48xxpj169eb2NhYU1tb62ZWrVplPB6PCQaDxhhjli9fbhzHMc3NzW6mpKTE+P1+Ew6HO7WNwWDQSHK/E0D3FRMTYyR95SsmJqarhwrgW+rs/juq5wjt379f9fX1ysnJcZd5PB5NmDBBW7ZskSRVVlaqra0tIuP3+5WZmelmKioq5DiORo8e7WbGjBkjx3EiMpmZmfL7/W5m8uTJamlpUWVlpZuZMGFCxAMUJ0+erCNHjujAgQPn3IaWlhaFQqGIF4CewXTysHhncwC6v6gWofr6eklSenp6xPL09HR3XX19vRISEpScnHzeTFpaWofvT0tLi8ic/TvJyclKSEg4b+bM+zOZs5WUlLjnJTmOowEDBnz1hgMAgG7pglw1FhMTE/HeGNNh2dnOzpwrH43MmX/pfdl45s2bp2Aw6L4OHTp03nEDAIDuq1c0v8zn80n6YrblyiuvdJc3NDS4MzE+n0+tra0KBAIRs0INDQ0aN26cm/nss886fP/Ro0cjvmfbtm0R6wOBgNra2iIyZ8/8NDQ0SOo4a3WGx+OJOJQG4NLS1NquT49e+EdgVNcGv9Hnrr3iMnkT4qI8GgAXSlSLUEZGhnw+nzZu3KiRI0dKklpbW7V582Y9++yzkqSsrCzFx8dr48aNuuuuuyRJdXV1qq6u1sKFCyVJY8eOVTAY1Pbt23XDDTdIkrZt26ZgMOiWpbFjx+rpp59WXV2dW7o2bNggj8ejrKwsNzN//ny1tra6T5PesGGD/H6/Bg0aFM1NB3CRfHr0pPKWln+zD8d5pPaWTuW+6W+sm3WTMvs73+izAC6+GPM1zwo8efKkPvnkE0nSyJEjtWTJEk2cOFEpKSm6+uqr9eyzz6qkpEQvvviihgwZouLiYr3zzjvau3evkpKSJEk/+9nPtG7dOr300ktKSUnR3LlzdezYMVVWViou7ot/Sd1+++06cuSIVq5cKUmaOXOmBg4cqDfeeEPSF5fPjxgxQunp6Vq0aJGOHz+u++67T9OmTdPSpUslScFgUEOHDtUPfvADzZ8/X/v27dN9992nX/7ylxGX2Z9PKBSS4zgKBoPq27fv1/mrAnABfJsZodraWt02+jtfmSvbtkv9+/f/Rr/BjBBwaej0/vvrXo62adOmc15ueu+99xpjvriE/oknnjA+n894PB5z8803m507d0Z8R1NTkyksLDQpKSnG6/WavLw8U1NTE5E5duyYmT59uklKSjJJSUlm+vTpJhAIRGQOHjxocnNzjdfrNSkpKaawsDDiUnljjPnwww/N+PHjjcfjMT6fzyxYsKDTl84bw+XzQE+TkJBw3kvnExISunqIAKKgs/vvrz0jZBtmhICex+PxdLgLvSQlJCSopaUTh84AXPI6u//mWWMArNPS0qLDhw+rr3O5FBOnvs7lOnz4MCUIsBBFCICV+vfvrz/tOqCBj/6X/rTrwDc+JwhA90YRAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtFvQidPn1aP//5z5WRkSGv16trrrlGTz75pMLhsJsxxmjBggXy+/3yer3Kzs7Wrl27Ir6npaVFs2bNUmpqqhITEzV16lQdPnw4IhMIBFRQUCDHceQ4jgoKCtTY2BiRqamp0ZQpU5SYmKjU1FTNnj1bra2t0d5sAADQDUW9CD377LNasWKFli1bpo8++kgLFy7UokWLtHTpUjezcOFCLVmyRMuWLdOOHTvk8/k0adIknThxws0UFRVp7dq1Ki0tVXl5uU6ePKm8vDy1t7e7mfz8fFVVVamsrExlZWWqqqpSQUGBu769vV25ubk6deqUysvLVVpaqtWrV2vOnDnR3mwAANAdmSjLzc01P/nJTyKW3XHHHeZHP/qRMcaYcDhsfD6feeaZZ9z1zc3NxnEcs2LFCmOMMY2NjSY+Pt6Ulpa6mdraWhMbG2vKysqMMcbs3r3bSDJbt251MxUVFUaS2bNnjzHGmPXr15vY2FhTW1vrZlatWmU8Ho8JBoOd2p5gMGgkdToPoPvYebjRDHxsndl5uLGrhwIgyjq7/476jNBNN92k//mf/9HHH38sSfrf//1flZeX6+///u8lSfv371d9fb1ycnLcz3g8Hk2YMEFbtmyRJFVWVqqtrS0i4/f7lZmZ6WYqKirkOI5Gjx7tZsaMGSPHcSIymZmZ8vv9bmby5MlqaWlRZWXlOcff0tKiUCgU8QIAAD1Tr2h/4WOPPaZgMKjrrrtOcXFxam9v19NPP6177rlHklRfXy9JSk9Pj/hcenq6Dh486GYSEhKUnJzcIXPm8/X19UpLS+vw+2lpaRGZs38nOTlZCQkJbuZsJSUl+tWvfvV1NxsAAHRDUZ8RevXVV/W73/1Or7zyit5//329/PLLWrx4sV5++eWIXExMTMR7Y0yHZWc7O3Ou/DfJ/K158+YpGAy6r0OHDp13TAAAoPuK+ozQI488oscff1x33323JGn48OE6ePCgSkpKdO+998rn80n6YrbmyiuvdD/X0NDgzt74fD61trYqEAhEzAo1NDRo3Lhxbuazzz7r8PtHjx6N+J5t27ZFrA8EAmpra+swU3SGx+ORx+P5ppsPAAC6kajPCH3++eeKjY382ri4OPfy+YyMDPl8Pm3cuNFd39raqs2bN7slJysrS/Hx8RGZuro6VVdXu5mxY8cqGAxq+/btbmbbtm0KBoMRmerqatXV1bmZDRs2yOPxKCsrK8pbDgAAupuozwhNmTJFTz/9tK6++mp95zvf0QcffKAlS5boJz/5iaQvDlUVFRWpuLhYQ4YM0ZAhQ1RcXKw+ffooPz9fkuQ4ju6//37NmTNH/fr1U0pKiubOnavhw4fr1ltvlSQNGzZMt912m2bMmKGVK1dKkmbOnKm8vDwNHTpUkpSTk6Prr79eBQUFWrRokY4fP665c+dqxowZ6tu3b7Q3HQAAdDfRvlwtFAqZhx56yFx99dWmd+/e5pprrjH/+q//alpaWtxMOBw2TzzxhPH5fMbj8Zibb77Z7Ny5M+J7mpqaTGFhoUlJSTFer9fk5eWZmpqaiMyxY8fM9OnTTVJSkklKSjLTp083gUAgInPw4EGTm5trvF6vSUlJMYWFhaa5ubnT28Pl80DPxeXzQM/V2f13jDHGdHUZu5SFQiE5jqNgMMgsEtDDVNcGlbe0XOtm3aTM/k5XDwdAFHV2/82zxgAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALDWBSlCtbW1+tGPfqR+/fqpT58+GjFihCorK931xhgtWLBAfr9fXq9X2dnZ2rVrV8R3tLS0aNasWUpNTVViYqKmTp2qw4cPR2QCgYAKCgrkOI4cx1FBQYEaGxsjMjU1NZoyZYoSExOVmpqq2bNnq7W19UJsNgAA6GaiXoQCgYBuvPFGxcfH649//KN2796tX//617r88svdzMKFC7VkyRItW7ZMO3bskM/n06RJk3TixAk3U1RUpLVr16q0tFTl5eU6efKk8vLy1N7e7mby8/NVVVWlsrIylZWVqaqqSgUFBe769vZ25ebm6tSpUyovL1dpaalWr16tOXPmRHuzAQBAd2Si7LHHHjM33XTTl64Ph8PG5/OZZ555xl3W3NxsHMcxK1asMMYY09jYaOLj401paambqa2tNbGxsaasrMwYY8zu3buNJLN161Y3U1FRYSSZPXv2GGOMWb9+vYmNjTW1tbVuZtWqVcbj8ZhgMNip7QkGg0ZSp/MAuo+dhxvNwMfWmZ2HG7t6KACirLP776jPCL3++usaNWqU/vEf/1FpaWkaOXKkfvvb37rr9+/fr/r6euXk5LjLPB6PJkyYoC1btkiSKisr1dbWFpHx+/3KzMx0MxUVFXIcR6NHj3YzY8aMkeM4EZnMzEz5/X43M3nyZLW0tEQcqvtbLS0tCoVCES8AANAzRb0I/eUvf9Hzzz+vIUOG6L//+7/105/+VLNnz9Z//Md/SJLq6+slSenp6RGfS09Pd9fV19crISFBycnJ582kpaV1+P20tLSIzNm/k5ycrISEBDdztpKSEvecI8dxNGDAgK/7VwAAALqJqBehcDis73//+youLtbIkSP1z//8z5oxY4aef/75iFxMTEzEe2NMh2VnOztzrvw3yfytefPmKRgMuq9Dhw6dd0wAAKD7inoRuvLKK3X99ddHLBs2bJhqamokST6fT5I6zMg0NDS4szc+n0+tra0KBALnzXz22Wcdfv/o0aMRmbN/JxAIqK2trcNM0Rkej0d9+/aNeAEAgJ4p6kXoxhtv1N69eyOWffzxxxo4cKAkKSMjQz6fTxs3bnTXt7a2avPmzRo3bpwkKSsrS/Hx8RGZuro6VVdXu5mxY8cqGAxq+/btbmbbtm0KBoMRmerqatXV1bmZDRs2yOPxKCsrK8pbDgAAupte0f7Cf/mXf9G4ceNUXFysu+66S9u3b9cLL7ygF154QdIXh6qKiopUXFysIUOGaMiQISouLlafPn2Un58vSXIcR/fff7/mzJmjfv36KSUlRXPnztXw4cN16623Svpilum2227TjBkztHLlSknSzJkzlZeXp6FDh0qScnJydP3116ugoECLFi3S8ePHNXfuXM2YMYOZHgAAEP3L540x5o033jCZmZnG4/GY6667zrzwwgsR68PhsHniiSeMz+czHo/H3HzzzWbnzp0RmaamJlNYWGhSUlKM1+s1eXl5pqamJiJz7NgxM336dJOUlGSSkpLM9OnTTSAQiMgcPHjQ5ObmGq/Xa1JSUkxhYaFpbm7u9LZw+TzQc3H5PNBzdXb/HWOMMV1dxi5loVBIjuMoGAwyiwT0MNW1QeUtLde6WTcps7/T1cMBEEWd3X/zrDEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWr26egAA7LH/r6d0quV0Vw/D9UnDyYj/vVQkenopIzWxq4cBWIEiBOCi2P/XU5q4+J2uHsY5Fb1a1dVD6GDT3GzKEHARUIQAXBRnZoKe++EIDU67rItH84XmtnYdDjTpqmSvesfHdfVwJH0xO1X0atUlNXMG9GQUIQAX1eC0y5TZ3+nqYbhGDerqEQDoShf8ZOmSkhLFxMSoqKjIXWaM0YIFC+T3++X1epWdna1du3ZFfK6lpUWzZs1SamqqEhMTNXXqVB0+fDgiEwgEVFBQIMdx5DiOCgoK1NjYGJGpqanRlClTlJiYqNTUVM2ePVutra0XanMBAEA3ckGL0I4dO/TCCy/ou9/9bsTyhQsXasmSJVq2bJl27Nghn8+nSZMm6cSJE26mqKhIa9euVWlpqcrLy3Xy5Enl5eWpvb3dzeTn56uqqkplZWUqKytTVVWVCgoK3PXt7e3Kzc3VqVOnVF5ertLSUq1evVpz5sy5kJsNAAC6C3OBnDhxwgwZMsRs3LjRTJgwwTz00EPGGGPC4bDx+XzmmWeecbPNzc3GcRyzYsUKY4wxjY2NJj4+3pSWlrqZ2tpaExsba8rKyowxxuzevdtIMlu3bnUzFRUVRpLZs2ePMcaY9evXm9jYWFNbW+tmVq1aZTwejwkGg53ajmAwaCR1Og/g3HYebjQDH1tndh5u7OqhXNL4ewKio7P77ws2I/Tggw8qNzdXt956a8Ty/fv3q76+Xjk5Oe4yj8ejCRMmaMuWLZKkyspKtbW1RWT8fr8yMzPdTEVFhRzH0ejRo93MmDFj5DhORCYzM1N+v9/NTJ48WS0tLaqsrDznuFtaWhQKhSJeAACgZ7ogJ0uXlpbq/fff144dOzqsq6+vlySlp6dHLE9PT9fBgwfdTEJCgpKTkztkzny+vr5eaWlpHb4/LS0tInP27yQnJyshIcHNnK2kpES/+tWvOrOZAACgm4v6jNChQ4f00EMP6Xe/+5169+79pbmYmJiI98aYDsvOdnbmXPlvkvlb8+bNUzAYdF+HDh0675gAAED3FfUiVFlZqYaGBmVlZalXr17q1auXNm/erH//939Xr1693Bmas2dkGhoa3HU+n0+tra0KBALnzXz22Wcdfv/o0aMRmbN/JxAIqK2trcNM0Rkej0d9+/aNeAEAgJ4p6kXolltu0c6dO1VVVeW+Ro0apenTp6uqqkrXXHONfD6fNm7c6H6mtbVVmzdv1rhx4yRJWVlZio+Pj8jU1dWpurrazYwdO1bBYFDbt293M9u2bVMwGIzIVFdXq66uzs1s2LBBHo9HWVlZ0d50AADQzUT9HKGkpCRlZmZGLEtMTFS/fv3c5UVFRSouLtaQIUM0ZMgQFRcXq0+fPsrPz5ckOY6j+++/X3PmzFG/fv2UkpKiuXPnavjw4e7J18OGDdNtt92mGTNmaOXKlZKkmTNnKi8vT0OHDpUk5eTk6Prrr1dBQYEWLVqk48ePa+7cuZoxYwYzPQAAoGvuLP3oo4+qqalJDzzwgAKBgEaPHq0NGzYoKSnJzfzmN79Rr169dNddd6mpqUm33HKLXnrpJcXF/d9t8H//+99r9uzZ7tVlU6dO1bJly9z1cXFxevPNN/XAAw/oxhtvlNfrVX5+vhYvXnzxNhYAAFyyYowxpqsHcSkLhUJyHEfBYJBZJOBbqK4NKm9pudbNuumSesTGpYa/JyA6Orv/vuCP2AAAALhUUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgragXoZKSEv3d3/2dkpKSlJaWpmnTpmnv3r0RGWOMFixYIL/fL6/Xq+zsbO3atSsi09LSolmzZik1NVWJiYmaOnWqDh8+HJEJBAIqKCiQ4zhyHEcFBQVqbGyMyNTU1GjKlClKTExUamqqZs+erdbW1mhvNgAA6IaiXoQ2b96sBx98UFu3btXGjRt1+vRp5eTk6NSpU25m4cKFWrJkiZYtW6YdO3bI5/Np0qRJOnHihJspKirS2rVrVVpaqvLycp08eVJ5eXlqb293M/n5+aqqqlJZWZnKyspUVVWlgoICd317e7tyc3N16tQplZeXq7S0VKtXr9acOXOivdkAAKA7MhdYQ0ODkWQ2b95sjDEmHA4bn89nnnnmGTfT3NxsHMcxK1asMMYY09jYaOLj401paambqa2tNbGxsaasrMwYY8zu3buNJLN161Y3U1FRYSSZPXv2GGOMWb9+vYmNjTW1tbVuZtWqVcbj8ZhgMNip8QeDQSOp03kA57bzcKMZ+Ng6s/NwY1cP5ZLG3xMQHZ3df1/wc4SCwaAkKSUlRZK0f/9+1dfXKycnx814PB5NmDBBW7ZskSRVVlaqra0tIuP3+5WZmelmKioq5DiORo8e7WbGjBkjx3EiMpmZmfL7/W5m8uTJamlpUWVl5TnH29LSolAoFPECAAA90wUtQsYYPfzww7rpppuUmZkpSaqvr5ckpaenR2TT09PddfX19UpISFBycvJ5M2lpaR1+My0tLSJz9u8kJycrISHBzZytpKTEPefIcRwNGDDg6242AADoJi5oESosLNSHH36oVatWdVgXExMT8d4Y02HZ2c7OnCv/TTJ/a968eQoGg+7r0KFD5x0TAADovi5YEZo1a5Zef/11bdq0SVdddZW73OfzSVKHGZmGhgZ39sbn86m1tVWBQOC8mc8++6zD7x49ejQic/bvBAIBtbW1dZgpOsPj8ahv374RLwAA0DNFvQgZY1RYWKg1a9bo7bffVkZGRsT6jIwM+Xw+bdy40V3W2tqqzZs3a9y4cZKkrKwsxcfHR2Tq6upUXV3tZsaOHatgMKjt27e7mW3btikYDEZkqqurVVdX52Y2bNggj8ejrKysaG86AADoZnpF+wsffPBBvfLKK/qv//ovJSUluTMyjuPI6/UqJiZGRUVFKi4u1pAhQzRkyBAVFxerT58+ys/Pd7P333+/5syZo379+iklJUVz587V8OHDdeutt0qShg0bpttuu00zZszQypUrJUkzZ85UXl6ehg4dKknKycnR9ddfr4KCAi1atEjHjx/X3LlzNWPGDGZ6AABA9IvQ888/L0nKzs6OWP7iiy/qvvvukyQ9+uijampq0gMPPKBAIKDRo0drw4YNSkpKcvO/+c1v1KtXL911111qamrSLbfcopdeeklxcXFu5ve//71mz57tXl02depULVu2zF0fFxenN998Uw888IBuvPFGeb1e5efna/HixdHebAAA0A3FGGNMVw/iUhYKheQ4joLBILNIwLdQXRtU3tJyrZt1kzL7O109nEsWf09AdHR2/82zxgAAgLUoQgAAwFoUIQAAYC2KEAAAsBZFCAAAWIsiBAAArEURAgAA1qIIAQAAa1GEAACAtShCAADAWhQhAABgLYoQAACwFkUIAABYiyIEAACsRRECAADWoggBAABrUYQAAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYK1eXT0AAHZoaW9WbO9a7Q/tVWzvy7p6OJes/aGTiu1dq5b2ZklOVw8H6PEoQgAuiiOnDioxY6nmb+/qkVz6EjOkI6dGKEvpXT0UoMejCAG4KPyJA3Vq/yz92w9H6No0ZoS+zKcNJ/XQq1XyTxzY1UMBrEARAnBReOJ6K9zcXxl9h+r6fhzy+TLh5qDCzUflievd1UMBrMDJ0gAAwFoUIQAAYC2KEAAAsBbnCAG4KJra2iVJ1bXBLh7J/2lua9fhQJOuSvaqd3xcVw9HkvRJw8muHgJgFYoQgIvi0/+/g398zc4uHkn3kOjhP8/AxcD/0wBcFDnf8UmSrk27TN5LaPal6NUqPffDERp8CV3Sn+jppYzUxK4eBmAFihCAiyIlMUF333B1Vw/jnAanXabM/lzSD9iIk6UBAIC1KEIAAMBaFCEAAGAtihAAALAWRQgAAFiLIgQAAKxlxeXzy5cv16JFi1RXV6fvfOc7eu655zR+/PiuHhaAb6CptV2fHo3O3ZfP3MU5mndzvvaKy+RNuDTukwTgq/X4IvTqq6+qqKhIy5cv14033qiVK1fq9ttv1+7du3X11ZfmPU0AfLlPj55U3tLyqH5n0atVUfuudbNu4p5EQDcSY4wxXT2IC2n06NH6/ve/r+eff95dNmzYME2bNk0lJSVf+flQKCTHcRQMBtW3b98LOVQAnRDNGaEL8awxZoSAS0Nn9989ekaotbVVlZWVevzxxyOW5+TkaMuWLV00KgDfhjchLqozLqMGRe2rAHRDPboI/fWvf1V7e7vS09Mjlqenp6u+vv6cn2lpaVFLS4v7PhQKXdAxAgCArmPFVWMxMTER740xHZadUVJSIsdx3NeAAQMuxhABAEAX6NFFKDU1VXFxcR1mfxoaGjrMEp0xb948BYNB93Xo0KGLMVQAANAFenQRSkhIUFZWljZu3BixfOPGjRo3btw5P+PxeNS3b9+IFwAA6Jl69DlCkvTwww+roKBAo0aN0tixY/XCCy+opqZGP/3pT7t6aAAAoIv1+CL0wx/+UMeOHdOTTz6puro6ZWZmav369Ro4cGBXDw0AAHSxHn8foW+L+wgBAND9dHb/3aPPEQIAADgfihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGv1+PsIfVtn7i7Aw1cBAOg+zuy3v+ouQRShr3DixAlJ4uGrAAB0QydOnJDjOF+6nhsqfoVwOKwjR44oKSnpS59YD6B7CoVCGjBggA4dOsQNU4EexhijEydOyO/3Kzb2y88EoggBsBZ3jgfAydIAAMBaFCEAAGAtihAAa3k8Hj3xxBPyeDxdPRQAXYRzhAAAgLWYEQIAANaiCAEAAGtRhAAAgLUoQgCsc+DAAcXExKiqqqqrhwKgi3GyNADrtLe36+jRo0pNTVWvXjxpCLAZRQiAVVpbW5WQkNDVwwBwieDQGIBuLTs7W4WFhSosLNTll1+ufv366ec//7n7xOlBgwbpqaee0n333SfHcTRjxoxzHhrbtWuXcnNz1bdvXyUlJWn8+PH69NNP3fUvvviihg0bpt69e+u6667T8uXLL/amArgAmBMG0O29/PLLuv/++7Vt2zb9+c9/1syZMzVw4EDNmDFDkrRo0SL94he/0M9//vNzfr62tlY333yzsrOz9fbbb6tv377605/+pNOnT0uSfvvb3+qJJ57QsmXLNHLkSH3wwQeaMWOGEhMTde+991607QQQfRwaA9CtZWdnq6GhQbt27VJMTIwk6fHHH9frr7+u3bt3a9CgQRo5cqTWrl3rfubAgQPKyMjQBx98oBEjRmj+/PkqLS3V3r17FR8f3+E3rr76aj377LO655573GVPPfWU1q9fry1btlz4jQRwwXBoDEC3N2bMGLcESdLYsWO1b98+tbe3S5JGjRp13s9XVVVp/Pjx5yxBR48e1aFDh3T//ffrsssuc19PPfVUxKEzAN0Th8YA9HiJiYnnXe/1er90XTgclvTF4bHRo0dHrIuLi/v2gwPQpShCALq9rVu3dng/ZMiQTheV7373u3r55ZfV1tbWYVYoPT1d/fv311/+8hdNnz49amMGcGng0BiAbu/QoUN6+OGHtXfvXq1atUpLly7VQw891OnPFxYWKhQK6e6779af//xn7du3T//5n/+pvXv3SpIWLFigkpIS/du//Zs+/vhj7dy5Uy+++KKWLFlyoTYJwEXCjBCAbu/HP/6xmpqadMMNNyguLk6zZs3SzJkzO/35fv366e2339YjjzyiCRMmKC4uTiNGjNCNN94oSfqnf/on9enTR4sWLdKjjz6qxMREDR8+XEVFRRdoiwBcLFw1BqBby87O1ogRI/Tcc8919VAAdEMcGgMAANaiCAEAAGtxaAwAAFiLGSEAAGAtihAAALAWRQgAAFiLIgQAAKxFEQIAANaiCAEAAGtRhAAAgLUoQgAAwFoUIQAAYK3/B5TWVJ380ecEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['price']].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\">From the boxplots, there is evidence that there are outliers for the durtaion as well as the price variable. To get a better visualisation of the distribution, we plot histograms. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "8MaKYdLfmmCE",
    "outputId": "5b5d8926-f82a-4aa6-8a68-fd117e782c56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Redmi\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['duration'], bins= 50, kde=True)\n",
    "plt.title('Histogram and Kernel Density Plot of Duration')\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Redmi\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['price'], bins=50, kde=True)\n",
    "plt.title('Histogram and Kernel Density Plot of Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\">From the histograms, the distribution of duration  is skewed to the right. The distribution of days left is normally distributed, and the distribution of price is also skewed to the right. </font>\n",
    "\n",
    "<font size = \"3\"> Next, scatter plots can be used to visualise any relationship between the numerical variables<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "mFdO2GW7oDhD",
    "outputId": "50f9a651-0723-4394-c329-b12c1ea92001"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['duration', 'price']].plot(kind='scatter', x='duration', y='price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be positive linera relationship between the price and duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\"> 3. Data Processing </font>\n",
    "<font size = \"3\"><li>Removing all outliers from duration and price variable using standard deviation</li>\n",
    "<li>Transforming the duration variable using log transformation and transforming the price variable using boxcox transformation </li>\n",
    "<li>Standardising the scale of all the numerical variable </li></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration has outliers: True\n",
      "722 row will be removed from \n",
      "\n",
      "price has outliers: True\n",
      "595 row will be removed from \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## removing outliers \n",
    "def three_sd_range(series):\n",
    "    mean = series.mean()\n",
    "    sd = series.std()\n",
    "    low = mean - 3*sd\n",
    "    high = mean + 3*sd\n",
    "\n",
    "    return (low, high)\n",
    "\n",
    "for col_name in ['duration', 'price']:\n",
    "    lower, upper = three_sd_range(df[col_name])\n",
    "    has_outlier = (df[col_name].min() < lower) or (df[col_name].max() > upper)\n",
    "    print(col_name + ' has outliers: ' + str(has_outlier))\n",
    "\n",
    "    if has_outlier:\n",
    "        # Remove outliers\n",
    "        curr_length = df[col_name].count()\n",
    "        df = df[ (df[col_name]>=lower) & (df[col_name]<=upper)]\n",
    "        new_length = df[col_name].count()\n",
    "        row_removed = curr_length - new_length\n",
    "        print(str(row_removed) + ' row will be removed from ')\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## log transforming the right skewed data: duration and price\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sqrt_transformed_data = np.sqrt(df['duration'])\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['duration'], bins=50, edgecolor='black')\n",
    "plt.title('Original Data (Right-Skewed)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sqrt_transformed_data, bins=50, edgecolor='black')\n",
    "plt.title('Sqrt-Transformed Data')\n",
    "plt.show()\n",
    "df['duration_sqrt'] = np.sqrt(df['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import boxcox\n",
    "boxcox_transformed_data, _ = boxcox(df['price'])\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['price'], bins=50, edgecolor='black')\n",
    "plt.title('Original Data (Right-Skewed)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(boxcox_transformed_data, bins=50, edgecolor='black')\n",
    "plt.title('Boxcox-Transformed Data')\n",
    "plt.show()\n",
    "df['price_boxcox'] = boxcox_transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "      <th>duration_sqrt_scaled</th>\n",
       "      <th>price_boxcox_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5953.0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5953.0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5956.0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.497464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>-1.710632</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline   flight source_city departure_time stops   arrival_time  \\\n",
       "0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
       "1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
       "2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
       "3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
       "4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
       "\n",
       "  destination_city    class  duration  days_left   price  \\\n",
       "0           Mumbai  Economy      2.17        1.0  5953.0   \n",
       "1           Mumbai  Economy      2.33        1.0  5953.0   \n",
       "2           Mumbai  Economy      2.17        1.0  5956.0   \n",
       "3           Mumbai  Economy      2.25        1.0  5955.0   \n",
       "4           Mumbai  Economy      2.33        1.0  5955.0   \n",
       "\n",
       "   duration_sqrt_scaled  price_boxcox_scaled  \n",
       "0             -1.735912            -0.498010  \n",
       "1             -1.685797            -0.498010  \n",
       "2             -1.735912            -0.497464  \n",
       "3             -1.710632            -0.497646  \n",
       "4             -1.685797            -0.497646  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "variables = ['duration_sqrt', 'price_boxcox']\n",
    "x = df[variables]\n",
    "x = StandardScaler().fit_transform(x)\n",
    "x = pd.DataFrame(x, columns=[f'{col}_scaled' for col in variables])\n",
    "df  = pd.concat([df, x], axis=1)\n",
    "df = df.drop('duration_sqrt', axis = 1)\n",
    "df = df.drop('price_boxcox', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "       40., 41., 42., 43., 44., 45., 46., 47., 48., 49.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['days_left'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,7,14,21,28,35,42,50]\n",
    "df['days_left_binned'] = pd.cut(df['days_left'], bins=bins, labels=False, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>days_left_binned</th>\n",
       "      <th>duration_sqrt_scaled</th>\n",
       "      <th>price_boxcox_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.497464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.710632</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline   flight source_city departure_time stops   arrival_time  \\\n",
       "0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
       "1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
       "2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
       "3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
       "4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
       "\n",
       "  destination_city    class  days_left_binned  duration_sqrt_scaled  \\\n",
       "0           Mumbai  Economy                 0             -1.735912   \n",
       "1           Mumbai  Economy                 0             -1.685797   \n",
       "2           Mumbai  Economy                 0             -1.735912   \n",
       "3           Mumbai  Economy                 0             -1.710632   \n",
       "4           Mumbai  Economy                 0             -1.685797   \n",
       "\n",
       "   price_boxcox_scaled  \n",
       "0            -0.498010  \n",
       "1            -0.498010  \n",
       "2            -0.497464  \n",
       "3            -0.497646  \n",
       "4            -0.497646  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_move = 'days_left_binned'\n",
    "moved_column = df.pop(column_to_move)\n",
    "df.insert(10, column_to_move, moved_column)\n",
    "df = df.drop(\"duration\", axis=1)\n",
    "df = df.drop(\"days_left\", axis=1)\n",
    "df = df.drop(\"price\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "#storing the data frame so that it can be used across all notebooks\n",
    "%store df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>days_left_binned</th>\n",
       "      <th>duration_sqrt_scaled</th>\n",
       "      <th>price_boxcox_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.497464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.710632</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298831</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-828</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Business</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>1.493494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298832</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-824</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Night</td>\n",
       "      <td>one</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Business</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.087181</td>\n",
       "      <td>1.555722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298833</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-826</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>one</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Business</td>\n",
       "      <td>3</td>\n",
       "      <td>0.373988</td>\n",
       "      <td>1.570295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298834</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-822</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Morning</td>\n",
       "      <td>one</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Business</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.148929</td>\n",
       "      <td>1.587833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298835</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-826</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>one</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Business</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>1.587833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297527 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         airline   flight source_city departure_time stops   arrival_time  \\\n",
       "0       SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
       "1       SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
       "2        AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
       "3        Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
       "4        Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
       "...          ...      ...         ...            ...   ...            ...   \n",
       "298831   Vistara   UK-828     Chennai  Early_Morning   one          Night   \n",
       "298832   Vistara   UK-824     Chennai          Night   one      Afternoon   \n",
       "298833   Vistara   UK-826     Chennai      Afternoon   one  Early_Morning   \n",
       "298834   Vistara   UK-822     Chennai        Morning   one  Early_Morning   \n",
       "298835   Vistara   UK-826     Chennai      Afternoon   one      Afternoon   \n",
       "\n",
       "       destination_city     class  days_left_binned  duration_sqrt_scaled  \\\n",
       "0                Mumbai   Economy                 0             -1.735912   \n",
       "1                Mumbai   Economy                 0             -1.685797   \n",
       "2                Mumbai   Economy                 0             -1.735912   \n",
       "3                Mumbai   Economy                 0             -1.710632   \n",
       "4                Mumbai   Economy                 0             -1.685797   \n",
       "...                 ...       ...               ...                   ...   \n",
       "298831        Hyderabad  Business                 3             -0.137069   \n",
       "298832        Hyderabad  Business                 3             -0.087181   \n",
       "298833        Hyderabad  Business                 3              0.373988   \n",
       "298834        Hyderabad  Business                 3             -0.148929   \n",
       "298835        Hyderabad  Business                 3             -0.137069   \n",
       "\n",
       "        price_boxcox_scaled  \n",
       "0                 -0.498010  \n",
       "1                 -0.498010  \n",
       "2                 -0.497464  \n",
       "3                 -0.497646  \n",
       "4                 -0.497646  \n",
       "...                     ...  \n",
       "298831             1.493494  \n",
       "298832             1.555722  \n",
       "298833             1.570295  \n",
       "298834             1.587833  \n",
       "298835             1.587833  \n",
       "\n",
       "[297527 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "df = pd.read_csv(\"/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'airline', 'source_city', 'departure_time', 'stops',\n",
      "       'arrival_time', 'destination_city', 'class', 'days_left_binned',\n",
      "       'duration_sqrt', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>days_left_binned</th>\n",
       "      <th>duration_sqrt</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.368800</td>\n",
       "      <td>-1.732372</td>\n",
       "      <td>0.198274</td>\n",
       "      <td>-2.491100</td>\n",
       "      <td>0.236474</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>-0.674351</td>\n",
       "      <td>2.375914</td>\n",
       "      <td>-1.742522</td>\n",
       "      <td>5953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.368800</td>\n",
       "      <td>-1.732372</td>\n",
       "      <td>-0.298600</td>\n",
       "      <td>-2.491100</td>\n",
       "      <td>0.445839</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>-0.674351</td>\n",
       "      <td>2.375914</td>\n",
       "      <td>-1.691940</td>\n",
       "      <td>5953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.562898</td>\n",
       "      <td>-1.732372</td>\n",
       "      <td>-0.298600</td>\n",
       "      <td>-2.491100</td>\n",
       "      <td>-2.002790</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>-0.674351</td>\n",
       "      <td>2.375914</td>\n",
       "      <td>-1.742522</td>\n",
       "      <td>5956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>-1.732372</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>-2.491100</td>\n",
       "      <td>-0.820969</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>-0.674351</td>\n",
       "      <td>2.375914</td>\n",
       "      <td>-1.717006</td>\n",
       "      <td>5955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>-1.732372</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>-2.491100</td>\n",
       "      <td>0.445839</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>-0.674351</td>\n",
       "      <td>2.375914</td>\n",
       "      <td>-1.691940</td>\n",
       "      <td>5955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295684</th>\n",
       "      <td>297916</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>0.433789</td>\n",
       "      <td>0.753675</td>\n",
       "      <td>-0.305768</td>\n",
       "      <td>1.482907</td>\n",
       "      <td>-0.743546</td>\n",
       "      <td>-0.128743</td>\n",
       "      <td>55377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295685</th>\n",
       "      <td>297917</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>-1.671408</td>\n",
       "      <td>0.433789</td>\n",
       "      <td>0.236474</td>\n",
       "      <td>-0.305768</td>\n",
       "      <td>1.482907</td>\n",
       "      <td>-0.743546</td>\n",
       "      <td>-0.078388</td>\n",
       "      <td>55377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295686</th>\n",
       "      <td>297918</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>-0.298600</td>\n",
       "      <td>0.433789</td>\n",
       "      <td>0.236474</td>\n",
       "      <td>-0.305768</td>\n",
       "      <td>1.482907</td>\n",
       "      <td>-0.743546</td>\n",
       "      <td>0.387089</td>\n",
       "      <td>55377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295687</th>\n",
       "      <td>297919</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>-0.298600</td>\n",
       "      <td>0.433789</td>\n",
       "      <td>0.753675</td>\n",
       "      <td>-0.305768</td>\n",
       "      <td>1.482907</td>\n",
       "      <td>-0.743546</td>\n",
       "      <td>-0.140713</td>\n",
       "      <td>55377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295688</th>\n",
       "      <td>297920</td>\n",
       "      <td>0.885018</td>\n",
       "      <td>1.074924</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>0.433789</td>\n",
       "      <td>0.753675</td>\n",
       "      <td>-0.305768</td>\n",
       "      <td>1.482907</td>\n",
       "      <td>-0.743546</td>\n",
       "      <td>-0.128743</td>\n",
       "      <td>55377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295689 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   airline  source_city  departure_time     stops  \\\n",
       "0                0 -1.368800    -1.732372        0.198274 -2.491100   \n",
       "1                1 -1.368800    -1.732372       -0.298600 -2.491100   \n",
       "2                2 -1.562898    -1.732372       -0.298600 -2.491100   \n",
       "3                3  0.885018    -1.732372        0.469739 -2.491100   \n",
       "4                4  0.885018    -1.732372        0.469739 -2.491100   \n",
       "...            ...       ...          ...             ...       ...   \n",
       "295684      297916  0.885018     1.074924        0.469739  0.433789   \n",
       "295685      297917  0.885018     1.074924       -1.671408  0.433789   \n",
       "295686      297918  0.885018     1.074924       -0.298600  0.433789   \n",
       "295687      297919  0.885018     1.074924       -0.298600  0.433789   \n",
       "295688      297920  0.885018     1.074924        0.469739  0.433789   \n",
       "\n",
       "        arrival_time  destination_city     class  days_left_binned  \\\n",
       "0           0.236474          0.370940 -0.674351          2.375914   \n",
       "1           0.445839          0.370940 -0.674351          2.375914   \n",
       "2          -2.002790          0.370940 -0.674351          2.375914   \n",
       "3          -0.820969          0.370940 -0.674351          2.375914   \n",
       "4           0.445839          0.370940 -0.674351          2.375914   \n",
       "...              ...               ...       ...               ...   \n",
       "295684      0.753675         -0.305768  1.482907         -0.743546   \n",
       "295685      0.236474         -0.305768  1.482907         -0.743546   \n",
       "295686      0.236474         -0.305768  1.482907         -0.743546   \n",
       "295687      0.753675         -0.305768  1.482907         -0.743546   \n",
       "295688      0.753675         -0.305768  1.482907         -0.743546   \n",
       "\n",
       "        duration_sqrt    price  \n",
       "0           -1.742522   5953.0  \n",
       "1           -1.691940   5953.0  \n",
       "2           -1.742522   5956.0  \n",
       "3           -1.717006   5955.0  \n",
       "4           -1.691940   5955.0  \n",
       "...               ...      ...  \n",
       "295684      -0.128743  55377.0  \n",
       "295685      -0.078388  55377.0  \n",
       "295686       0.387089  55377.0  \n",
       "295687      -0.140713  55377.0  \n",
       "295688      -0.128743  55377.0  \n",
       "\n",
       "[295689 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objective: Parameter specifies the objective function to be optimized during training. Since we performing regression, 'regression' is an appropriate choice.\n",
    "\n",
    "- Metric: This parameter specifies the evaluation metric to be used during training. 'rmse' (Root Mean Squared Error) is a common choice for regression tasks.\n",
    "\n",
    "- Num_leaves: This parameter controls the maximum number of leaves in each tree. Increasing num_leaves may improve the model's capacity to capture complex relationships in the data, but it also increases the risk of overfitting.\n",
    "\n",
    "- Learning_rate: This parameter controls the step size at each iteration during gradient boosting. A lower learning rate typically results in a more stable training process but may require more iterations to converge.\n",
    "\n",
    "- Feature_fraction: This parameter controls the fraction of features to be randomly sampled for each tree. It helps in reducing overfitting by introducing randomness into the model.\n",
    "\n",
    "- Bagging_fraction and bagging_freq: These parameters control bagging (bootstrap aggregation), which is another technique to reduce overfitting. bagging_fraction specifies the fraction of data to be used for each iteration, while bagging_freq specifies the frequency of bagging.\n",
    "\n",
    "- Verbose: This parameter controls the level of verbosity during training. Setting it to 0 suppresses all output, while higher values provide more information.\n",
    "\n",
    "- Early_stopping_rounds: This parameter enables early stopping, which allows training to stop if the performance on the validation set does not improve for a certain number of rounds (specified by this parameter). It helps prevent overfitting and reduces training time.\n",
    "\n",
    "These parameters provide a good starting point, but you may need to experiment with different values and potentially add more parameters to further optimize your model's performance on your specific dataset. Additionally, consider using techniques like cross-validation to fine-tune these parameters and assess the model's generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df_prepared.csv\")\n",
    "\n",
    "# Drop the unnecessary index column and the target column\n",
    "X = df.drop(['Unnamed: 0', 'price'], axis=1)  # Adjust the target column name here\n",
    "y = df['price']  # Adjust the target variable here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set LightGBM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 100,  # Change this value based on the best parameter\n",
    "    'learning_rate': 0.1,  # Change this value based on the best parameter\n",
    "    'feature_fraction': 1.0,  # Change this value based on the best parameter\n",
    "    'bagging_fraction': 0.9,  # Change this value based on the best parameter\n",
    "    'bagging_freq': 5,\n",
    "    'early_stopping_rounds': 10,  # Number of rounds for early stopping\n",
    "    'verbose': -1  # Suppress early stopping metric printing\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_test: (59138, 9)\n",
      "Size of y_pred: (88707,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of X_test:\", X_test.shape)\n",
    "print(\"Size of y_pred:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[train_data, test_data])\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions and Evaluate the Model\n",
    "- Calculate Root Mean Squared Error (RMSE)\n",
    "- Calculate R-squared Error\n",
    "- Calculate Mean Absolute Percentage Error (MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 6989.0550333750725\n",
      "Normalized RMSE: 0.057303306112974704\n",
      "R-squared: 0.9045101020392872\n",
      "Mean Absolute Percentage Error: 0.3366347652524351\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Maximum and minimum values of the target variable\n",
    "max_price = y_test.max()\n",
    "min_price = y_test.min()\n",
    "\n",
    "# Normalize RMSE\n",
    "normalized_rmse = rmse / (max_price - min_price)\n",
    "print('Normalized RMSE:', normalized_rmse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print('Mean Absolute Percentage Error:', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE): This metric measures the average deviation of the predicted values from the actual values. In the case, the RMSE is approximately 6989.05. Lower RMSE values indicate better model performance, as they represent smaller deviations between predicted and actual values. However, the interpretation of RMSE depends on the scale of the target variable. For example, if we are predicting flight prices in dollars, an RMSE of 6989.05 means, on average, your model's predictions are off by approximately $6989.05.\n",
    "\n",
    "R-squared (R): This metric represents the proportion of the variance in the dependent variable (target variable) that is predictable from the independent variables (features) in the model. R-squared values range from 0 to 1, where 1 indicates a perfect fit and 0 indicates that the model does not explain any of the variability of the response data around its mean. In this case, the R-squared value is approximately 0.9045, indicating that the model explains around 90.45% of the variance in the target variable.\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE): This metric measures the average percentage difference between the predicted and actual values. In the case, the MAPE is approximately 0.3366, which means, on average, the model's predictions have an error of around 33.66% relative to the actual values. MAPE is useful for understanding the magnitude of errors in percentage terms, especially when dealing with data with different scales.\n",
    "\n",
    "In summary, lower RMSE and MAPE values and higher R-squared values indicate better model performance. However, it's important to interpret these metrics in the context of your specific problem and the scale of your target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 6989.0550333750725\n",
      "Normalized RMSE: 0.057303306112974704\n",
      "R-squared: 0.9045101020392872\n",
      "Mean Absolute Percentage Error: 0.3366347652524351\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df_prepared.csv\")\n",
    "\n",
    "# Drop the unnecessary index column and the target column\n",
    "X = df.drop(['Unnamed: 0', 'price'], axis=1)  # Adjust the target column name here\n",
    "y = df['price']  # Adjust the target variable here\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 100,  # Change this value based on the best parameter\n",
    "    'learning_rate': 0.1,  # Change this value based on the best parameter\n",
    "    'feature_fraction': 1.0,  # Change this value based on the best parameter\n",
    "    'bagging_fraction': 0.9,  # Change this value based on the best parameter\n",
    "    'bagging_freq': 5,\n",
    "    'early_stopping_rounds': 10,  # Number of rounds for early stopping\n",
    "    'verbose': -1  # Suppress early stopping metric printing\n",
    "}\n",
    "\n",
    "# Create LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[train_data, test_data])\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Maximum and minimum values of the target variable\n",
    "max_price = y_test.max()\n",
    "min_price = y_test.min()\n",
    "\n",
    "# Normalize RMSE\n",
    "normalized_rmse = rmse / (max_price - min_price)\n",
    "print('Normalized RMSE:', normalized_rmse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print('Mean Absolute Percentage Error:', mape)\n",
    "\n",
    "# Plot feature importance\n",
    "lgb.plot_importance(bst, max_num_features=15) # Change max_num_features to display desired number of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Root Mean Squared Error (RMSE)\n",
    "RMSE is a commonly used metric in regression tasks to evaluate the performance of predictive models. It provides a measure of how well the model's predictions match the actual target values. Let's break down what RMSE represents and how to interpret its value:\n",
    "\n",
    "Root Mean Squared Error (RMSE): RMSE is a measure of the average magnitude of the errors between predicted and actual values in the units of the target variable. It's calculated as the square root of the mean of the squared differences between predicted and actual values.\n",
    "\n",
    "Interpretation:\n",
    "Lower RMSE: A lower RMSE value indicates better model performance. It means that, on average, the model's predictions are closer to the actual values.\n",
    "Higher RMSE: Conversely, a higher RMSE value suggests poorer model performance. It means that, on average, the model's predictions are further away from the actual values.\n",
    "\n",
    "Result:\n",
    "The current RMSE value is 7205.25, it means that, on average, the model's predictions are approximately 7205.25 units (in the same scale as the target variable) away from the actual target values.\n",
    "\n",
    "Evaluation:\n",
    "Assess the RMSE value in the context of your specific problem and domain knowledge to determine whether the model's performance is satisfactory or requires further improvement.\n",
    "In summary, RMSE provides a useful metric for evaluating the accuracy of regression models, with lower values indicating better performance. It's important to understand and interpret RMSE to assess the effectiveness of predictive models accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To improve the RMSE for LightGBM model, we can use several strategies\n",
    "\n",
    "- Hyperparameter Tuning: Use GridSearchCV to search for the best combination of hyperparameters.\n",
    "\n",
    "- Feature Engineering: Create new features and transform existing ones to capture additional information from the data.\n",
    "\n",
    "- Early Stopping: Implement early stopping to prevent overfitting and improve training efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for LightGBM involves finding the optimal values for various parameters that control the training process of the LightGBM model. These parameters can significantly affect the performance and generalization ability of the model. Here's a brief explanation of some key hyperparameters for LightGBM:\n",
    "\n",
    "Learning Rate (or Shrinkage Rate): Learning rate controls the step size during the optimization process. A smaller learning rate can lead to slower convergence but may result in better performance by allowing the model to explore the parameter space more thoroughly.\n",
    "\n",
    "Number of Leaves (num_leaves): This parameter determines the maximum number of leaves in each tree. Increasing the number of leaves can make the model more complex and potentially prone to overfitting, while decreasing it can lead to underfitting.\n",
    "\n",
    "Maximum Depth (max_depth): Maximum depth specifies the maximum depth of each tree. Deeper trees can capture more complex patterns in the data but may also overfit. Limiting the depth can help control overfitting.\n",
    "\n",
    "Minimum Child Samples (min_child_samples): This parameter specifies the minimum number of samples required to create a new split in a node. It can help prevent overfitting by ensuring that each split is based on a sufficient amount of data.\n",
    "\n",
    "Subsample (subsample): Subsample controls the fraction of samples used for training each tree. It can be used to introduce randomness and reduce overfitting by training on a subset of the data.\n",
    "\n",
    "Feature Fraction (colsample_bytree): This parameter specifies the fraction of features to consider when building each tree. It can be used to introduce additional randomness and reduce overfitting by training on a subset of features.\n",
    "\n",
    "Hyperparameter tuning involves systematically searching through different combinations of these parameters to find the combination that results in the best model performance, typically measured using a validation metric like RMSE (Root Mean Squared Error) for regression tasks.\n",
    "\n",
    "Grid search and random search are common techniques used for hyperparameter tuning. Grid search exhaustively searches through a predefined grid of hyperparameter values, while random search samples hyperparameter values randomly from a predefined range. Both methods evaluate the performance of each combination using cross-validation and select the best set of hyperparameters based on the validation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform hyperparameter tuning using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   1.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 206982, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20672.999411\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 15, 'num_leaves': 100, 'reg_alpha': 0}\n",
      "Best RMSE: 7003.829490636005\n",
      "Root Mean Squared Error on Test Set: 7038.530436952809\n",
      "Root Mean Squared Error: 7038.530436952809\n",
      "Normalized RMSE: 0.057708955257635815\n",
      "R-squared: 0.9032400306247649\n",
      "Mean Absolute Percentage Error: 0.3340792890480289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Redmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed data\n",
    "df = pd.read_csv(\"/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df_prepared.csv\")\n",
    "\n",
    "# Remove the 'Unnamed: 0' column\n",
    "X = df.drop(columns=['Unnamed: 0', 'price'])\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'num_leaves': [20, 40, 60, 80, 100],\n",
    "    'min_child_samples': [5, 10, 15],\n",
    "    'max_depth': [-1, 5, 10, 20],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.01, 0.03]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM regressor\n",
    "lgb_model = lgb.LGBMRegressor()\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best RMSE score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)\n",
    "\n",
    "# Predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error on Test Set:\", test_rmse)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Maximum and minimum values of the target variable\n",
    "max_price = y_test.max()\n",
    "min_price = y_test.min()\n",
    "\n",
    "# Normalize RMSE\n",
    "normalized_rmse = rmse / (max_price - min_price)\n",
    "print('Normalized RMSE:', normalized_rmse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print('Mean Absolute Percentage Error:', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LightGBM] [Info] Total Bins 305\n",
    "[LightGBM] [Info] Number of data points in the train set: 206982, number of used features: 9\n",
    "[LightGBM] [Info] Start training from score 20672.999411\n",
    "Best Parameters: {'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 15, 'num_leaves': 100, 'reg_alpha': 0}\n",
    "Best RMSE: 7003.829490636005\n",
    "Root Mean Squared Error on Test Set: 7038.530436952809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of Hyperparameter Tuning with LightGBM\n",
    "\n",
    "Best Parameters:\n",
    "#### Learning Rate: 0.1\n",
    "A learning rate of 0.1 indicates that each step during training adjusts the model parameters by 10% of the gradient's value, helping to prevent overshooting the optimal solution.\n",
    "\n",
    "#### Maximum Depth: Unlimited (-1)\n",
    "An unlimited maximum depth allows the trees to grow until all leaves are pure, providing the model with more flexibility to capture complex relationships in the data.\n",
    "\n",
    "#### Minimum Child Samples: 15\n",
    "This parameter sets the minimum number of samples required to split an internal node. A higher value helps prevent overfitting by avoiding splits that result in nodes containing too few samples.\n",
    "\n",
    "#### Number of Leaves: 100\n",
    "The model will have 100 leaves in each tree. Increasing this value can make the model more expressive, potentially capturing finer-grained patterns in the data, but it also increases the risk of overfitting.\n",
    "\n",
    "#### Regularization Alpha: 0\n",
    "No regularization penalty is applied to the model's weights. Regularization helps prevent overfitting by penalizing large parameter values, but in this case, no penalty is used.\n",
    "\n",
    "#### Best Root Mean Squared Error (RMSE):\n",
    "Training Set: 7003.83\n",
    "The RMSE on the training set indicates the average deviation of the predicted prices from the actual prices in the training data. A lower RMSE suggests that the model's predictions are closer to the actual prices, indicating better performance.\n",
    "\n",
    "#### Root Mean Squared Error on Test Set:\n",
    "Test Set: 7038.53\n",
    "The RMSE on the test set measures the average deviation of the predicted prices from the actual prices in the unseen test data. This metric provides an estimate of the model's performance on new, unseen data.\n",
    "\n",
    "#### Additional Metrics:\n",
    "Normalized RMSE: 0.0577\n",
    "Normalized RMSE scales the RMSE by the range of the target variable. It provides a standardized measure of prediction error relative to the variation in the target variable.\n",
    "\n",
    "#### R-squared (Coefficient of Determination): 0.903\n",
    "R-squared measures the proportion of variance in the target variable that is explained by the model. A higher R-squared value indicates that the model explains more of the variance in the target variable.\n",
    "\n",
    "#### Mean Absolute Percentage Error (MAPE): 0.334\n",
    "MAPE measures the average percentage deviation of the predicted prices from the actual prices. It provides insight into the magnitude of prediction errors relative to the actual prices.\n",
    "\n",
    "#### Interpretation:\n",
    "- The model achieved relatively good performance with an RMSE of approximately 7038.53 on the test set, indicating that, on average, the model's predictions deviate by around $7038.53 from the actual prices.\n",
    "- The R-squared value of approximately 0.903 indicates that the model explains about 90.3% of the variance in the target variable, suggesting a good fit to the data.\n",
    "- The MAPE of approximately 0.334 indicates that, on average, the model's predictions deviate by about 33.4% from the actual prices, which may be acceptable depending on the specific application.\n",
    "- Overall, the model's performance is satisfactory, but further optimization and evaluation may be necessary depending on the specific requirements and context of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=100, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=15, num_leaves=60, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=5, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=60, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.1, max_depth=5, min_child_samples=5, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=10, num_leaves=100, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=-1, min_child_samples=5, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=15, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=15, num_leaves=100, reg_alpha=0; total time=   0.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=5, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=10, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=60, reg_alpha=0.01; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=20, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=5, num_leaves=20, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.05, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=60, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_child_samples=5, num_leaves=20, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.2, max_depth=-1, min_child_samples=10, num_leaves=20, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=10, min_child_samples=15, num_leaves=80, reg_alpha=0.03; total time=   0.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=10, num_leaves=80, reg_alpha=0; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.05, max_depth=-1, min_child_samples=10, num_leaves=40, reg_alpha=0; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[CV] END learning_rate=0.1, max_depth=10, min_child_samples=5, num_leaves=80, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20668.289416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165585, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20652.327294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20677.698211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20685.098837\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 165586, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20681.583141\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END learning_rate=0.2, max_depth=5, min_child_samples=15, num_leaves=100, reg_alpha=0.01; total time=   0.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 206982, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 20672.999411\n",
      "Best Parameters: {'reg_alpha': 0, 'num_leaves': 100, 'min_child_samples': 15, 'max_depth': 20, 'learning_rate': 0.1}\n",
      "Best RMSE: 7004.211558367038\n",
      "Root Mean Squared Error on Test Set: 7041.345833350922\n",
      "Root Mean Squared Error: 7041.345833350922\n",
      "Normalized RMSE: 0.05773203871038586\n",
      "R-squared: 0.9031626076016126\n",
      "Mean Absolute Percentage Error: 0.3345070349902675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Redmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed data\n",
    "df = pd.read_csv(\"/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df_prepared.csv\")\n",
    "\n",
    "# Remove the 'Unnamed: 0' column\n",
    "X = df.drop(columns=['Unnamed: 0', 'price'])\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'num_leaves': [20, 40, 60, 80, 100],\n",
    "    'min_child_samples': [5, 10, 15],\n",
    "    'max_depth': [-1, 5, 10, 20],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.01, 0.03]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM regressor\n",
    "lgb_model = lgb.LGBMRegressor()\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(estimator=lgb_model, param_distributions=param_grid, n_iter=100, cv=5, scoring='neg_root_mean_squared_error', random_state=42, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best RMSE score\n",
    "best_params = random_search.best_params_\n",
    "best_score = -random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)\n",
    "\n",
    "# Predictions on the test set using the best model from RandomizedSearchCV\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Calculate RMSE on test set\n",
    "test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error on Test Set:\", test_rmse)\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Maximum and minimum values of the target variable\n",
    "max_price = y_test.max()\n",
    "min_price = y_test.min()\n",
    "\n",
    "# Normalize RMSE\n",
    "normalized_rmse = rmse / (max_price - min_price)\n",
    "print('Normalized RMSE:', normalized_rmse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "\n",
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print('Mean Absolute Percentage Error:', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LightGBM] [Info] Total Bins 305\n",
    "[LightGBM] [Info] Number of data points in the train set: 206982, number of used features: 9\n",
    "[LightGBM] [Info] Start training from score 20672.999411\n",
    "Best Parameters: {'reg_alpha': 0, 'num_leaves': 100, 'min_child_samples': 15, 'max_depth': 20, 'learning_rate': 0.1}\n",
    "Best RMSE: 7004.211558367038\n",
    "Root Mean Squared Error on Test Set: 7041.345833350922\n",
    "Root Mean Squared Error: 7041.345833350922\n",
    "Normalized RMSE: 0.05773203871038586\n",
    "R-squared: 0.9031626076016126\n",
    "Mean Absolute Percentage Error: 0.3345070349902675"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that the best hyperparameters for the LightGBM model, as determined by the RandomizedSearchCV, are as follows:\n",
    "\n",
    "- Learning Rate: 0.1\n",
    "- Max Depth: 20\n",
    "- Minimum Child Samples: 15\n",
    "- Number of Leaves: 100\n",
    "- Regularization Alpha (reg_alpha): 0\n",
    "\n",
    "The best Root Mean Squared Error (RMSE) achieved on the training data during cross-validation is approximately 7004.21. When applying this model to the test set, the RMSE obtained is around 7041.35. RMSE measures the average deviation of the predicted values from the actual values, with lower values indicating better performance.\n",
    "\n",
    "The R-squared value of approximately 0.903 indicates that the model explains around 90.3% of the variance in the target variable. R-squared values range from 0 to 1, where higher values signify better model fit to the data.\n",
    "\n",
    "The Normalized RMSE, which is the RMSE normalized by the range of the target variable, is approximately 0.0577. This metric provides a standardized measure of model performance relative to the scale of the target variable.\n",
    "\n",
    "Finally, the Mean Absolute Percentage Error (MAPE) is approximately 0.3345, indicating that, on average, the model's predictions deviate by around 33.45% from the actual values. MAPE measures the accuracy of the model's predictions as a percentage of the actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAIhCAYAAADdH1JpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXxU1fn48c+9s0+WSUJIQgBBkFVAkbrBV60bakH0V622WEStWlvBvXVp61IVN6pVXGutSxexm9ZaRK11Q0FxQWXf1yRkn8w+dzm/P24yMqxJCCTA8369aM29Z2aeuZncuc895zxHU0ophBBCCCGEEEJ0SXpnByCEEEIIIYQQYsckaRNCCCGEEEKILkySNiGEEEIIIYTowiRpE0IIIYQQQoguTJI2IYQQQgghhOjCJGkTQgghhBBCiC5MkjYhhBBCCCGE6MIkaRNCCCGEEEKILkySNiGEEEIIIYTowiRpE0KI/dgjjzyCpmkMGzas3c9RUVHB7bffzoIFCzousJ349re/zbe//e298lo707dvXzRNy/zLzc3l6KOP5oUXXtgrr//cc8+haRpr167NbGvvsZk2bRqvvPJKh8XWYu3atWiaxnPPPbfTdu+++27WsXS5XJSWlvK9732PJUuWtOq1br/9djRN64CohRBi3yNJmxBC7Mf+8Ic/ALBo0SI+/vjjdj1HRUUFd9xxx15L2rqSMWPGMHfuXObOnZtJoiZPnswTTzzRKfE8/vjjPP74421+3J5K2toTx9y5c3nnnXe48cYbeeuttxgzZgybNm3a5WMvvfRS5s6duxeiFEKIrkeSNiGE2E99+umnfPnll4wbNw6AZ555ppMj2vcUFBRwzDHHcMwxx3Duuecye/Zs8vPzefDBB3f4GMuySKVSeySeoUOHMnTo0D3y3HvDgAEDOOaYYzj++OO57rrrePDBB2loaNhpT108HgegV69eHHPMMXspUiGE6FokaRNCiP1US5J27733Mnr0aGbOnJm5AN7Spk2buPzyy+nduzder5fy8nLOPfdcNm/ezLvvvsuRRx4JwMUXX5wZ3nb77bcDOx6ud9FFF9G3b9+sbXfccQdHH300RUVF5Ofnc8QRR/DMM8+glGrzezv77LPp06cPtm1vs+/oo4/miCOOyPz8t7/9jaOPPppQKEQwGKRfv35ccsklbX5NcJK4QYMGsW7dOuCb4YH3338/d911FwcffDA+n4933nkHcBLnCRMmUFRUhN/vZ+TIkfz1r3/d5nnnzZvHmDFj8Pv9lJeXc/PNN2MYxjbttne8U6kUv/71rxkyZAh+v59u3bpx4okn8tFHHwGgaRqxWIznn38+8/vb8jmqqqr48Y9/TK9evfB6vRx88MHccccdmKaZ9ToVFRWcd9555OXlEQqFOP/886mqqmrXcWzRkoS1HM+WIZCff/455557LoWFhfTv3z9r39b+8pe/cOyxx5Kbm0tubi6HH374Njco/vvf/3LyySeTn59PMBhkzJgxvP3221ltampqMn8HPp+P7t27M2bMGP773//u1nsUQoiO4O7sAIQQQnS8RCLBiy++yJFHHsmwYcO45JJLuPTSS/nb3/7G5MmTM+02bdrEkUceiWEY3HLLLYwYMYK6ujreeOMNGhoaOOKII3j22We5+OKL+eUvf5nptevVq1ebY1q7di0//vGPOeiggwAnUZk6dSqbNm3i1ltvbdNzXXLJJZx11ln873//45RTTslsX7p0KZ988gmPPPIIAHPnzuX888/n/PPP5/bbb8fv97Nu3Tr+97//tTl+AMMwWLduHd27d8/a/sgjjzBw4ECmT59Ofn4+AwYM4J133uH000/n6KOP5sknnyQUCjFz5kzOP/984vE4F110EQCLFy/m5JNPpm/fvjz33HMEg0Eef/xx/vKXv+wyHtM0OeOMM/jggw+45pprOOmkkzBNk3nz5rF+/XpGjx7N3LlzOemkkzjxxBP51a9+BUB+fj7gJGxHHXUUuq5z66230r9/f+bOnctdd93F2rVrefbZZwHn83TKKadQUVHBPffcw8CBA/nPf/7D+eef367j2GLlypUA2xzP7373u3z/+9/niiuuIBaL7fDxt956K3feeSff/e53uf766wmFQixcuDCTBAL86U9/4sILL+Sss87i+eefx+Px8NRTT3HaaafxxhtvcPLJJwMwadIkPv/8c+6++24GDhxIY2Mjn3/+OXV1dbv1HoUQokMoIYQQ+50XXnhBAerJJ59USikViURUbm6uOu6447LaXXLJJcrj8ajFixfv8Lnmz5+vAPXss89us++EE05QJ5xwwjbbJ0+erPr06bPD57QsSxmGoX7961+rbt26Kdu2d/mcWzIMQ5WWlqqJEydmbf/5z3+uvF6vqq2tVUopNX36dAWoxsbGnT7f9vTp00d95zvfUYZhKMMw1Jo1a9TkyZMVoH72s58ppZRas2aNAlT//v1VOp3OevzgwYPVyJEjlWEYWdvHjx+vevTooSzLUkopdf7556tAIKCqqqoybUzTVIMHD1aAWrNmTWb71sem5ff89NNP7/S95OTkqMmTJ2+z/cc//rHKzc1V69aty9rectwWLVqklFLqiSeeUID617/+ldXusssu2+FnY0vvvPOOAtRLL72kDMNQ8Xhcvf/+++qQQw5RLpdLffnll0oppW677TYFqFtvvXWb52jZ12L16tXK5XKpCy64YIevG4vFVFFRkTrzzDOztluWpQ477DB11FFHZbbl5uaqa665ZqfvQwghOosMjxRCiP3QM888QyAQ4Pvf/z4Aubm5fO973+ODDz5gxYoVmXavv/46J554IkOGDNnjMbX0ioVCIVwuFx6Ph1tvvZW6ujqqq6vb9Fxut5sf/vCH/POf/yQcDgPOXLI//vGPnHXWWXTr1g0gM7TzvPPO469//WurCl5sadasWXg8HjweDwcffDB//etfmTp1KnfddVdWuwkTJuDxeDI/r1y5kqVLl3LBBRcATo9Yy7/vfOc7VFZWsmzZMgDeeecdTj75ZEpLSzOPd7lcrerFev311/H7/e0e7vnaa69x4oknUl5enhXjGWecAcB7772XiTEvL48JEyZkPX7ixIlter3zzz8fj8dDMBjk+OOPx7Is/v73vzNixIisduecc84un+utt97CsiyuvPLKHbb56KOPqK+vZ/LkyVnvz7ZtTj/9dObPn5/pyTvqqKN47rnnuOuuu5g3b952h6cKIURnkaRNCCH2MytXruT9999n3LhxKKVobGyksbGRc889F/imoiQ483jaM9SxrT755BPGjh0LwNNPP82HH37I/Pnz+cUvfgE4w+/a6pJLLiGZTDJz5kwA3njjDSorK7n44oszbY4//nheeeUVTNPkwgsvpFevXgwbNowXX3yxVa/xf//3f8yfP59PP/2UxYsX09jYyCOPPILX681q16NHj6yfN2/eDMANN9yQSfpa/v30pz8FoLa2FoC6ujrKysq2ee3tbdtaTU0N5eXl6Hr7vs43b97Mv//9721iPPTQQ7eJccuksi0xbum+++5j/vz5fP7556xfv57Vq1dz9tlnb9Nu6+O5PTU1NcDOh+q2/B7OPffcbd7jfffdh1KK+vp6AF566SUmT57M73//e4499liKioq48MILd3venhBCdASZ0yaEEPuZP/zhDyil+Pvf/87f//73bfY///zz3HXXXbhcLrp3787GjRvb/Vp+vz/T07Wllov9FjNnzsTj8fDaa6/h9/sz23enDP3QoUM56qijePbZZ/nxj3/Ms88+S3l5eSY5bHHWWWdx1llnkUqlmDdvHvfccw8TJ06kb9++HHvssTt9jVAoxLe+9a1dxrJ1gYzi4mIAbr75Zr773e9u9zGDBg0CoFu3bttNDFqTLHTv3p05c+Zg23a7Erfi4mJGjBjB3Xffvd395eXlmRg/+eSTdsW4pX79+rXreG5Pyzy4jRs30rt37+22afk9zJgxY4eVJ1uS0eLiYn7729/y29/+lvXr1/Pqq69y0003UV1dzezZs3cZjxBC7EmStAkhxH7Esiyef/55+vfvz+9///tt9r/22mv85je/4fXXX2f8+PGcccYZ/PGPf2TZsmWZJGJrPp8P2H5vWN++ffnb3/5GKpXKtKurq+Ojjz7KFLsA5yLc7Xbjcrky2xKJBH/84x936/1efPHF/OQnP2HOnDn8+9//5rrrrst6ja3fxwknnEBBQQFvvPEGX3zxxS6TtvYaNGgQAwYM4Msvv2TatGk7bXviiSfy6quvsnnz5kwCYVkWL7300i5f54wzzuDFF1/kueee2+kQSZ/Pt93f3/jx45k1axb9+/ensLBwpzH+9a9/5dVXX80aItmaYil7ytixY3G5XDzxxBM7/D2OGTOGgoICFi9ezJQpU1r93AcddBBTpkzh7bff5sMPP+yokIUQot0kaRNCiP3I66+/TkVFBffdd992S/EPGzaMRx99lGeeeYbx48fz61//mtdff53jjz+eW265heHDh9PY2Mjs2bO57rrrGDx4MP379ycQCPDnP/+ZIUOGkJubS3l5OeXl5UyaNImnnnqKH/7wh1x22WXU1dVx//33ZyVsAOPGjePBBx9k4sSJXH755dTV1TF9+vRMotdeP/jBD7juuuv4wQ9+QCqVylRkbHHrrbeyceNGTj75ZHr16kVjYyMPP/wwHo+HE044Ybdee1eeeuopzjjjDE477TQuuugievbsSX19PUuWLOHzzz/nb3/7GwC//OUvefXVVznppJO49dZbCQaDPPbYYzutmtjiBz/4Ac8++yxXXHEFy5Yt48QTT8S2bT7++GOGDBmSmdM4fPhw3n33Xf7973/To0cP8vLyGDRoEL/+9a956623GD16NFdddRWDBg0imUyydu1aZs2axZNPPkmvXr248MILeeihh7jwwgu5++67GTBgALNmzeKNN97Yo8dwZ/r27cstt9zCnXfeSSKR4Ac/+AGhUIjFixdTW1vLHXfcQW5uLjNmzGDy5MnU19dz7rnnUlJSQk1NDV9++SU1NTU88cQThMNhTjzxRCZOnMjgwYPJy8tj/vz5zJ49e4c9pUIIsVd1ciEUIYQQHejss89WXq9XVVdX77DN97//feV2uzPVCjds2KAuueQSVVZWpjwejyovL1fnnXee2rx5c+YxL774oho8eLDyeDwKULfddltm3/PPP6+GDBmi/H6/Gjp0qHrppZe2Wz3yD3/4gxo0aJDy+XyqX79+6p577lHPPPPMLisk7srEiRMVoMaMGbPNvtdee02dccYZqmfPnsrr9aqSkhL1ne98R33wwQe7fN4+ffqocePG7bRNS/XIBx54YLv7v/zyS3XeeeepkpIS5fF4VFlZmTrppJMyVT1bfPjhh+qYY45RPp9PlZWVqZ/97Gfqd7/7XauOTSKRULfeeqsaMGCA8nq9qlu3buqkk05SH330UabNggUL1JgxY1QwGFRA1nPU1NSoq666Sh188MHK4/GooqIiNWrUKPWLX/xCRaPRTLuNGzeqc845R+Xm5qq8vDx1zjnnqI8++qhN1SP/9re/7bRdS4XImpqaHe7b2gsvvKCOPPJI5ff7VW5urho5cuQ28bz33ntq3LhxqqioSHk8HtWzZ081bty4TDzJZFJdccUVasSIESo/P18FAgE1aNAgddttt6lYLLbTmIUQYm/QlGrHqqZCCCGEEEIIIfYKqR4phBBCCCGEEF2YJG1CCCGEEEII0YVJ0iaEEEIIIYQQXZgkbUIIIYQQQgjRhUnSJoQQQgghhBBdmCRtQgghhBBCCNGFyeLae5lt21RUVJCXl4emaZ0djhBCCCGEEKKTKKWIRCKUl5ej6zvuT5OkbS+rqKigd+/enR2GEEIIIYQQoovYsGEDvXr12uF+Sdr2sry8PMD5xeTn53dyNEIIIYQQQojO0tTURO/evTM5wo5I0raXtQyJzM/Pl6RNCCGEEEIIsctpU1KIRAghhBBCCCG6MEnahBBCCCGEEKILk6RNCCGEEEIIIbowSdqEEEIIIYQQoguTpE0IIYQQQgghujBJ2oQQQgghhBCiC5OkTQghhBBCCCG6MEnahBBCCCGEEKILk6RNCCGEEEIIIbowSdqEEEIIIYQQoguTpE0IIYQQQgghujBJ2oQQQgghhBCiC5OkTQghhBBCCCG6MEnahBBCCCGEEKILk6RNCCGEEEIIIbowSdqEEEIIIYQQoguTpE0IIYQQQgix3zNNkzVr1nR2GO0iSZsQQgghhBBivzZnzhxGjRrFKaecQjKZ7Oxw2kySNiGEEEIIIcR+qbKykkmTJnHcccfx1VdfsXr1ah544IHODqvNJGkTQgghhBBC7FcMw+DBBx9k0KBB/OlPf8psHzlyJKecckonRtY+7s4OQAghhBBCCCE6yjvvvMPUqVNZtGhRZlthYSF33303l19+OS6XqxOjax9J2oQQQgghhBD7vMrKSq699lpeeumlzDZN07j00kuZNm0axcXFnRjd7pGkTQghhBBCCLHPSyaT/Otf/8r8fOSRR/LYY49x5JFHdmJUHUPmtAkhhBBCCCH2eQcffDA33XQT3bp14+mnn2bevHn7RcIGnZy0vf/++5x55pmUl5ejaRqvvPJKZp9hGNx4440MHz6cnJwcysvLufDCC6moqMh6jlQqxdSpUykuLiYnJ4cJEyawcePGrDYNDQ1MmjSJUChEKBRi0qRJNDY2ZrVZv349Z555Jjk5ORQXF3PVVVeRTqez2nz99deccMIJBAIBevbsya9//WuUUh16TIQQQgghhBA7t379eq644gpisVjW9p///OcsX76cSy+9FF3ff/qnOvWdxGIxDjvsMB599NFt9sXjcT7//HN+9atf8fnnn/PPf/6T5cuXM2HChKx211xzDS+//DIzZ85kzpw5RKNRxo8fj2VZmTYTJ05kwYIFzJ49m9mzZ7NgwQImTZqU2W9ZFuPGjSMWizFnzhxmzpzJP/7xD66//vpMm6amJk499VTKy8uZP38+M2bMYPr06Tz44IN74MgIIYQQQgghtpZKpbj77rsZPHgwTz31FHfffXfW/kAgQFFRUSdFtwepLgJQL7/88k7bfPLJJwpQ69atU0op1djYqDwej5o5c2amzaZNm5Su62r27NlKKaUWL16sADVv3rxMm7lz5ypALV26VCml1KxZs5Su62rTpk2ZNi+++KLy+XwqHA4rpZR6/PHHVSgUUslkMtPmnnvuUeXl5cq27Va/z3A4rIDM8wohhBBCCCF27T//+Y865JBDFJD516tXL5VIJDo7tHZrbW6wT/UZhsNhNE2joKAAgM8++wzDMBg7dmymTXl5OcOGDeOjjz4CYO7cuYRCIY4++uhMm2OOOYZQKJTVZtiwYZSXl2fanHbaaaRSKT777LNMmxNOOAGfz5fVpqKigrVr1+4w5lQqRVNTU9Y/IYQQQgghROusXr2aCRMmMG7cOFauXAmAy+Xi6quv5uuvv8bv93dyhHvePpO0JZNJbrrpJiZOnEh+fj4AVVVVeL1eCgsLs9qWlpZSVVWVaVNSUrLN85WUlGS1KS0tzdpfWFiI1+vdaZuWn1vabM8999yTmUsXCoXo3bt3W962EEIIIYQQB6REIsHtt9/O0KFD+fe//53Zftxxx/H555/z29/+NtOZs7/bJ5I2wzD4/ve/j23bPP7447tsr5RC07TMz1v+d0e2Uc1FSLb32BY333wz4XA482/Dhg27jF8IIYQQQogDmWVZHH300dxxxx2kUikAevTowZ///Gfee+89RowY0ckR7l1dPmkzDIPzzjuPNWvW8NZbb2V62QDKyspIp9M0NDRkPaa6ujrTC1ZWVsbmzZu3ed6ampqsNlv3ljU0NGAYxk7bVFdXA2zTA7cln89Hfn5+1j8hhBBCCCHEjrlcLn74wx8C4Ha7uf7661m6dCkTJ07caYfJ/qpLJ20tCduKFSv473//S7du3bL2jxo1Co/Hw1tvvZXZVllZycKFCxk9ejQAxx57LOFwmE8++STT5uOPPyYcDme1WbhwIZWVlZk2b775Jj6fj1GjRmXavP/++1nLALz55puUl5fTt2/fDn/vQgghhBBCHChisRjRaDRr2zXXXMOPfvQjvvzyS6ZPn35Ad35oSnXeQmPRaDQzmXDkyJE8+OCDnHjiiRQVFVFeXs4555zD559/zmuvvZbVm1VUVITX6wXgJz/5Ca+99hrPPfccRUVF3HDDDdTV1fHZZ5/hcrkAOOOMM6ioqOCpp54C4PLLL6dPnz6ZsbGWZXH44YdTWlrKAw88QH19PRdddBFnn302M2bMAJwiKIMGDeKkk07illtuYcWKFVx00UXceuutWUsD7EpTUxOhUIhwOHxAf/CEEEIIIYRQSvHPf/6Ta6+9lnPOOYeHHnqos0Paq1qdG+zpMpY7884772SV7Gz5N3nyZLVmzZrt7gPUO++8k3mORCKhpkyZooqKilQgEFDjx49X69evz3qduro6dcEFF6i8vDyVl5enLrjgAtXQ0JDVZt26dWrcuHEqEAiooqIiNWXKlKzy/kop9dVXX6njjjtO+Xw+VVZWpm6//fY2lftXSkr+CyGEEEIIoZRSS5YsUaeeemrmGt/lcqmvv/66s8Paq1qbG3RqT9uBSHrahBBCCCHEgSwSiXDnnXfy0EMPYZpmZvvYsWN5/PHH6d+/fydGt3e1Njdw78WYhBBCCCGEEAcopRQvvfQS119/PRUVFZntffr04aGHHuLss88+IIuMtIYkbUIIIYQQQog9auHChUydOpV33303s83n8/Hzn/+cm266iWAw2HnB7QMkaRNCCCGEEELsUf/73/+yErbx48fz29/+9oAaCrk7ZE7bXiZz2oQQQgghxIHGNE2OOOIIYrEYDz/8MOPHj+/skLoEmdMmhBBCCCGE2OsWLFjAe++9x9VXX53Z5na7eeWVVygvL8fv93didPumLr24thBCCCGEEGLf0NDQwJQpUxg1ahTXXnstn332Wdb+fv36ScLWTpK0CSGEEEIIIdrNtm3+8Ic/MGjQIB577DFs20YpxW9+85vODm2/IUmbEEIIIYQQol0+/fRTRo8ezY9+9CNqamoACAaD3HPPPTz77LOdHN3+Q+a0CSGEEEIIIdqkrq6OW265haeffpot6xqed955TJ8+nd69e3didPsfSdqEEEIIIYQQrbZ06VLGjBlDfX19ZtuQIUOYMWMGJ598cidGtv+S4ZFCCCGEEEKIVhswYAD9+vUDIDc3l+nTp7NgwQJJ2PYgSdqEEEIIIYQQOxSNRrN+drlcPPbYY1xwwQUsW7aM66+/Hq/X20nRHRgkaRNCCCGEEEJswzRNHn30UQ466CDmzp2bte+oo47iT3/6E+Xl5Z0U3YFFkjYhhBBCCCFEljlz5vCtb32LqVOn0tDQwJVXXollWZ0d1gFLkjYhhBBCCCEEAJWVlVx44YUcd9xxfPnll5nthx12GPF4vBMjO7BJ9UghhBBCCCEOcIZh8Oijj3LbbbcRiUQy20eOHMljjz3Gscce24nRCUnahBBCCCGEOIC9++67TJkyhUWLFmW2FRYWMm3aNC677DJcLlcnRidAkjYhhBBCCCEOWEopfvWrX2USNk3TuPTSS5k2bRrFxcWdHJ1oIXPahBBCCCGEOEBpmsaMGTPQdZ0jjzySjz/+mN/97neSsHUx0tMmhBBCCCHEAeKtt94iGAwyZsyYzLbDDz+cDz74gGOOOQZdlz6drkh+K0IIIYQQQuzn1q9fzznnnMPYsWO5/PLLMQwja//o0aMlYevC5DcjhBBCCCHEfiqVSnH33XczePBg/vnPfwKwePFiZs6c2cmRibaQ4ZFCCCGEEELsh2bNmsXVV1/NypUrM9tKSkq4//77ueCCCzoxMtFW0tMmhBBCCCHEfmT16tWcddZZjBs3LpOwuVwurr76apYtW8bkyZNlKOQ+RnrahBBCCCGE2E/8+c9/5kc/+hGpVCqz7bjjjuPRRx9lxIgRnRiZ2B2SYgshhBBCCLGfOOKII7AsC4AePXrw5z//mffee08Stn2c9LQJIYQQQgixjzIMA4/Hk/l5yJAh/OxnPyOdTnPrrbeSn5/fidGJjqIppVRnB3EgaWpqIhQKEQ6H5Y9ICCGEEEK0SywWY9q0afzrX//is88+w+fzdXZIoh1amxvI8EghhBBCCCH2EUop/v73vzNkyBCmTZvGokWLmD59emeHJfYwGR4phBBCCCHEPmDJkiVcddVV/Pe//81s83g82LbdiVGJvUGSNiGEEEIIIbqwSCTCnXfeyUMPPYRpmpntp512Go888ggDBw7sxOjE3iBJmxBCCCGEEF2QUoqZM2dyww03UFFRkdnep08ffvvb33LWWWehaVonRij2FknahBBCCCGE6II2btzIxRdfnFlzzefzceONN3LjjTcSDAY7OTqxN0khEiGEEEIIIbqg3r178/Of/xyAM888k0WLFnHHHXdIwnYAkqRNCCGEEEKITtYyFDIej2dtv+mmm3j99dd59dVX6d+/fydFJzqbJG1CCCGEEEJ0ogULFnDcccfxgx/8gHvuuSdrXzAY5PTTT++kyERXIUmbEEIIIYQQnaChoYEpU6YwatQoPvzwQwDuv/9+KisrOzky0dVI0iaEEEIIIcReZNs2zzzzDAMHDuSxxx7LrLM2cOBAXn31VXr06NHJEYquRqpHCiGEEEIIsZd8+umnXHnllXzyySeZbTk5OfzqV7/i2muvxev1dmJ0oquSpE0IIYQQQoi94Nprr+Xhhx9GKZXZdv755zN9+nR69erViZGJrk6SNiGEEEIIIfaC7t27ZxK2oUOHMmPGDE466aROjkrsCzS1Zaov9rimpiZCoRDhcJj8/PzODkcIIYQQQuwhSik0Tcv8nEqlGDNmDBMnTmTq1Kl4PJ5OjE50Ba3NDaSnTQghhBBCiA5UXV3NTTfdRHFxMffff39mu8/n45NPPkHXpRagaBtJ2oQQQgghhOgApmny5JNP8qtf/YrGxkbcbjcXXXQRQ4cOzbSRhE20h3xqhBBCCCGE2E0ffPABo0aNYurUqTQ2NgLOwtjLly/v3MDEfkGSNiGEEEIIIdqpsrKSSZMmcfzxx/PVV19ltl900UUsX76cs88+u/OCE/sNGR4phBBCCCFEGxmGwYwZM7j99tuJRCKZ7SNHjuSxxx7j2GOP7cToxP5GkjYhhBBCCCHa6IUXXuD666/P/FxYWMi0adO47LLLcLlcnRiZ2B/J8EghhBBCCCHa6MILL+TQQw9F0zQuu+wyli9fzhVXXCEJm9gjpKdNCCGEEEKInUin07z33nuceuqpmW0ej4c//OEPaJrGkUce2YnRiQOB9LQJIYQQQgixA2+99RYjRozg9NNPZ8GCBVn7jjrqKEnYxF4hSZsQQgghhBBbWb9+Peeeey5jx45l2bJl2LbNVVdd1dlhiQOUJG1CCCGEEEI0S6VS3H333QwePJh//OMfme3HHnssDz/8cCdGJg5kMqdNCCGEEEIIYNasWVx99dWsXLkys62kpIT777+fSZMmoevS3yE6hyRtQgghhBDigNbQ0MDkyZP597//ndnmcrmYMmUKt99+OwUFBZ0XnBBI0iaEEEIIIQ5w+fn5bNq0KfPz8ccfz4wZMxgxYkQnRiXEN6SPVwghhBBCHNBcLhePPvoo5eXl/PnPf+bdd9+VhE10KZK0CSGEEEKIA8aKFSsYN24cH3/8cdb2Y489ltWrVzNx4kQ0Teuk6ITYvk5N2t5//33OPPNMysvL0TSNV155JWu/Uorbb7+d8vJyAoEA3/72t1m0aFFWm1QqxdSpUykuLiYnJ4cJEyawcePGrDYNDQ1MmjSJUChEKBRi0qRJNDY2ZrVZv349Z555Jjk5ORQXF3PVVVeRTqez2nz99deccMIJBAIBevbsya9//WuUUh12PIQQQgghxJ4Ri8X4xS9+wbBhw5g1axZXXnkllmVltfH5fJ0UnRA716lJWywW47DDDuPRRx/d7v7777+fBx98kEcffZT58+dTVlbGqaeeSiQSybS55pprePnll5k5cyZz5swhGo0yfvz4rD/CiRMnsmDBAmbPns3s2bNZsGABkyZNyuy3LItx48YRi8WYM2cOM2fO5B//+AfXX399pk1TUxOnnnoq5eXlzJ8/nxkzZjB9+nQefPDBPXBkhBBCCCFER1BK8fe//50hQ4Ywbdq0zE35zZs3s27duk6OTohWUl0EoF5++eXMz7Ztq7KyMnXvvfdmtiWTSRUKhdSTTz6plFKqsbFReTweNXPmzEybTZs2KV3X1ezZs5VSSi1evFgBat68eZk2c+fOVYBaunSpUkqpWbNmKV3X1aZNmzJtXnzxReXz+VQ4HFZKKfX444+rUCikkslkps0999yjysvLlW3brX6f4XBYAZnnFUIIIYQQe8bixYvVKaecooDMP4/Ho26++WYVjUY7OzwhWp0bdNk5bWvWrKGqqoqxY8dmtvl8Pk444QQ++ugjAD777DMMw8hqU15ezrBhwzJt5s6dSygU4uijj860OeaYYwiFQllthg0bRnl5eabNaaedRiqV4rPPPsu0OeGEE7K6zU877TQqKipYu3btDt9HKpWiqakp658QQgghhNhzIpEIP//5zxkxYgT//e9/M9tPO+00Fi5cyLRp08jJyenECIVomy6btFVVVQFQWlqatb20tDSzr6qqCq/XS2Fh4U7blJSUbPP8JSUlWW22fp3CwkK8Xu9O27T83NJme+65557MXLpQKETv3r13/saFEEIIIcRumTx5Mg888ACmaQLQp08fXn75ZV5//XUGDhzYydEJ0XZdNmlrsXX1HqXULiv6bN1me+07oo1qLkKys3huvvlmwuFw5t+GDRt2GrsQQgghhNg9v/zlL9E0DZ/Px6233srixYs5++yzpSqk2Gd12aStrKwM2LYXq7q6OtPDVVZWRjqdpqGhYadtNm/evM3z19TUZLXZ+nUaGhowDGOnbaqrq4FtewO35PP5yM/Pz/onhBBCCCE6RjgcZtmyZVnbjjjiCJ588kkWLVrEHXfcQTAY7KTohOgYXTZpO/jggykrK+Ott97KbEun07z33nuMHj0agFGjRuHxeLLaVFZWsnDhwkybY489lnA4zCeffJJp8/HHHxMOh7PaLFy4kMrKykybN998E5/Px6hRozJt3n///axlAN58803Ky8vp27dvxx8AIYQQQgixQ0opXnjhBQYNGsS5556bGQrZ4vLLL6d///6dFJ0QHatTk7ZoNMqCBQtYsGAB4BQfWbBgAevXr0fTNK655hqmTZvGyy+/zMKFC7nooosIBoNMnDgRgFAoxI9+9COuv/563n77bb744gt++MMfMnz4cE455RQAhgwZwumnn85ll13GvHnzmDdvHpdddhnjx49n0KBBAIwdO5ahQ4cyadIkvvjiC95++21uuOEGLrvsskzP2MSJE/H5fFx00UUsXLiQl19+mWnTpnHddddJV7sQQgghxF60YMECjjvuOCZPnszmzZtZuHAhjz32WGeHJcSes8frWO7EO++8k1WCteXf5MmTlVJO2f/bbrtNlZWVKZ/Pp44//nj19ddfZz1HIpFQU6ZMUUVFRSoQCKjx48er9evXZ7Wpq6tTF1xwgcrLy1N5eXnqggsuUA0NDVlt1q1bp8aNG6cCgYAqKipSU6ZMySrvr5RSX331lTruuOOUz+dTZWVl6vbbb29TuX+lpOS/EEIIIUR71dfXqyuvvFLpup517fjd735XrV27trPDE6LNWpsbaEo1V9MQe0VTUxOhUIhwOCzz24QQQgghWsG2bZ599lluuukmamtrM9sHDhzIjBkzspZ/EmJf0trcwL0XYxJCCCGEEKJNFi5cyKWXXsrHH3+c2ZaTk8OvfvUrrr32WrxebydGJ8TeIUmbEEIIIYTosjRN49NPP838fP755zN9+nR69erViVEJsXd12eqRQgghhBBCHHrooVx11VUMHTqUt99+m5kzZ0rCJg44krQJIYQQQoguYe7cuZx33nmkUqms7XfddRcLFizgpJNO6qTIhOhckrQJIYQQQohOVV1dzSWXXMLo0aP529/+xkMPPZS1PxgM4vF4Oik6ITqfJG1CCCGEEKJTmKbJjBkzGDhwIM8++2xm+6uvvopt250YmRBdiyRtQgghhBBir5szZw6jRo3iqquuIhwOAxAKhXjkkUd4//330XW5TBWihfw1CCGEEEKIvaayspJJkyZx3HHH8dVXX2W2X3TRRSxbtoypU6fidkuBcyG2JH8RQgghhBBir4jFYhx22GHU1NRkto0cOZLHHnuMY489thMjE6Jrk542IYQQQgixV+Tk5HDZZZcBUFhYyBNPPMH8+fMlYRNiF6SnTQghhBBC7BEbN26kW7duBAKBzLZbbrmFdDrNjTfeSHFxcSdGJ8S+Q3rahBBCCCFEh0qn09x3330MHjyY++67L2tfTk4ODzzwgCRsQrSBJG1CCCGEEKLDvPnmmwwfPpybbrqJWCzGvffey+rVqzs7LCH2aZK0CSGEEEKI3bZu3TrOOeccTjvtNJYvXw6ArutceumlFBYWdnJ0QuzbZE6bEEIIIYRot2QyyfTp05k2bRqJRCKzffTo0Tz22GMcfvjhnRecEPsJSdqEEEIIIUS7zJ49mylTprBq1arMttLSUu6//34mTZqEpmmdGJ0Q+w8ZHimEEEIIIdpl/vz5mYTN5XJxzTXXsGzZMi688EJJ2IToQJpSSnV2EAeSpqYmQqEQ4XCY/Pz8zg5HCCGEEKLdkskkhx56KL1792bGjBkMHz68s0MSYp/S2txAhkcKIYQQQoidUkrx6quvsmrVKq677rrMdr/fzwcffECPHj2kZ02IPUiSNiGEEEIIsUMrVqzgqquuYvbs2Xg8HsaNG8egQYMy+8vLyzsxOiEODDKnTQghhBBCbCMWi3HLLbcwbNgwZs+eDYBhGLzwwgudHJkQBx7paRNCCCGEEBlKKf7+979z3XXXsXHjxsz23r178+CDD3LOOed0YnRCHJgkaRNCCCGEEAAsWbKEqVOn8vbbb2e2eTwebrjhBn7xi1+Qk5PTidEJceCSpE0IIYQQQvDee+9xyimnYJpmZtvpp5/Oww8/zMCBAzsxMiGEzGkTQgghhBCMHj2aAQMGANC3b19eeeUVZs2aJQmbEF2A9LQJIYQQQhyAqqurKSkpyfzs8Xh49NFHee+997jpppsIBAKdGJ0QYkvS0yaEEEIIcQAJh8Ncc801HHTQQXz11VdZ+0466STuuOMOSdiE6GIkaRNCCCGEOADYts0LL7zAoEGDePjhh0mlUkyZMgWlVGeHJoTYBRkeKYQQQgixn1uwYAFXXnklH330UWZbIBBg7NixWJaF2y2XhEJ0ZfIXKoQQQgixn2poaOBXv/oVTzzxBLZtZ7Z/97vf5cEHH6RPnz6dGJ0QorUkaRNCCCGE2M/Yts2zzz7LTTfdRG1tbWb7wIEDmTFjBmPHju3E6IQQbSVz2oQQQggh9jO2bTNjxoxMwpaTk8O9997L119/LQmbEPsgSdqEEEIIIfYzbrebxx57DIDzzz+fpUuXcuONN+L1ejs5MiFEe8jwSCGEEEKIfZhlWTz99NN861vf4lvf+lZm+5gxY1i0aBFDhw7txOiEEB1BetqEEEIIIfZRc+fO5aijjuInP/kJV155ZVaxEUASNiH2E5K0CSGEEELsY6qrq7nkkksYPXo0n3/+OQCffPIJ7733XidHJoTYEyRpE0IIIYTYR5imyYwZMxg4cCDPPvtsZvuIESN4//33OfHEEzsxOiHEniJz2oQQQggh9gEffPABU6ZM4auvvspsC4VC3HnnnfzkJz+RBbKF2I9JT5sQQgghRBd39913c/zxx2clbBdffDHLly9n6tSpkrAJsZ+TpE0IIYQQoosbO3YsmqYBcMQRRzB37lz+8Ic/UFJS0smRCSH2BrktI4QQQgjRxUSjUXJzczM/H3nkkfzsZz/j4IMP5rLLLsPlcnVidEKIvU1TSqnODuJA0tTURCgUIhwOk5+f39nhCCGEEKIL2bhxIzfccAPLli1j/vz5MuxRiP1ca3MDGR4phBBCCNHJ0uk09913H4MHD+all15iwYIFPPXUU50dlhCii2j37RvDMKiqqiIej9O9e3eKioo6Mi4hhBBCiAPCm2++ydSpU1m+fHlmW3FxMQUFBZ0XlBCiS2lTT1s0GuWpp57i29/+NqFQiL59+zJ06FC6d+9Onz59uOyyy5g/f/6eilUIIYQQYr+xbt06zjnnHE477bRMwqbrOldeeSXLli3jggsu6OQIhRBdRauTtoceeoi+ffvy9NNPc9JJJ/HPf/6TBQsWsGzZMubOncttt92GaZqceuqpnH766axYsWJPxi2EEEIIsU9KJpPcddddDBkyhH/+85+Z7aNHj+bTTz/l0UcflRFMQogsrS5E8r3vfY9bb72V4cOH77RdKpXimWeewev1cumll3ZIkPsTKUQihBBCHNgWLlzI4YcfjmVZAJSWlnL//fczadKkTFl/IcSBobW5gVSP3MskaRNCCCHE1VdfzWOPPcbUqVO5/fbbCYVCnR2SEKITSPVIIYQQQohOlkgk+O1vf0s6nc7afscdd/DFF1/w0EMPScImhNilVleP/O53v9vqJ91yfLYQQgghxIFGKcWrr77KNddcw9q1azEMg5/97GeZ/QUFBVIdUgjRaq3uaQuFQpl/+fn5vP3223z66aeZ/Z999hlvv/223C0SQgghxAFtxYoVfOc73+Hss89m7dq1ANxzzz3EYrHODUwIsc9qdU/bs88+m/nvG2+8kfPOO48nn3wSl8sFgGVZ/PSnP5V5WkIIIYQ4IMViMaZNm8b06dOzhkOecsopzJgxg5ycnE6MTgixL2tXIZLu3bszZ84cBg0alLV92bJljB49mrq6ug4LcH8jhUiEEEKI/YtSin/84x9cd911bNiwIbO9d+/ePPjgg5xzzjlSFVIIsV17tBCJaZosWbJkm+1LlizBtu32PKUQQgghxD7Htm3Gjx/P9773vUzC5vF4uPnmm1myZAnnnnuuJGxCiN3W6uGRW7r44ou55JJLWLlyJccccwwA8+bN49577+Xiiy/u0ACFEEIIIboqXdcZPnw4s2bNAuD000/n4YcfZuDAgZ0cmRBif9Ku4ZG2bTN9+nQefvhhKisrAejRowdXX301119/fWaem9iWDI8UQggh9l1KKSzLwu3+5r53NBrljDPO4IYbbmDChAnSsyaEaLW9trh2U1MTgCQgrSRJmxBCCLFv+vrrr5kyZQqnnHIKv/rVrzo7HCHEfmCPL65tmib//e9/efHFFzN3lCoqKohGo+19SiGEEEKILqexsZGrr76akSNH8v777zNt2rRMKX8hhNgb2pW0rVu3juHDh3PWWWdx5ZVXUlNTA8D999/PDTfc0GHBmabJL3/5Sw4++GACgQD9+vXj17/+dVaxE6UUt99+O+Xl5QQCAb797W+zaNGirOdJpVJMnTqV4uJicnJymDBhAhs3bsxq09DQwKRJkzJr0U2aNInGxsasNuvXr+fMM88kJyeH4uJirrrqqqySvkIIIYTYf9i2zfPPP8+gQYN45JFHsCwLgJ49e1JdXd3J0QkhDiTtStquvvpqvvWtb9HQ0EAgEMhs/3//7//x9ttvd1hw9913H08++SSPPvooS5Ys4f777+eBBx5gxowZmTb3338/Dz74II8++ijz58+nrKyMU089lUgkkmlzzTXX8PLLLzNz5kzmzJlDNBpl/PjxmZMvwMSJE1mwYAGzZ89m9uzZLFiwgEmTJmX2W5bFuHHjiMVizJkzh5kzZ/KPf/yD66+/vsPerxBCCCG6hi+++ILjjjuOiy66KJOgBQIB7rrrLhYuXMhRRx3VyREKIQ4oqh26deumli5dqpRSKjc3V61atUoppdSaNWtUIBBoz1Nu17hx49Qll1ySte273/2u+uEPf6iUUsq2bVVWVqbuvffezP5kMqlCoZB68sknlVJKNTY2Ko/Ho2bOnJlps2nTJqXrupo9e7ZSSqnFixcrQM2bNy/TZu7cuQrIvM9Zs2YpXdfVpk2bMm1efPFF5fP5VDgcbvV7CofDCmjTY4QQQgixd9TX16uf/vSnStd1BWT+ffe731Vr167t7PCEEPuZ1uYG7epps207q5eqxcaNG8nLy2t/BrmV//u//+Ptt99m+fLlAHz55ZfMmTOH73znOwCsWbOGqqoqxo4dm3mMz+fjhBNO4KOPPgLgs88+wzCMrDbl5eUMGzYs02bu3LmEQiGOPvroTJtjjjmGUCiU1WbYsGGUl5dn2px22mmkUik+++yzHb6HVCpFU1NT1j8hhBBCdE1PPPEEjz/+eGYqxsCBA3njjTf4xz/+QZ8+fTo5OiHEgapdSdupp57Kb3/728zPmqYRjUa57bbbMglVR7jxxhv5wQ9+wODBg/F4PIwcOZJrrrmGH/zgBwBUVVUBUFpamvW40tLSzL6qqiq8Xi+FhYU7bVNSUrLN65eUlGS12fp1CgsL8Xq9mTbbc88992TmyYVCIXr37t2WQyCEEEKIvejaa6+lb9++5OTkcO+99/L1119n3fgVQojO0K7FtR966CFOPPFEhg4dSjKZZOLEiaxYsYLi4mJefPHFDgvupZde4k9/+hN/+ctfOPTQQ1mwYAHXXHMN5eXlTJ48OdNu6/VQlFK7XCNl6zbba9+eNlu7+eabue666zI/NzU1SeImhBBCdAG1tbXMmTOHs88+O7MtEAgwc+ZMevbsSa9evTovOCGE2EK7krby8nIWLFjAiy++yOeff45t2/zoRz/iggsuyCpMsrt+9rOfcdNNN/H9738fgOHDh7Nu3TruueceJk+eTFlZGeD0gvXo0SPzuOrq6kyvWFlZGel0moaGhqzeturqakaPHp1ps3nz5m1ev6amJut5Pv7446z9DQ0NGIaxTQ/clnw+Hz6frz1vXwghhBB7gGVZ/O53v+MXv/gFsViMhQsXMmDAgMz+LadLCCFEV9DuddoCgQCXXHIJjz76KI8//jiXXnpphyZsAPF4HF3PDtHlcmXGmR988MGUlZXx1ltvZfan02nee++9TEI2atQoPB5PVpvKykoWLlyYaXPssccSDof55JNPMm0+/vhjwuFwVpuFCxdSWVmZafPmm2/i8/kYNWpUh75vIYQQQuwZc+fO5cgjj+SnP/0pDQ0NpNNpbr755s4OSwghdqrVPW2vvvpqq590woQJ7Qpma2eeeSZ33303Bx10EIceeihffPEFDz74IJdccgngDFe85pprmDZtGgMGDGDAgAFMmzaNYDDIxIkTAQiFQvzoRz/i+uuvp1u3bhQVFXHDDTcwfPhwTjnlFACGDBnC6aefzmWXXcZTTz0FwOWXX8748eMZNGgQAGPHjmXo0KFMmjSJBx54gPr6em644QYuu+yyna5eLoQQQojOV11dzY033shzzz2XtX3SpEncd999nROUEEK0VmvLUWqa1qp/uq7vVtnLLTU1Namrr75aHXTQQcrv96t+/fqpX/ziFyqVSmXa2LatbrvtNlVWVqZ8Pp86/vjj1ddff531PIlEQk2ZMkUVFRWpQCCgxo8fr9avX5/Vpq6uTl1wwQUqLy9P5eXlqQsuuEA1NDRktVm3bp0aN26cCgQCqqioSE2ZMkUlk8k2vScp+S+EEELsPYZhqEceeUSFQqGsEv4jRoxQH3zwQWeHJ4Q4wLU2N9CUUqpTs8YDTFNTE6FQiHA4LD10QgghxB60bt06JkyYwFdffZXZFgqFuOuuu7jiiitwu9s1tV8IITpMa3MDOVsJIYQQYr/Uo0cPkslk5udLLrmEe+65Z7vL/AghRFfW7qQtFovx3nvvsX79etLpdNa+q666arcDE0IIIYRoC7XVMjxer5cZM2Zwyy238Oijj3LMMcd0YnRCCNF+7Roe+cUXX/Cd73yHeDxOLBajqKiI2tpagsEgJSUlrF69ek/Eul+Q4ZFCCCFEx3vnnXe49tpr+dOf/sSwYcOy9tm2vU01aiGE6Apamxu06wx27bXXcuaZZ1JfX08gEGDevHmsW7eOUaNGMX369HYHLYQQQgjRFhs3buT888/npJNO4ssvv2Tq1KlsfT9aEjYhxL6uXWexBQsWcP311+NyuXC5XKRSKXr37s3999/PLbfc0tExCiGEEEJkSaVS3HvvvQwaNIi//vWvme3xeJyGhoZOjEwIITpeu5I2j8eTGTNeWlrK+vXrAaciU8t/CyGEEELsCW+88QYjRozg5ptvJh6PA1BcXMzvf/975s6dS1FRUSdHKIQQHatdhUhGjhzJp59+ysCBAznxxBO59dZbqa2t5Y9//CPDhw/v6BiFEEIIIVi7di3XXXcdL7/8cmabruv85Cc/4c4776SwsLAToxNCiD2nXT1t06ZNo0ePHgDceeeddOvWjZ/85CdUV1fz1FNPdWiAQgghhBAA3//+97MStjFjxvDZZ5/x6KOPSsImhNivyeLae5lUjxRCCCHa5/333+eEE06gtLSU+++/n0mTJmWV+BdCiH3NHl1ce82aNZimyYABA7K2r1ixAo/HQ9++fdvztEIIIYQQAKxevZpUKsWQIUMy244//nheeOEFJkyYQCgU6sTohBBi72rX8MiLLrqIjz76aJvtH3/8MRdddNHuxiSEEEKIA1Q8Hue2225j6NChXHLJJdi2nbV/0qRJkrAJIQ447UravvjiC8aMGbPN9mOOOYYFCxbsbkxCCCGE6ES2rdhQH2dpVRMb6uPY9p6fSaGU4pVXXmHo0KH8+te/JpVKMW/ePB547PdZMXRGbEII0dnaNTxS0zQikcg228PhMJZl7XZQQgghhOgcK6sjvLFwM6tqoiRNC7/bRf/uuZw2rJRDSvL2yGsuX76cq6++mtmzZ2e26S43I79zASsCg3noreX0757L4B55LK2M7NXYhBCiK2hXIZLx48cTDAZ58cUXcblcAFiWxfnnn08sFuP111/v8ED3F1KIRAghRFe1sjrCsx+upT6WpkfIT9DrJp42qQwnKcrxcvGYvh2aHMViMe666y5+85vfYBhGZnvfEUdz9MQbGDp0SCaGFZujVDYl6RHyM6Akd4/HJoQQe8MeLURy//33c/zxxzNo0CCOO+44AD744AOampr43//+176IhRBCCNFpbFvxxsLN1MfSDCjJzVRlzPN7yPW5WVEd5c1Fm+lXnIuu737FxrfeeotLLrmEjRs3Zrb17t2bsRf/DPchxzKwNC8TQ67PjWnbRJIG3XO95PrcaJq2x2ITQoiupl1z2oYOHcpXX33FeeedR3V1NZFIhAsvvJClS5cybNiwjo5RCCGEEHvYpsYEq2qi9Aj5tymjr2kaPUJ+VlZH2dSY6JDXy8/PzyRsXq+XW265hbc+/Iz8ocdRXhDIiiGSNGmIG3TL8dIQN4gkzT0aW3vIXDshxJ7Urp42gPLycqZNm9aRsQghhBCik8TSJknTIugNbHd/wOtic1OSWNrc7v62Ovroo7nkkkuoqKjgkUceYcCAASytatpuDGnLxrRsQkEPTQmDtJVdUbKjY2urzpgHKIQ4sLSpp62+vj5rGAPAokWLuPjiiznvvPP4y1/+0qHBCSGEEGL3tLYHKMfrxu92Ed9B4pNIW/jcLnK8bbvfq5TiL3/5C+PHj9+mWNnjjz/OrFmzMuu+bhmDUoqmhEFtNEXKsHDrGom0hUvX8br0rOevbkqRNCyaEsZe7+FqmQe4sCJMQdBDv+JcCoIeFlaEefbDtays3rZwmxBCtFWbzrxXXnklPXr04MEHHwSgurqa4447jvLycvr3789FF12EZVlMmjRpjwQrhBBCiNZrSw9Qz4IA/bvnsrAinJkz1kIpRWU4yfCeIXoWbL8nbnu+/vprpkyZwvvvvw/A008/zRVXXJHZ7/P5thvDvDV1GKZFTTSNYdm4dQ3DtIkbNgNLc8nzO5cv9bEUKzdHWVcfJ8/v5i/z1vHfxZv51sFFDCnLp2dBYI/Ocdvb8wCFEAeuNvW0zZs3jwkTJmR+fuGFFygqKmLBggX861//Ytq0aTz22GMdHqQQQggh2qatPUC6rnHasFKKcrysqI4SSRqZ4h8rqqMU5XgZe2hpq5KPxsZGrrnmGkaOHJlJ2MC5jtgZXdcY3COPdXVxFlY0URtJ0ZRIUxdNUxdLkzJt0pZNNGVSE0nyyZp6VtfFyAt4OKQklw0NCV77qpK7XlvMHf9exBPvrtqjPV17ex6gEOLA1aakraqqioMPPjjz8//+9z/+3//7f7jdzh2vCRMmsGLFio6NUAghhBBtsnUPUJ7fg0t3qi0OKMmlPpbmzUWbtxlKeEhJHheP6cuw8hCNcYO1tTEa4wbDe4ZaVVLftm2ef/55Bg0axMMPP5wZDtm/f3/+85//8Nxzz+0y7g9X1pI2LTwuHQXYSkMBPo8Lv1sDBfWxNJ+uayCSNOlXnMOg0lzW18cJJwy653nx6DoN8TRfb2rco0MUv5kHuP2BSwGvi5RpddpcOyHE/qNNwyPz8/NpbGykT58+AHzyySf86Ec/yuzXNI1UKtWxEQohhBCiTdrSA9S7KJi1/5CSPPp9O5dNjQliaZMcr7tVwwy/+OILpkyZwkcffZTZFggE+MUvfsH111+P3+/fZdwbG+LMW12HrmsEPTqxtI2tFLrm/KyARNrk5CElRJImRTkeyvL9fLaukUTaoijHi6ZpaJpGLGUxvNzP5khqjw1R3HIOXp7fs83+9s4DFEKIrbWpp+2oo47ikUcewbZt/v73vxOJRDjppJMy+5cvX07v3r07PEghxJ4jZapFR5PP1I7trWOzZQ/QlgU9mhIGSqld9gDZtqIynGBNbYzKcGKXcVZUVHD00UdnJWznnHMOS5Ys4Re/+EWrEjaA1bUxaqMpkmmTuGHj8+jk+tz4PDpxwyZpWNTG0jTGDXwendL8ANGURX08Ta7/m3l4HpeOadsYttqjQxRb5uBVhpMolX2MWuYBHlKS26Z5gEIIsT1tuvVz5513csopp/CnP/0J0zS55ZZbKCwszOyfOXMmJ5xwQocHKYTYM6RMteho8pnasb15bFp6gCoa41SFU9TH05i2jVvXKQp6KQv5dtgD9PaSzTz34VrW1sUwLBuPS6dvtxwuGtOXk4eUbvf1ysvLufzyy3nssccYNGgQjzzyCGPHjm1z3EopEmkLXYMcn5uWTkK3puHyuIglDQzLwu/WMz1cacvGtG08rm/ei1O8xKkyuSeXA2iZB1gRTrCi2unZDHhdJNIWleFkm+YBCiHEzrQpaTv88MNZsmQJH330EWVlZRx99NFZ+7///e8zdOjQDg1QCLFntBQpqI+l6RHyE/QGiKdNFlaEqQgnWjV/pSuybdXmYV2iY+yvn6mOsCeOzc4+6z0LAhQEPby1eDMel4bf48LndqGUoqopwYaGOKcOLd2mB+jtJZu55/WlRJLOQtYtCcjy6gj3vL4UgJOHlPLFF18wbNgwPJ5vhgTeeeed9OvXjylTpuD1ett1nAJeF7qmYSsFKGDLv12FDeiaRs+iAP0jTqXL0jwfbl3HsOzMe4wmTUry/eT53URT5h4dotgyD7AlId/clMTndjG8Z4ixh2Yn5HJ+arsD4ZgdCO9R7L42n8G6d+/OWWedtd1948aN2+2AhBB73v5aplp6eTrP/vqZ6gh74ti06rOuwLAUsbSJHTNoSYJ0HbwuF1u/kmnaPPfhWiJJg4MKA+i63hynTo7XxfqGBE+9sYAXf/N3/vCHZ/jNb37Dtddem3l8YWEh11133W4dq/yAh4IcLw2xNAnDxuvWcWlgKUibNpqmUZjjpSDozfRwVTWlyPG6aIynsX2KcMLA63ZRmudv91IFbdWaeYByfmq7A+GYHQjvUXSMVs9pmzlzZqufdMOGDXz44YftCkgIseftj2WqZYHbzrU/fqY6Skcfm9Z81jc1JljfEMfv0UGBptFcoANQ4PforKuPZ73m5xsaWFsXo1uON5OwfUMR/WIWL9/yPZ555vcopbjtttuoqqrazaOTLc/nVLcsyvGi4SRqCcN2EjagKNfLISW55Pk8mR6u4T1DFAa9NCVNVtZEaUwYJA2LrzY18sbizbh0ba8MUdR1jd5FQQaX5dO7KLhNwibnp7Y5EI7ZgfAeRcdpddL2xBNPMHjwYO677z6WLFmyzf5wOMysWbOYOHEio0aNor6+vkMDFUJ0nL1ZpnpvFF5ob3lz0XGk9PmOdeSxae1nPZxMs74+jkvT6N89hz5FQXoVBuhTFKR/9xw0pVhW1cTrCyv5ZE0dpmlTF3MWsg54XVmvWbv6a96+91IW//0hzIRzEZmXl8cdd9xBt27d2nVMTNPmkzV1Wa8PzrDOkb0L6V0YZGBpLoVBL7l+N4VBLwNLc+kVcgp/RJIGG+rj9CvO5dRDSyhsrhoJGqZlE00ZpE3L6VzsZHJ+arsD4ZgdCO9RdKxWD4987733eO2115gxYwa33HILOTk5lJaW4vf7aWhooKqqiu7du3PxxRezcOFCSkpK9mTcQojdsLfKVLd32Edbx/fvTnnz/dXeniOxv5Q+353jtqPHduSxae1n/aBuARJpizy/G13X8W1xi7YhlmZzNEXKsHny3VXk+Nz07ZbDsYd0w+PSmx+nk2yq56uXH2ft3FlZr3P62d/jD48/TI8ePdp17LYsdJIwLNy6Ru/CAD8+4RBOGVqaGfZYG3EKedgKdA3CCYNIymRVTZRH31mJ3+2iIOihKpxgcWUEt67RvziIaSuiKYug18W3+hZSHzPaPTS3I/6O9qXzU1eZW7UvHbP2OhDeo+hYbfr2HD9+POPHj6euro45c+awdu1aEokExcXFjBw5kpEjR25nSIUQoqtpKVO9sCJMrs+d9YXRUXNA2lt4oT2J3jc9GduPd09Wj+uKOmOOxN74TO3K7l5w7s5x29lj+xXndtixae1nXUMj4HGRMqys12yIOT1whmXj0qE034emaSyvjlDRmCDP56YulqZq3qss/NdTGInoN89d1o/jLvw5/777Mtzu7O/61h67lkInDbE0Ls1ZjDtmKr7e1MSN//iKa8IDmHRsX04aXJJVwRIATaNngZ+DioIEvW5iKZO3l1RTH09jWzZul07KtAl4XBTmeEikLdbUxhlUmtuui9+O+jvaV85PXWlu1b5yzHbHgfAeRcdq1y3Pbt267bAYiRBi79idC9Q9Xaa6vYUX2pvo7S+9PB2hsyo4dnbp85XVEWZ/XcXXm8LEDJMcj5vhPUOcPrysVb26Syqb+M/XlaQMi/KCQJuOW2uOeUcdm9Z+1rvn+TioW5CNDXHqY84aZi4NKsKJ5nL4EPC68bld+DyuTKERn9dLns/Noo3rMwmb259Lz1Mm0//4/8fPxw/bbsLWms9cS6GThlgaDYVhg9ftwq9pmG6LcNLgsXdWUprv473lteT43BzbrxuaBosqmqiJpEgZVnPCqdGYSNMYT5E2bZQCvwdQiqakQTxtUhD0UBdNYXXPbfPQ3I78O+qK56etvz8SaYvn53adyq9d8Zh1tAPhPYqOJZ8EIfZBHXFHtC1lqtuqPcM+dqfCXlfo5ekKOruCY8tnqiV5ihsmQY+bEb1CnDZs58nT7lhZHeG3/13B8s0RrC3mf6ypi7F0c4RrThmw017dldURFlU0EU2Z9OkWpHuePzO3ZFfHzbYVs7+uYmNDnJ4FAVTzUL6tH3vFCf3b/feWTlu8ubSKqnCKknwffbsFWVIV2eln/YjehYzsXUjKtDFNm4aEQSSZJmlYeN06HpdOrt+DtzkB03WdbjleIgmTC44+iGLfFbz81TuEBnyLg8+4lD49ezBuRA8GluZh2ypzHNrymWspdOLSwLAh4HFl1mHzuF3k+TQa4waP/m8l5QXOnDZN02hKGJjNi2RHUyaramIUBLysromRthSaBmlT0ZQwUVv8ehKGRcDjYlNjnFDA2+qL347+O+pq56etvz98Lp3aaBo0GNm7oEtUfu1qx2xPOBDeo+hYkrQJsY/pyDvArSlT3R7tGfaxO+P7O7uXp6voMnMkNL5ZXkvbs7UgbFvxl3nr+XJDI163Tp7fg8elYViKSNLgyw2NvPjxen4xbugOe3XzmhdxLgh6qImkiKYsDu9d4FQw3MVx+3BVLbMWVpEyLTY1JHC7dAqDToXDohxv1mPb8/f2x7lr+f0Ha6iJJLGUwqVpFAQ9lBc4cfQI+fG7Xaytj1LZmKI4z8tJg0pwu/XM30RNUxIbRTJtoqHhdWn4PDpFQQ/Ktlj+zt/QNJ1+J36P+liaPsU5/OmKb/P+cZ+wNgorqppIpC0+XlPPlxvCWTeI2vKZq4ulSRgWtm3jdX+TsLXwuJwNmxoTDC7Lzzxf2rIxLRuP302u5qY+lqayKUF9LI1lK5RSaIAFaApUc7VM07JJobG4MsJ3hpW1+uK3o/+OutL5aXvfH5ubnPebH3DTEE9TlOPLtO+suVVd6ZjtKQfCexQdS5I2IfYhW94BPqR7DtGURUM8jdelc0j3HFbWxNp8R7SlTHVHas+wj90d378new73FZ09R2LLC8KeBQGCXjfxtMmiiiYqw8k9MsRqQ0OceWvq0TWNbpkKguBza3hzvGxuSjF3dT0bGuL06ZYDbNuTUhdLYylFvs9DjldRHUnz1cZGRvYuID/g2eFxW1kd4cVP1lMfS1Ga78fr1jEsRU0kSTRlcnjvAvID7qzHtuXv7Y9z1/LAG8tINVee9Lk1UqaiLpamKWkRCrpZUtnEis1R4mkTXdeoDLu5e9YSLhrTl5OHlFKU4+XfCyqIpkyaZ4YRTlqU+zzUrfiCr/72ENGqtegeH7mDjsWT27255L+GJ5jLpwvXE0uZ9CvOJcfn3uYGkWmrnX7m/B6dhniKhRVhLNsZ1pgylTMk0lIoFBoaLl3DsBW67iRdW56/vC4dt8s5th6XTixlEk9ZxFImevMabpmbAwo0HZQNpoKAB9y61qYbB+39O9rZkPUd9UIP7xnisIMKMJur7O7Jwh8tn/u6aIqyfD8p00YpE49LJ+h1YZg2q2piFAa9Wcnqzs4be7JwyYFwTj8Q3qPoOJK0CbEPabkDHPDofLaukfp4GtO2ces6RUEvZSFfl6g21Z5hHx0xvn9P9RzuKzpzjkRrhpS9sXAznsN0EobVYb+bNbUxGhNpuuc6vQMpw8r0SHndOqHmeU1ramOZpG3rnhSvS8et60SSBtGkRTRlUhdLEUmalOX7KQv5tjluLe83ljIJBTxoGuialkkW62NpVtVEGVSa265jnk5b/P6DNaRMi6KgJ1PkK+gFv1ujPm7w9YYwPreOjaK8IEB+wE3SsFleHeGe15fyv6XVvPLFJuJpK9P5qQCzqZYv//UM8aUffPN+jDQrPv+IQSecTX0sxbT/LOaNxZuJJA2Kgh7Shs0hpbkU5fiyhsyNG9Fjh5+5+liaxRVhqiMpXpq/gQK/G7cGScPGslIotEyvWMsC2vkBNx5dzypzntdc8r8mkiTH58Kl6ygUpq3wuDTSpsokpArI/AB43DqDy/JojButPi+25++otUPWFc6wzVjKIpG2mLe6jgUbnV7iPV34Y1Njgi82NNAQS7O2Lo7ZXLwl6HVhKUXA46I+liaSNMkPfPO+d3Te2BuFSw6Ec/qB8B5Fx9itb+50Os2aNWvo378/brfkf0LsabG0SW00RV3MKded63fjcbkxLJvqSJJwMk23HF+nV5tqz7APGd+/+zrzGO5qSFnAo/Ofryv4amMjLpfWoRd4moKkYVIXtZ3hd0qha071xKBv24rGW/ek5Pnd+D06q2uc+VZet45m6XhcGpubEmxoiHPq0NKs49byfvsV52KYiupIEm+O3ryAtUau3019NMVql8bRB3dr8zF/c2kVNZEkQa97m6rMuq4T9LiojToFRgaV5mbaeFxOUZF1dXH++ukGDMtJfhSgLIOm+f8i/NFMlJHMPJ+3xyCKTr2CnPIB2Mrmxn8sJJk2ncdqEE9b1EbT1MZSHNOvm7N2ms/FZ+saGNWngH7FOSyqbCLH6yKaskhbNvGUxfLNTdTG0vQqDHBoj3wShkUo6KWyKYVpgdcNbk3DVIq0qXC5nJtPxXl+mpImZUpljuchJc7abFVNKXoVBsjze1BKETdsdM3pndu6N82tO/PmKsIJupl2q3vG2vp31Joh64Az77IqgqUUadMinDCwFXTP9XFs/2L8Hn2PFv5YUtXE8s0RPLpOXsCDx+/GsBThhEE8ZWGaCp9HI219k/Xu6LyxNwse7YnRIF3NgfAexe5rV6YVj8eZOnUqzz//PADLly+nX79+XHXVVZSXl3PTTTd1aJBCCIdzoZYinjIpyfdvMRTMhTdHZ3NTEpTTrrO1ddhHR4zv70olqztDZ86R2NmQsvpYimWbI9TH0gwszaNXYbDDLvD6Fefg97rY1JjEo2t4PS5cmo6lFLGUQWNCUZrvp19xTuYx2+1Jabni17TMumC6roHt9E9tfcRa3m+5L0D/khwiKSNTpdHj0rGVojFh0K8kd5tj3pohZVXhFJZS+NzOdqVw5m81DycEp3cp4NG3m9S5XWQSNoDEms+p/+9TmPWbvmkXyKfw2xeRM/wUNE3HBqrCSZrXuc4MN0xbCsOySNcncOn1FAa9zhDNhMHv3l9Nn245xNMmbyze7BSCUYqGuEHKsumR72Noj3zcLp1cXSPk9xD0ukkZJqalsLTmBNvrwqVreN0uJh/bh3eW1WR9hj0ujcKgF5fu/H91UwqlyPSoOsm683trid3VXFylMWFsc17c1bmitX9HrethrqI2mnLmXbqcAjc1hoWGhluHuliaxZVhjh/QnQEluXuk8IdtKz5dU49pKQqDLnzNBWhaeoaN5kTbtDXSpo1p2zs8b3R2wSMhDlTtStpuvvlmvvzyS959911OP/30zPZTTjmF2267TZI2IfYQ5xJM284lZAtn354o/NCeuQttHfaxO+P7O6vUfVfTWXMkdjSkTCnFquoY0aRJQcCTufDenQs807T5fEMDdbE0BQEP+T4XFbbCvdXjFU6iUxj0UB76JpncuiclkjRJmjblBX6aEgYNcQOXrhFNGvQqCNKjwE/DVsPrtny/LYVHVtfEiCTNzDDEbjlevn9kb3xuF0urmgh6XKypi/HO0moqw8lMb+D2biyUhXy4NGf+l8eliKcMDFtlhhNazQlZ0OtGKUXatLGaexgBElv0KsUWv0vtv6d/c2A0nbyRZxA6bhIuf66zCbCV829LLUdUAUnTZlV1jB4hi1y/m1DAQ7ccHyuqo6yri6MBbpeGadukm5cViKYsFlWGKc310z3XS0PC4KCiALGUgdflIpa20DRFjtdNXvPnY1BZPn2Lc7b5DB/bvxunDC0h4HGzojrCxoYEsZSBrRRxw8oE62qew6Zr2efMlrfW2nNFa/6OWlO05MsNjaypjePSoFuuj7RpkzRs/F4XLk0jljLZ2JCgKWEQCnr3SOGPTY0JaiIpeoT8hBMGPrcrE6+mOYlwIp2gV1EQ07JZWxvb4XmjyxQ8EuIA066k7ZVXXuGll17imGOOyfqDHTp0KKtWreqw4IQQ2RKGRXGuF00j666+YdlEkya5fjfdcrwkDKtDX3d3erDaOuyjPeP75c5vts6YI7GjIWWRpDM/DDSKcn3k+b/52mnPBd7bSzZnLbqsNc+RyvO7MW1FyrBxLtU1dF2jLN9PQdBLZVMy8/xb9kgur4oQS5s0xFJomkY4nsawnc9UQ8wAFaco1wuQNbyu5f3OW1OHYVhUR9OkDZO0pfB5dHK9bo7sW8RXG8O88kUFtdEUmxqcCopuHUJBL91zfQQK/Nu9sTB2cBkP5C2nIpxAR2V6v1q0dKKlDZNNDTaxtLN+mWnbaIBhfpN9BQYcgyu/O1ZTDb6eQyk69Qq8pf2ynm97N3r0liPZPPwQwLAVXpfTG1OS76c038+G+jgp06JftxwGleVRE03x0ao6okmDpoTF5qYUuhYm4HXh9+j0KcohnrYYUJZL0OvG69LxuV0EvC7W1kZZVROlLOTnzMN6ZOaAbf0ZjqVNygv81MV0wvE0frfenHQqwEng3bpGQ9wgP+DJnBdN0+av8zeyri7GId1zM5/V7Z0rWvN31JqiJQ0Jg8ZEmh4FTpJjKYWtbJTSMZXCrUM8ZbKuLk5fTSPg1du8rtyuxNImKctmUFkeX28Kb+f7wyDgdXHpcQcztEdop+eNzi54JMSBql1JW01NDSUlJdtsj8Vi29x1EUJ0nByvm+JcH8W5Xioak1SEE6RNG69bp2coQI8CP6B1aKGJ3e3Bak8PXVsTPbnzu629PUdiR0MzG+JpwgmD4lwf/bvnbvP7ae0Fnm0r/vrZBh5/ZyXxtEVJro+Az0VjLE19LI3P7aJHyI9pKQzbxqPrzppmxTk0JYxtnv+QkjwGl+Xx+xW1bG5KOpX0mvfleHXyAx4MS1EfN5izopah5flZf1e6rjG4Rx4vfbqBulgKZStSpp1JpnSgsilJr6IApXl+KhoT1EaTpC3w+JzhfrXRFNGUySElOayri/HXTzfw87GDcbt1vF4XP/q/vtz5nyWkrOZiHTT3huF0Kuk6VDal8ehOufuWqUhmQwWuwvJvYvX46Tb2p1iJJnIOPalV39Nb9rCprTK6+nianoVB+nfPIZoyaUgYdMtxetE0TaMuliYcN7Cbj4OmgUt35sbF0xbJdARd11hU0UTA46Yo6KV/SQ5V4TRr6xK8+Ml6XHr2vMetP8tbngvX1sVpSprYSjUfA6capaZpdM9z1rUDjdpIin9+tpHXF1bh0jVqo+ms5Rm2d67Y1d9Ra4qWeHQNXaN5WCsYzT1tibTdHLPCVrCwIkxlU5Icr4vCnNavK9caLXH6PS4O713AquoY9fE0sZSJS9cpyPFSGPQytEdol+cNWRTasScrZwqxPe36izryyCP5z3/+w9SpUwEyXwBPP/00xx57bMdFJ4TI0nJ3/3/LNrO5MUFjwsSyFS5dw7Zs0rbNyYNL21T0YGdfPLvbg7WyOsLshc0lrtMmQa9T4vr0Dl5oWe78dg3bG1Jm2oqiHB8DS50L46215gJvZXWE17+q5IV562lKpsnxumhKmrib5wfleNMkDGcO26E9QsRMizyvm/7dc4gbNinD3ub5/7u4imfmrCGSTFOS56GiMUVL51TSsPG5bWculQ71cYPKcJLS3G/Wr7JtxYcrakmbTs9W3Pgm6dNwEqvGhEm0MsLq6lhmX8DjwrBsGmMGuX4XG+rjVDYm8Ht0VlZHiSQMLh7Tj4FleZwwqITH311FTSSFpZzEDJx5SKV5PmqiaRK2Tao5WTMaKml4+3ck1i6g/EeP4ynskYk30P/IVv8eoTlZ28G+gMfFISW5mbltpm0TCngIJwwSaZMlFU3O8ES+6aVzqnRC0lRE0xbdc9x0z/Vh2k4Rl+pIgmjaJs/nRtc0lK1IpE3eW17N3DW1fHdkLyaMKMfdPBdry57dYw8uJGlY1MXSFPrdeNw6jQmT7nk+RvcrYlVtnB4hP//5qoIV1VEs2yYU9OLS9KzlGYpyvG0+V/QsCNCvew7z19bTsyCAz+0iz+/03rUU8Ti0Zz6NcYPGuEG+31myQYHT42apTBJuWjYoxcbGBIZls6Ym1mEJQY98P8W5XhZXNnFI91xG9SkkmjJJWzYeXaOqKcWIXq0rUrR1rzo4PerfPFeSEb0K9uuiUQf6/GnROdqVtN1zzz2cfvrpLF68GNM0efjhh1m0aBFz587lvffe6+gYhRDNdF0jP+BmxeZoZu2m3Oa1m2piaZpSFmcf3rPVX+67+uLZnR6sldWRrGppLUPW1tTEWFoV4ZpTBnTYl9uWd35b5iilLRuvSyfP7z5g7vx2BVsPKQt6XLy6oIJFlU3OIshtrGjZ0tO7sjpCwjDJ83lwuTRiaZO0ZVGa7yfo9RBPJ6kMp6iP1aJpTk/LwoowJXl+Th6SfSNjaWUTd762pHmekkZt1GCL0YRYChrjhhMjzryxpGGxYFMjRx3cDfhmfTifWyOWVE7Jf7btmTJtMG3b6Q1rLibi0p15THVxzRnOpyBgOsP7/rukmsWVEa46eQAu3RnieWiPfOKGlflMFwa9pE2nSASAbSRpmvd3wh//Aywn7oa3f0fJubft/i90OxriaeavqWd1TYyyfD9uTSORtnDrOpXNCY9Ld957S+aXMrNTQFtpzSX7nZLzq2pjTgVI2+bDlbWkTMsppNK8ZttXG8L887ONXPx/B3PioBI2NSYYUJrLZ+vreXNJNUnDJp62iCQN3JpGKOihe56PlTVxpxhJLM3CyiZMy6YpaZIwbKdHK+glkTZZVROlMFjY5nPF6too9dE06+viLKuKkONzktHyAj8Jw6Yox8v3Rh2EZcFbSzazKZzAshS5XheNzb2RmuYs42AD1ZEURUEP4aTJfbOXcFC3nB3Oe2ytlvP86toY6+vjrK6J0SPkZ1BZHn6Pi8pwkm652y9StKObei296l+sbySeNomkTNKmTdq06Z7n43vfyttve51k/rToLO26ghk9ejQffvgh06dPp3///rz55pscccQRzJ07l+HDh3d0jEKIZqZp8+aizXhcGnk+L0nTKZWtaxrFOV6Sps1bizfzgyMPytyR3pHWfPHsauHcnS0y+5eP139TLS3gycydiCQMvtzQyF8+Xs8vxw3tkC/2LecXmaZNQ8LIrF9XGPDgdusc26/tZddF+2w9pOz04WVUNiW3qcRX0ZjE59E5pNRJ8rbuTdiyp7co6G1eu0uBcgp4JAyruWiIkxS0zL/K87tImYrqSIpwwuTskd/cyFhZHeE3by5zSvS7dQzbJmFsNWEMp6cskjQpyvXSLddLfTRNXSyd2d+yPpxLg2ja3mXxH01zKg2mLYWruaCIrjmPspRT5MPnctEtx0tVU5JH3l7Bed/qhdbcZdVti14+gIRhk7YUiRVzqX/791hN1Zl9rtwicoZ+e5skuaPEDUUynKQ6kmJVdRS/R0cBA0vzsGxniOLOjocGBH0u6iIpkqaFwhkpkDIVtm3j1jUMS2WKoti2ImVYLK2KcMe/F/OfryoAZ3jpqpooScMm6NXJ8eo0xi1ilk3StEmk6xnSI5+h5Xm8/HkttoLCoIeUYRNNmcTSFmkrRVGOh/rmapibI6lWL4ux5Tl05EEFVDQmqYmmWFMXY2NDgm8dXNg8qiCXicccxNr6GPPX1KNpWmY5BR3n78XtcqHhJG5m88c8adp0z/XhdmntTgi2jPGgoiAleX6WVTmL3ddEUwwszeOIgwoZe2gp/Ypz2VAfzyRoCcPkrUXVO7ypd9LgEh55ewU1kRRet4bP7aJbrpeg183/llbTp1twv0teZP606Eztvu08fPjwTMl/IcTe8fmGBtbWxSjN95Prc2cqxrWUvY6mTNbUxvh8Q0OmR2B7WvvFs7OFc2HHQ9s2NsSZt7oOlwZFOV4MS5E0LFyaRlGOl+pIio9X17GxIc5B3XK2ed6d2bJyYLccL0f0LsTt1hncI4+XF2wiknTm14QCHhJpi9V1MfL9HgaV7b93fru67Q2bTJnOsEXT1nnli03Mdldt05uw5WLyS6sipC0bM2Hjal4M2+vWSKScAgsti0eDk9C49ZYbGSpzI0PXNd5YuJnaaApQmM2Jwo64XU4xC2zwuJzy8VsyLZvGhNGqaq2mpTJVJZuv17G2WFvM6ZGzWF8foyTfT00kxcJNYUJBD01xA1+ei2jazCyIXLtpDdUvzyC55vNvXkR3kX/k2YRGfx99BzdaOordvBSAaVkkDAu3SyecNOie69vl8VBAU9wgbtrNSwSQtTh2bDtJcMpSkEjTlDR4b7nJ+OFlVDQ6N2ZCAaeX0rQVPrcLj8tZeNuwFRWNcf75eYJo0qRvcdBZBiDXi2E7vUIp06Ip4fx+V9ZE6dMtp1XLYmzvHNqrMMiG+jiraqJUNSVZvCmMpuCrDWFOG1bK9488iA11cSyliKetzLDS/OabWijFpsYklq0ozfcRThhYSlHo97YrIXCKrmzIKrqS59cozi2mKWGwsiZK/+65XH5cP9bWx3ji3VWZBC1t2tREUuT7PQwozd3mpt7k0X1YWhmhRyjAyN4FzQVq9Eyhof01eZH506IztStpmzVrFi6Xi9NOOy1r+xtvvIFt25xxxhkdEpwQIltdLI1hOXNtNE3Dt9V6bAGvi/pYdo/A9rT2i0eDdi3WvLo2RjhukON3ht7EUlYmuczxuQj6XDQmDFbXxtqUtG1dOdDj0unbLYfJo/uyrCpCj/zmsuJxg3DCwK3r9CvOwa3rLKuKcOKgkv3qAmJfsuWwySWVTfzn60rcukV5QYCg173d4UXfLCafJpk28XtcpJrH3BmW7RSd0CDVPJ9M15yFtm1bobl0CnO82IrMjYweoYDzuc/3s7iiCbt55paufVONcUtuXSORNkmZNkN75HNE78LMvr5FQVRz4tIaW/fl7ehRcUOxoT5BKOBhc1OKQ8tDvLOsmqpNjc7wynSShg9n0vjxy2B/08Pt73M4Raf+GE+33q2KpyO5deemUX00jc+18x7+Fk0pC49Lw+92euDt5gO0syTambuniKdNqiMpGhMGhTlevC6NZVURkoZFwOsi6HU3ry/n9KI6FTudQiQBr5tcn4uyfD/1MYNoyiScMMj3ezi0PMQ5o3pmlmjY2Vyy7Z1DG+JpVtZESaQtinN9WLbK6iU7Y1gZw3qG8Lh0UpbNwk1h8nzuzHm8KWlg2oo8n1MJ1aXreJuPZ1sTgpXVEf46v6XoCtRG05mCL0U5PkJBLwNL86iJpJi7po7ZC6syoy4CHj/zVtdR1eQkkIaltlmm4x+fbaK6KUl5gX+7N/T21+RF5k/v+/blAjLtStpuuukm7r333m22K6W46aabJGkTYg/pluPF49JJpC1yvM4aSC3DAHN9zpCz7fUIbK21Xzxxw2r3Ys1p2yba5MxzUOqb9aWSpkUkpWcWd22tt5ds5p7XlxJJGOQH3OT63ZiWzfLNEe76z2J6hPwM6ZG/3Tlt0ZS5X15A7Gt0XaNnQYBXF1SQNm0GlubtdHhRwOOiNupUuOue6yVtKTZHUqRNhVtXzaX5nQIdGk7SlrScDU51PouyfB+G5Vy45wc8JE2LolxnrTjDsLdJpraUNCwSBpQXBJg8um/WkGNN1/B79G3WNdtdLT1w4YRBJGkwtDyfpGFjWKp5wW+d2NI5mYTNldedwpMvJThwdKdUb7Zx5ul5dQ3LVgS9bnwuSO1i1ZGWJLs9xy9p2ERSBqZl4/G7nV7b5sqdXrfu9NwpG9tW2MoZQp5CkWhI4G6uSlkW8jfPO7OoaEwwZkAx/+/wnjsdDrilrc+htm2zaFMTjXGDoqCnuRiKgdftYkAowIrqKAvWN1Cc52NJZRP9i3MoyfVRHU01ryfoFKdx65pzUytuUJLvz1oiY8uEYGcXni1DItfVxXDpGt1yvVjNBV8iKaO56IqPgNdFVTjB20uyewydaqvO304sZWXm+2malpU8WkrRs3D759P9NXmRypn7tn29gEy7PlUrVqxg6NCh22wfPHgwK1eu3O2ghBDbd0TvQvp2y+GrTY3Ytk3SUCgUGhp+j4au6xzWqyCrR2B72vLF07so2ObFmvt0C2JaimjSKUjgcbkyVeTSpuX0lvjdHFTUuiFcpmnz3IdraYilmwtHpDMFHQIenca4QSRh0L97DnWmk6x1ay7hDfvvBURXtqOLyrYML3L2KuJpg+WbUyRN50LcUmBtlRQoIHtqmsIyLDaFkxQ0r9PV8rmPpixyfG4Sxs57pA0bPDqcOqSEnoUBNtTHM73KzlwqC61lzGMHaXkqS8Ha2iixlFMls6UH2dA9FJ18OZtfvpv8o84hdMz30L3+jgugjZylBzQM28a2oD6WQttR1+VWki2Tt9pI4fRwul06huVUmTQtGzRnHmLLTSJLKSKpb17BpTk3l2Npk3X1cQzLj60U+X4Po/oU8sR7q6iLpSgPBTi4Ww4Jw2JhRZhNjXG+M7wHxXm+zGd5y3OoYSkWVYRZWRNF05ylDTxuZ96l16Wjac55atbCzRTmeNhQ5xQDCXhdNMTSVIYTKOX0WGqaRkU4SbccL/2752T9jbScl2sjKd5evP3ksl9xbmbY5iHdc5vPleBzu/Dm6NTH0qyqiTUXYLGwbKgMJ+lZEMi8Vrp5vb88t3MOrY+liSRN8gPOd0XA68JWNi5Na1Pysi/3cLTY0XqU0LrCSqLz7A8FZNqVtIVCIVavXk3fvn2ztq9cuZKcnLbNTxFCtJ7brXP4QQXMXV2HaavMPB6FIpJyeh8O612wyyIkbf3iaetizVrznB2lnH+m7fS22bZzZ95Wzpf6X+at5/tHH7TLE+XnGxpYUR0hbVnEUqp5AV1HIq2hac7d9P8trSbodeNurrDXsv6S3P3cu3a21ENbi9toGoSTFpZl49rq47arfMlWztBJd47G4T2dv4v+3XP5eE0dSoG3VT1CGv9ZWMWCjY0U5/opDwXQgBWbIzTEjQ7vadtSdX0TK177HfkjTkXfYtijv/+R9PzxM7jzdjxvdW9xesw0/B4XsZRJJGni2uVvZvf5XFAY9LKpwSmc0ZL/mbbzOdE1MuebFnpmYWtImTbr6+J0z/cyomeI176sYE1tnIBXzxpK2C3Hyydr6/lyQ2NWJcdTh5Y6xY9W12XWItQAr0vHshXhuIXyg2HZ1MfSLNscpT6WYlBpLn2KgizY0Mja2ji2UvjcOh6XjselEU2ZRFMmow5yesMyx7n5vNwj5GfW15U0xI3tXniePqwsc1Mk1+emMOilJpLE23wTK9fvziq6Ul4QoKop6QwpbX6dlGlhWYpYyiTodWHaNmnrmyOZSFsUBLx0z/OxoSHRqu+Qfb2Ho8WO1qNszegT0Xn2lwIy7bqCmTBhAtdccw0vv/wy/fv3B5yE7frrr2fChAkdGqAQ4humafPRylp0reWucUshfeciRddg7qpaTHPAThO39nzxtGWx5rX1cafAgNbc+7HFla1zYeOUZP9iYyMJ097lHa6aSIqmhOEsgLzFtaBznaYyz5s2bcoLPJg2mfWXDusVoi6Wlrufzfb03e5dLfVw/pG9W93La9o21U1pNOXcoEhvcQXe2ogVzsX95miK3kVBThtWyrKqJuKGiWXvOrkwbUVDNE3asNkcTjJ3dR1Br5uDi4Jb3DTpWEop4kveo+GdP2BF60ltXkXJ+XdlXRh3hYStRcq0aUqYBLwuDFsR8LqIbaci59ZazlC7brmtcMKke56fcMKZl7YlS5G1yLmd2e4sMeDWnZs8FlAfM/hsfZi0aVGS56Mox4dh2mxqjLOxMe6sGacUlkvfppLjCQO78++vKqiJJAl6XaRNi6RhZdZdS5oWCzeF8XtcRJMmoYCHgqCXPL+bUMBDca4HpTTyAx76dQ+ia86iEZ+vb2RZVZTiXB9Bn/ub83LQCwrqY2nK8v3N50OTPL+bQ7rn8NWmMH//bCON8VSmJ/uQklwiSYPNTSn8Hr15eL2ZKbpy8pAS/vn5puYeQ9tZdDuWIpwwqImmyPW5CXhdmbl1WyZkpwwp5fm5a3f5HbKv9HC09ty4vcJKuxp9IjrX/lJApl1J2wMPPMDpp5/O4MGD6dWrFwAbN27kuOOOY/r06R0aoBDiG5+ur2dFdRSfWyfX5ybZXH3NpTsT+qMpk+Wbo3y6vp5j+hXv9Ln25BfPgvUNxNImGuDWYOvaAl6XDprT41cfS+/yDpetVGbOyo4ukhXgcmk0xg1y/W4Kgh5qImk+WVvPt/oUyt1POu5u944ublqz1EP3XB8Hdwvy6fqGHS5G3JJgz19bR8JwFpBvmQPV8itUqlUj8ACnKmNLz90hJXl857AevLeilqRhtOrxlnIKnyQN58ZJXBlsaIg7n8MOztrSNWupf+tJUhsWZrYlNy7GrNuIp3jvFxlpDYVzw8SlawQ9OpFWDkNuSW7aY+GmCEFvjHh65/MSt9zn0pyKn1tW7XRpzpBtW0FT0kTXNSJJk3jKJGZY6GgUBj34vWRVcvxiQyNPv7+ahliKtGXTFDaxlDPvMOBx4XXrmJZiVU2UUMCDS9fI9blJmRaRsEFDLE3Q56Yx7nyWoimDgNfpGRtUlktFQ5JVNbHmdQJdjOhZwIjeIZ7/yBkmvrYunqkk6vc48/giKZOllRF0DaJJi6HlIUDh1p11DetiFkqBS9c4ul+Ai8f0pV9xLl9uCDNvTR0NsRRJwybX76a8IEBFY5yGeBrT8pAwTDSNrISsNd8h+0oPR1vPjW0dfSI61/5SQKbdwyM/+ugj3nrrLb788ksCgQAjRozg+OOP7+j4hBBbWLE5Stp01iSKpkzSlsqsxeR8gWsk0jYrNkd3mbTBnvniMU2bOStrmy8OwK3rKNPOXNzaChKGRUHAQ1HQ23wndud3uHwePdPDtrPrYx2cZNawsWzneHh0je8M73HA3/1s693uHSVmO7u48bp05q2uQ8cpod4QT+PSNPJ8brrl+tjclOT9FTWM7F3A+ro4Syqb8HtchAIeSvO81ERSuFw6o/oUYpo2tdF089ps3xSu0DTNWaqtDZlSJGlmDY0tCnoJeHQSaUjvYngkOOX4IymLWMoix+cCW1ETTaFpGrpS7eop2pqdjNI4589EPv8PqG+eMXDI0RSefBmegrIOeJU9xymmobAsm7jR+t9Ne/NdG2d9vLbYeiisBpniGm5NEU0Z1MXSWecaC0VtNI3b5ZynvC5nbb/qpiT1sbRT7MirgXKSNtNUWLbCtJxe5qRhkTKd4YT1cecmkmUp6uPpTC+epkGu37nBURNJUhNxEkm/R0dlKqLarK6JsnxzBI+uOzdE/G4iSYPVNTEAykI+cv1ufC6djY0JmpLNC8Qr6FngzN+rjRj4vXpmqLGua5w6tJQ3F1dRE3V68Dwup3/SicmFrRRfrG9kaI/8bW7q7eo7ZE/0cHT0aIH29gS2ZfSJ6Fz7SwGZdkenaRpjx45l7NixHRmPEGIn/B4XCqfAh6W2HB6pMK3mngjdmV/SWh39xfP5hgY2N6XID3iIpUzM5otuHaB5SKetoCDHS37Ag6XULu9wNcRauRZWc/W6ww/KdcpUa84CvMV5vl0/uFlXnyzfnvjaerd7R4nZ4B55/G9pNXXRFHl+N/l+D5Zt8/WmRirCCQ4tz6cqnCSRNkma36RVGlAQcBMKeqhsTFAQ9NC/JIdllRHqY2k2NST4Wn3T9uuNYX7/wSpG9SkCwO/RSRh282fHGSrp0jWsVna1eZqrVrbI8bhJGDZGKxK2rOOIk7y5m6seBrw6qZY/wnZSyia28B0a3n0WO96Y2e4u7EHRyZcT6H9k+598L3KKg9hEd17bpUtROJUofUpho+1wuQEbp/DJF+sbqG4ug6+UIuh1YdkQS1t43Tpp0yapbNKG2roqDinLpry55zmWMkk0Wigg3+cGzbm55HPrWB4Xq2pimLbtbHfpNCVMKr9KYNmKpGFTGPLgc+sopYgmrczNjKakSah5TcrlmyOsq4/j0jUO6Z6DpSCRsijO82WGjGeqtHpddM/zNffIOb3Sbl2nV2GQfsU5pEyb+liKHxx9EN/qU7TN+WZn3yEd3cOxo3PTqYeWEPC423ze3ld6AsXu2V8KyLQ6aXvkkUe4/PLL8fv9PPLIIztte9VVV+12YEKIbY06qABN00htVf1ANf+PpSDg0hh1UEGHvF57EoSWteR6hPxUNa/RppTKlGVHcxK4lmpliZS5yztcre1V8Xtc1MfTaGgU53qJJA38nh0/99bvL5G2eGtx150sv70CH4f2yKdXUZCA15W12PiWtne3WymVWRoh1+dmxeYImxoTpEyLP8xZy6bGOEVBL8U5Ply6xtebwry5uCqzJteWw7MKgx5iKYs1NVEaE9sW51BAQ8KkIWHi1iHX62JzUxqPW28e1mtltTVsqGpK85+vq/DoNA+dzM6N7K1fZCc8Li3rcxtJGxhmGzO2LbRc25vW7iVsAHWvP0Ls6/9mftbcPkKjzyf/yLPR3DtfuqOrsVXber88+jfDXPds2ZIds4FEK6pYOoVNFOGkQdp0Fm8vDHoJ+l3UxVKgFKba8RIG0ZRJLGlQlOv0ZLl0jbRpEzcsioIep6plyqAqnCRlWc6all5naRPDUtTHUtRGUuT63URTTq9A2rRJGJazzpuCaNKkPBSgV2GAWNpkQ0MCw7KpiaYIej2U5Pvp390pzuR165kerljaxOvWOaZfN+JpK2u5FE3TMG2bWMoknrZYXh1pU1LUkT0cO+oRm7e6jjcXV9E9z4fXrbfpvN2V5jp19RuG+7L9pYBMq5O2hx56iAsuuAC/389DDz20w3aapknSJsQeouka+i4uLrTmdrtrZXWE17+uYv7aeqIpk1yfmyP7FnHG8LKdfhG2rCUH0KswSF0sRV00jWnZuFxa87wknZI8H5ZlsagiTFm+M3+iR74ft1vf5suLVl5fu3RnmGh9PE3KtNjUmOCovt22e/ds6zu2adOmJuL0IPUI+bfpRWqZ/7GpMUEk6RQ/yPW7yfN59sqX6/YKfMRSJu8vrwGci6OA10XfbjlcNKYvJw8pzTw2ljZJGCa5lpvaaIp4ymRTQ4yNDUmSlo1P18jxuVlUEeaTNfV8urYeTXMuaNy6TlHQS0m+l8pwEttWhAJu8gJePM0XlDWRFLoGlY3JXVZTNG34dG09Aa8bXYfa2M7nlRnNCypvSdG29b2qIqmsnyMpA6O1E+J2wm4uLb87cg89KZO0BQeOpvDkS3Hnl+x2bPsCw3bmvHZWwtYWtmruaU0YzhDJ5iUFBpTksKY2hmGpnc6xtGxY35Ag4HVjKWcesq5rGJZN3LDZ0JggbVjE0jaa5txosJUzvLJliHFNJOXMHWwuw+/SNWxlo5RTBEXXNPL9Hj5d10hVOIHVvGK53+NmSFkevYuC210GpSWxShhWpqz/liobE6yti/Hix+txubQ2JUUd1cOxox4xw1I0xNPURFO4XRrHHNwts1RDa4qcdJW5TvtLdc2ubH8oINPqpG3NmjXb/W8hxN6zuja6wyE8LVKmzeraKAcX57b7dVZWR7jztSUs3BQmZVrYtkLXNRZVNPHpugZ+NX7IDk9wLWvJLa+OcFBhgOJcX2Z+k23ZmMqp5lcfS/LOshqShsWq6hifr2+gb7ccxh5aSlPCzPryiqfMVtV7iCVNbGDBugZSlk3A46Z/cYrVtdGseLe+Yxvw+Jm3uo6NDXHczWuJuTQtqxfpxY/XU5jjZcGGBlZVx0gYFgGvi37FORxxUFGrvlzbeyd1ywIfHh18XjfRpEl9zMC0FLru9ATk+dwsr45wz+tLsZVicFk+sbTJ4oom1tXGWb456tx5jzgFB1oqjwJo0TT3vb6EtKXw6BoFzcm3YdlUR5JUR5xhjy3zY1oWR/e5Nbw5XjY2xIm2ZoIYEDMUsVYWAekIiZSNadpUNiVZUtnEn+etx7TbMitu+1pRIDGLUjZ2IoIrGMps8/cZQf4x5+I/6DACB4/czYj2Pbs4nXU5hu0sK5Dnd6NrGvUxA8u2W1UUpyXBcOk6uqaR43WWSUgazvBKTdOcm24KkqZNZTjpJHfNwyfdzUler6IAybTN5kiyubfXxuPS0TRYXx9rXhfOhcflzAVOGTYra2Lk+j0U5Ti9t1v2cO0ssaqLJpm/toGA10V5gZ8cn2eb+V4tN7O2d17rqB6OHY0WWFntrJfYshB4PO0knq0d2tgV5jrtK9U19wf7egGZNn8KDcNg0KBBvPbaa9tdYFsIsWfYtmL+6vpdXhxYCpZXRTh5cFnmcW05Qdm24rF3VvLpunpsW+F16bjdzvC0eNrk03X1PP7OKqZ/77DtPo/brXPRmL7c8e/FLKmK4NI0NM0pUpCynOfzezTmrw2jUJSFfBQ0L/S6uLKJLzc2MqA0l8N6FWS+vNbWRlp1gR1OGrh1HZ9LJ8/voUe+j02NcZ79cG3mi297d2ybEgb18TSgEU1ZaLpOrwJ/89IBKUxbsbo2SmGOl6rGJAnDqTIXbV6XqjFu7PLLdXfupG5siDNvdR2WbaOURjicpDFhYClw685FXlPSpDDopTTPx6aGBHf/ZwmH9y6gPpZmfX2cSNIZAhVLGiS2yjZahteurUvgdsFhvQpw6S1JmbMo76bGBKnmoVhb5yqa5lxYdtXrb0PBvbOXsrY2xuLKJqIpc6/HmqpcTv1bT6DpHkovuC/rwrjwhIv2cjRidyggkTZpQFEVTrQ6ebcVFOZ4GVYeYkllE6uqo/jcLnoXBXG7NKJJk4QRp3mdcGxbketzeuaShoVh2yjbKbY0rDyHpqTB3FV1VIUTxNNOz2806YyKcOd40TVnLHpJnrMw+6qaKIXBQoCsHq4dJVbxlMknaxoAOKpvEfkBJ+Hbcr5Xy82s1TWxHZ7XOqKHY3s9YpGkSUM83VwwRSOeTmfWk2vt0MbOnuskc+r2vn25gEybkzaPx0Mqldpm7K8QYs9pueB/c3FVq9rXNKWyHre9RGFHd0fX18WYs6IWw7RBKSLNa6NpmjOUybI15qysYX1djL7dt9+b16dbkIOLg8RSJinTQtlOhct8v4d+3XOIpgx8Hp2DuwXRm5ODXJ9G2J0mmrKobkqR43Wh6xp5fg99u+Xy+YamXb5vt64T8LppSpqEkwabm5KEAm5Kot9Mut/eHduUaRGOG9hAjs+FYdqYlsLnceEJelhZEyNlWMTTJmlTketzSng7cz0sNjYkCHhcO/xy3d07qatrY9RGUpjKqUqXNq1M8m42XzAaps2mcAKXrpMyLKJpkyE98kg3//6CXp1wwqRpqxJ6aqv/NyxnCFjBFgv7appTrrwaJ/neegVAZ+H0jqihuOe8NH89bpfuHLu9GKsVD9P4/gtEv3yTlqMcW/QOucNO2msxiI5n2NCUbPu8yFjSojjXR59uQZZVRfG4dbxuDa/bhdG89IACfC5nIXDLVrhdGi6vM3xR0zXCcYNorknatEmZtlNFGOdvU8OpTFkfN8j1uQj5PTTEDbxundpoispwgmjK2qaHa3uJlWkr3C6dI3vm0y03u5iT05un87+l1RzULUj/7rk7Pa/tbg/H9nrE0paNadnYLo2mtI2tnGGl4JyTTMup8rqqJrrD1+rsuU5daU6d6Pra1d87depU7rvvPn7/+9/jdnft8phC7Ou2vOD3uXa8YPaWbGXvNFFYUtVESZ6PxrhBwrCwlaJHyM/JQ0qpCicIJwzSzVlBy9eIUpBu7pJpjBt8uq5hu0lby53DoNfND47sRVVTirhhEfS4KMn18u6KWtbWxinJ9WZ9SaVNm6TpVH8MJwwqw0l6FjpfUi6tdf0ihmmjac6wRY+uYdiK+phBU3Mv05mHlW/3jm3atDFthdet49Z1TMtqnjfmDGmybJu05QwnzPe7cTdfGHhcOrk+Zw2kxmQ6U8xjyy/XjriTaitFwnCqzVmW3VxOfFuW5QxlNSwnUVtbGydhWOR4XeT6fUSSkVYdx6pIilAw+/fjdTm9aV63TlMinTUUUtk2OT430HVLB0ZTFgqLXK/zO27fks6tp2yL6Jdv0Pj+C9jJaGa7p9tBuEMHxpy1/V1be2t1wLKdZKA2miYU9FCS6yNl2sTSaSxL4XHr2JbCVqApha0Upg0pw8Lj0ikMeulfmsuKzRFWVUdJmTYHFQWoDCeJGnbzUGktE5/XrZPjdRM3LGdEQcxgVPO6lVvfKNo6saoKJ3lp/nrKC7ZNFpRyRnAkDIvykB+loCHuLIFwSPccVtbEtjmv7U4Px/Z6xOIpk8aEQW00hWE5i7ovq4yQ43fm/zXG0hi2zYsfr2fRpqadrrm2o57AU4aW4HO7WFrVtEeG0nWVOXVi39CujOvjjz/m7bff5s0332T48OHk5ORk7f/nP//ZIcEBbNq0iRtvvJHXX3+dRCLBwIEDeeaZZxg1ahTgnDjuuOMOfve739HQ0MDRRx/NY489xqGHHpp5jlQqxQ033MCLL75IIpHg5JNP5vHHH88sDA7Q0NDAVVddxauvvgrAhAkTmDFjBgUFBZk269ev58orr+R///sfgUCAiRMnMn36dLzefavCl9h3bH3Bv6wy3KrHJdL2DhOFtGnz3vIaAh4Xh/bMpyHmTOL+ckMj7y2roTTPm5WwtVR8ZIsKb2lLEU1uf07SlncOXS4X5QUBIkmTNbVRPlpVR100ScqCTY1JGhImZSE/hUEvVvMFis+tEUk6VdVaLK+Otep9GwpyXdo38610Zy5IU9JkxeYo4WSakN+bdcdWKeUke0AybWK7XSj1zYWPaSunaIVyCp20DBuElru5NrbtFOPoFvRu8+XaEXdSg14XmqY58e2k0l7ChC2TkRWbI2iaRtCr4/e4Seygxn0mMW85jqZNXSxNnt+dmdfWlDQJ+tzk+dzUx9LEjGSmBzbH6yIU3HY+SFfS8t5iaXubnsKOltq0hPq3niS9eVVmm+YNUPB/F5B3xHg0l9zsPBD5PS4ShlM+f2h5Pj63k4QZlnKWQ7GdnrVIyiSeNrFtRcq00DUdXdcoy/Phc+t8vq6eTQ1Jwgnj/7P333FyneXdP/6+79Omz/aiLlmSe+82YIyNTYAAgUDymBAgoQTzC/EDDglJSJ4klAeSEAJJwBDABAI86V9KMC5Ud2PjKlu2etu+O31Ov39/nJnRrrSrnV3tSpZ83q+XQZo9M3PPaGfO+dzXdX0+aAL2NNp9m1pCCEHTQNbxQ7IJwdquFFU34J0vWc8l67rnFB7ThVXa1Eka+qzzXmXbZ7wcdV09ureI60cGKroWGRcN5K0lrRAdWhFLGpKtIyW8RqUxbUZul1uGStS8AE2A1jBRSply3q6G2SqBdTfgjqeW1xzk+TBTF3PisKjfgo6ODt7whjcs9VoOY2pqiiuvvJKrr76a73//+/T19bF9+/YZQuqTn/wkn/rUp7j11lvZvHkzH/nIR3j5y1/O1q1byWajD9VNN93Ed77zHb71rW/R3d3NBz7wAV796lfz8MMPo2lRntUNN9zAvn37uO222wB417vexVve8ha+853vANEO9qte9Sp6e3u5++67mZiY4K1vfStKKT772c8u+3sR88Jk+gX/VM1ltNxeJWN/wcYLOUwoKKXYPlZFCoEbBGw5UMIPwsaFvUbNDXhuFoE0WxTVT54b5UWbe1tzYtN3Z+tewAozyWTVYdtohZ3jVcYrDqGiFeoK0Qlp90QNxwtImTpSgONHzmqpaVlzpXr7phUl249ad8zo/rJhUR/NxlV55Vn51o6t64dsH6uyd6pKzfXxw+ii3tSifLdsIjpxSxEFhUuiVkpdRkKm4vh4jdYk23Nx/RKP7i1w2kCutZ7ZdlKn2+1rQmB7wRF3UnMJg6ShUbIXttvqK5BKUXUCqm7QaqU8lOmGJBCFmeeTBjU3oOL46EJgGRqndSR46kAZxw/JmDqaFmWl1b2AetGZ/cGfZyiWr8YWVKeY+vGtVJ+8a8bt6TOvpvOlv4WW6VymZ455vpM0JBet7cDQNd591QYyps6fffspHt9XJGVqUTSJFX2m+rMWI42ieMbSMbXIbdf2A7aOVEjoko6Uge1FrrfO9E02BYIQVwkcP0AAU1WXPYZGXzbBz3dO0ZOx2hIdR5r3Gi3bHChGmXWletR+mTI1MhL2FWrsK9TIJXSeGy0vWXVqY1+Wt16xln/7+T7uenqkMcdrUPdDJFHbqN0wztK0KK9UCNg2VuPcVXnGKy7/+vO9vO78lbO6/k4XrNtGy3z1vuU3BzneM3UxJxaLEm1f+cpXlnods/KJT3yC1atXz3i+devWtf6slOLTn/40f/zHf8zrX/96AL761a/S39/PN77xDd797ndTLBb50pe+xNe+9jWuvfZaAL7+9a+zevVq7rzzTq6//nqefvppbrvtNu6//34uvfRSAL74xS9y+eWXs3XrVk499VRuv/12tmzZwt69e1mxYgUAf/M3f8Pb3vY2PvrRj5LLHbxIi4lZKpoX/EkjwTNDZcKwvRkKKdWsLRfNwe180mBfoYYkwA2CyEmw6UYxjSOlFw0XbL5yzy5edlofzwyVW7uRQaDYOxVleO2aqDFRcSg2TDPgoFV7FI0UBRvtm6qTT+p4QdQiOZBLMJhPtJ6rtoDWkEBFr9PSo91ppaL2PSkFAtHasX16uMRPnh1rBNYGSCmQKmpLChVRNcnxWdOVxPZCpmoujn+wAtgUQFJEQlSFkUvbP/10J70Zq2W5f+hO6mTVYftolcmaix9G77ulS8bLDgzM/poylh65yx3h32MuwuZ7Ps8dp/9YhSGrO5Pkkkbrd2YwZ/HcaBVDkyQNidNoKdU1QY9lMlH1FrG648NyrdIvDM8QbEbvOrquew+JVWce4V4xJztCwJquFClL55xVHZTqPh/93tPsL9SijRHbJ2lqVGwfJwgpKcWKvMXm/hwpS6fm+OybqPDk/hKBivLtio3W9ukbMc2PeTgtJqNY9zE06EpbDOYtHto9yYFind960fp5Rcdc815DhTqP7J7CC0JMXZJL6oSN792JqotS4AUhUsDHvvc0dz87zg2XrWlb5MxlnrVttMwdT42ye6JG1QlIGhpdGYsV+QSP7StStEPCMOqIEELQmzHJJQ0mqy5PHigigacOFHl2pExXypqzanYszUGO90xdzInFgrpEwjDkr/7qr7jyyiu55JJL+KM/+iNs216utfHtb3+biy66iDe+8Y309fVx/vnn88UvfrH18507dzI8PMx1113Xus2yLK666iruvfdeAB5++GE8z5txzIoVKzjrrLNax9x3333k8/mWYAO47LLLyOfzM44566yzWoIN4Prrr8dxHB5++OE5X4PjOJRKpRn/xcS0S/OCf6zsMFlzoxDVNuhKHRQK02kObntBQN0NKNkedTdEk1FLYWSuMf/jC2BFZ5I9EzU+c9dzPLG/SEfKYENPhhUdCbwg5L4dE+yfqmF7wbyZWkEjGLbuRQdmk3qjMhRStj3cOdr65sILVfRaw6gKRMNIozcbDdNv6MnQl7VI6LKxUx2S0KPd7mxCI2FIMpZGytQo1gMsXaJrEj+M5kumv0ehii6STEOyvidJ2fH46r278BsHNXdSh4o24+U6D+6cZO9UDSEgn9DxA4UfKv7niSG2jc4+c3ZoJWw5yVoaPdlIqE5WXaQQXLq+m0s39DSiEKJQ6SBUURSEEHRlLDKJ9n43T2aslaeTPutahJWm89p3M/i2v4sFWwxCwUTFRdckm/szfPaHzzXiRSSGJgmBkt2YzfLDxuyaha5JJqsuD+2a5ImhMl4YbRLV3IDJmtfWd7UC3ACqjsfuiRojRZuf757imw/saSugvjnvddaKPIWax86xCs8MV7AMScaK2qcF0Sa664c4Xojnh2gCdBl1Edzx9AifvvO5Ob/fprNttMw//mgbH/nuFj7yvS185Ltb+McfbeOup0f4yj27ePJAsTGjq9GVNinVPZ4brSAFdKcNTF2SSehYmsBoxCjoUrCr0e2hScFALklHyuDJA0W+cs+uw9a1kJb2+QhDxZ6JKj/eOsqPt46ye6J62Pt+6Hu8a7xKoeZx9sp8bPcfM4MFVdo+8YlP8Cd/8idcc801JJNJPvWpTzE+Ps4XvvCFZVncjh07+NznPsf73/9+/uiP/ogHH3yQ973vfViWxW/+5m8yPBw56fX398+4X39/P7t37wZgeHgY0zTp7Ow87Jjm/YeHh+nrO3wwvK+vb8Yxhz5PZ2cnpmm2jpmNj3/84/z5n//5Al95zMlOuzb8zQv++3aM4wUB7V66B4FgU//hLRemJtGlYKru4TR8qjUtCn5VInJ4NDTFfHFbChgvO3ghFGoe56/uaPXj55ImZwzm2DleI1SR02A7lQ0vhJQpGMgn6E5bTFVdRkohlq6xsjvN1IH2TDSaVByPpGGQMiWOr9jcn+WC1dH3wP5CnULN49zVHfxiT4EePZpzC8IoR6nqBtS9kIQRtYz25y28IGR4jjcmJLqYKtYDMpbGzvEqj+yd4pL13QCcuzrPAzsmuHfbOLbno0nJRNVBbwiei9d2Mlnz5ty9rbp+wxlueWtZ0eMLXryxh7e9aH3DxCT6/bz13l2tGZpQRbN+TYOUsu3NaY5ysuKXJ6j84n/Iv+gGhDwoWDuvfjudL30bWrrj+C0u5nmFJsENQwwpeGDnJAcaF/uOH20WWZrA9SV1P6r4dyR1pmou28cqFOoubhB9j8qGEHL9hWcMVhyf/nwCQ9OYrDj84KlhTunL8OJNvfO2L06f99o+VuGbD+4haaR5ZE+Buhtlo7l+iNew20eApkXRKx0pg7oX8uxImR88OcyGl85dndo2WubTdz7HsyNlgmnCZsd4he88foC+XILzV3dQtn0MTUMQzdPuL9QpOwEJQ+IG0To0KfD8EGVEreheoEiYUbZe0tCOWDVbKnOQbaNlvvHAHu7fMUGx5qEEdCRNLlvfdVjl8UTPD4s5NixItN1666189rOf5cYbbwTgtttu43Wvex233HLLskQAhGHIRRddxMc+9jEAzj//fJ566ik+97nP8Zu/+Zut4w59bqXUvOs59JjZjl/MMYfyoQ99iPe///2tv5dKJVavXn3EtcWc3Cwkr6vZOvHsSJkdY1VqTnttgmOVOr931qmHtVyAinZ1G/b2AFHH5UHjd72Nj7IuYKzsUnF9kobOWCUaSM8mIoFYtv3IBr5hVNEOKVPSkTTIJw0SmuCKjT30Zi029KTZPlLm7f88d0V7NnwfHBFdTPRkTd56xTr0xnR+86ScSxgIEbW9NI1HkqaG7QUU6h4b+zI8M1TCDxS1xmzbXEYgoVLR43oAgomq2/q3/sXeKR7bV6DYnEkLDm6Ru6HNkwdKnNKbnnNwv9k2tdyySBEFB++Zii4qN/dlkVIQhornRsr4jay9Qzf4/TZ27E8WVOBTfvjbFO75Jsqto+V6yZ73itbPpwdnxywfGrBww/3jw9ruFF6geHJ/kZ6MGYkbITBEJKb8MAQVfYcUah7Fmkc2EVX6wzDabJNCUXcbpkiLwPUVExWX3oyFH4ZMVj1u+cl2Hto5yca+bNvmGnUvwPFD+rIWKVNHk4KxkkPdm/b9pCJxqWuRU2vGkkzVXO7ZNs7F67u4aG3XYWIkDBXfuH8Pj+0tYOpRzqahCbxAMVl1GC876LLZpqiT0CV7pmoEoaLmBPiNuANDClw/Em0T1WgGvOoGGJrA8QJWdqbIJqJL37mMoJbCHKQpQB/bW0AT0J01EQgKNY87nh5htOJw07WbZrznJ3J+WMyxYUGibffu3bz61a9u/f36669HKcWBAwdYuXLlki9ucHDwsADv008/nf/4j/8AYGAgGgAZHh5mcHCwdczo6GirKjYwMIDrukxNTc2oto2OjnLFFVe0jhkZGTns+cfGxmY8zgMPPDDj51NTU3ied1gFbjqWZWFZ1pw/j3lhsW20zJfv3sn+Qp3OlElP2kKTHHG4eWNflvdevZG//O4WDhTba0feN1Wf08a4O22wfXTuvhq/jWuCQEHZ8ai5IbYb8OT+IkmzSlfKZENviqFi5Cy4kP5rx1dMVD2KdkDatLGDkN5MglN6M/TlTBZq0h4Q7WTrUrQEWZPmSTkIQ3RN4gWRa2WrxccP0aVEE4IgjFqLHD+ai1PB7Lvcrq/IJkTDuCSyo/7KPbuYqDjsHKtQnaVKJ6BhhlLBC0J6Mtasu7dpQ8fzg2MyMRaGIQ/unOCj393Cuas7uf6sfgxNsnMs2v1+fqexLS/1XY8ydecteBN7W7eVHvovMudehxDL7UkZM50TRbBJQBMC3ZSMlmyChuOslIKCG7VwH/q5joyNgmg2LFSYApKmju1Fs8GL2SIPgULNxQsUfhhi6aKx0RTw4K4J9hfq/NaLZm/Fm77ROFF1eHakzHDRxvMDxssOoTp8FrrmBCR0SaAUkxWXou1RdXxu+ckOHlozdZhI3DtV4/6dk0gh6E4fjBux9Cjfc6zsMFyyKdkeQRit2/PDlmulIIpnEUIhZdQS6QYhkzUX2/NJmTrZhMEpvZkZG+2zVc2O1hwkDBW3PTnMs8NlTE3QnbFaj9Gfk0xU3bYqjzExh7Ig0ea6LsnkwV9SIQSmaeI4y+MaduWVV7J169YZtz377LOsXbsWgPXr1zMwMMAdd9zB+eef31rjT37yEz7xiU8AcOGFF2IYBnfccQdvetObABgaGuLJJ5/kk5/8JACXX345xWKRBx98kEsuuQSIYg2KxWJL2F1++eV89KMfZWhoqCUQb7/9dizLasUPxJwYtNuauBzP+4379/Dz3VNIYP9UHb2Zu9ObZqLqztket3kgyx/80qn87LPjbT1X09r90JYLUxO8/csPRScQNb8EmKsdTwFlp9FeKSCfNJBSMFq2mag6FGouiPYMMFqPGSqcUOH4IWlDsL47g64JnjxQpLzDQ8rmgH376BJShqRse3zmrudY3Zli80C2dVJ+Yn+BzlR0QRAYGlM1l7oXGbMkTY3nRiuYusTxA9wgPOJsXqDAbjg0ZizJ00MlJqsufRmTnz5no2Z5v5teLHU3oFB1gKh151B+sm2MqnNsLlO9AGRkQdfK9JMoHt1XnHc28WTFL40x9cMvUdt697RbBZnzrqfjJb8ZC7aYOQmB8YpL0Pichypqd3TdI3+ZOQG4QdAKzXZ8RdLQqLiL37xxfIUUfqNjIIopqbmTpE2NPRN1LEPw4VedOeP8Mz3vM2lIbDdozLtWCJuC85AFNc8bZccnmKoTNlq7E4ZGQpc8sf/wTcqd41UK9agSKMTBDbTmXLIuRTTLV3UZL7sopVjRkWTPZFRta+bTKSBtaaRMnYrtU6h50RxbR4Lz13TSlZ4Z0TRb1exozUH2F+o8sb9IoBTZpHFYx1Y2oVO2fR7fV4xDs2MWxILdIz/84Q+TSh38BXNdl49+9KPk8wdbQj71qU8tyeL+9//+31xxxRV87GMf401vehMPPvggX/jCF1ozdEIIbrrpJj72sY+xadMmNm3axMc+9jFSqRQ33HADAPl8nt/+7d/mAx/4AN3d3XR1dXHzzTdz9tlnt9wkTz/9dF7xilfwzne+k1tuuQWILP9f/epXc+qppwJw3XXXccYZZ/CWt7yFv/qrv2JycpKbb76Zd77znbFz5AnEQloTl5p7to/zo62jhAo602ar9WOsbFNxfDb1HWyPW9mRnCEsf/TMCF+6e2fbz1VzwsPE6ea+LP/z5AHGKg4pQ1By5j/1t3NxEKjooiJp6phpyYHGvNhCL/CnS5JARSHWmhYNu//gqaG2hu4PxW1c+AgC3KDCvz+ylz98xelANGf25IECVcen6kRRBaAapixRTIDfcEebqM5vpgJQcQMylk5/zmLLgRJ9uQQ7xms4jcH8uTqbAhW18HSmo4ub6f92j+4t8NV7drVVAT1adBl1brpBiKVLcgmD27eMUHN97GOxgOcZyvco/fy/Kd77LZR3cHPSHDyVrpf/DtbgpuO4upgThWLDEj9j6WQSGoV6e23urdzEEPQgJGVp1L3Ixn8xH8eoghfOqJY7vhcJGw3+65HILXFjX5aJqktnyuDBHZPsm6qRsXSeOlDCDxX9OYvRUvS6mu3i0+WLJkDXRCvPU4qoqoeAp4dL9DU6Cg7dpBQKFIq66zNZ9ag4HnU3IAhV67vzyX0FlBDkkwZBqKJqXuP805EyKNY9am4Uy9KdMQlCxakDOQQKTcB4xcHUZKtFcq6q2ZECt2cLJp9O1fUbJmAKQzt8Q6d5W83z49DsmAWxINH2kpe85LDK1xVXXMGOHTtaf1/K2baLL76Y//qv/+JDH/oQf/EXf8H69ev59Kc/zZvf/ObWMR/84Aep1+vceOONrXDt22+/vZXRBvC3f/u36LrOm970pla49q233trKaAP4l3/5F973vve1XCZf85rX8Pd///etn2uaxve+9z1uvPFGrrzyyhnh2jEnBtN3DJczd2U2wlBx19Mj1L2AVZ3JVkCzpQvMtMlk1WV/waY7bfD0cIlvP3qgJSz3T9V5eqiMG7SvWoIQPvfj7YeJ05LjRe053tJdgAcKxioOIdFQuCZEKzdosRTrHj/aOsr63jTdKZNyrb18urlQQNkO+PEzo7x4Uy+P7S1w344Jdo5VKNk+jhdGpikCLF0jZWn0ZizW96QYLTnsmay19Txho3VpouIyWnYYKTtUbI8wnL+10/YD0lYUDvv//WI/D+6cZLxqs3uyju0dm6bE5q+YUjBRtnlo9xQTVfcFWWELPYehW38Pf3Jf6zaZzNH50reRPvvauLoW0za+gtAP6UqbuIvc/Kj7kYW+FCxqA6vJoXeVIrpNBVDyPf7yO1tIJwz8INr4c4OQjqQRVQcbf06bFt0Zk4rtEyjVEmyy0cARxYwcjE8RKHQJAsFU1WOi4pK2NEKlePU5g6zpTrOhJ00+ZTBecfEaLeqOH7TaR5vv2t6C3cjNFBhS4oUKS9foz0XVsGxCZ7zicOaKHClTxw9CLjulm288sIcn9pcwdRn9p0lMXbC6K821p89eNVusOUja1EmZOiDwgshMazpNw5aUoS9raPbx6iqKWT6Emq1nJ2bZKJVK5PN5isViXKE7hoSh4nM/3s6TB4ozclcg6lF/brTC2Svz/M5VpyzLl9reyRof+d4Wto1WyCb0w77EHT+gbPsM5BL0ZCzcIGQwn8DSJP98/y6q87TSHIoAXnHWQEOc6tRcn6GiTbnu8cCuyUUPs8+FJcHQNQxdogvFWPXodw+TjZw1KSNjk6XAkHDO6g7Gyy5TNTdyZBSKuhtdEEVtOSAlJA2NzpSJoUu2jVQWNMslBZhaNOQuhWDHeK2tqmU+oZMyZSQk/fCoLs6OlowpqbnhC3qGbeIH/0Dl0e+DkGTPfyX5F/8GWiJzvJcVcwKiCTB1Sdgw83k+oInIKEqFMzsdpIhm8abry4QuSFtRHpuhSbpSBnsma9S9EK3RmpixNOpeJLjUNMMmQ4NcwkQKRc0NcYMQpRSmpvHGC1fxlivWsqEnw19+dwv/8Yt9+H5kauL4YSNO4JAcycbaO5IGhhEJsIFcZM/v+FH75mXruxgpOwzmE9hewN6pOjXHb7TvRzPKpi45YzDHizb2Lmm3TRgq/vHH2/j2owcIwnDGTJtSiomqiyYFrz13Be956cZlueY4nl1FMQunXW2wfBI/JuZ5xEJyV5ajv7zq+kgh6M1YjFUclBXtRGoiasPTpaBie9STBo4fsqkvTcUJeGJ/ccGCDaKT2myhoE/vLxAswwWDItr5DA49ux4FXhAiQhH1zCwRXghP7S9i6RKlIGVqjVm1sNF+Ez2XCMEPIuFkamLhL0lFWWb7CjZru5KYWnvVx6Lt06bXzLLj+C8swaZ8F6Q2w76/4yVvIahM0PHi38Ds23AcVxdzImNqkDJ1Srb/vKpaB3PMHM+2RttXSBF1A3hBlJ+JiO4euTpGbpGdhoYXqMj0JIw2EDuSJkJAxQkIQzCkwAsjp9otQwU++0OPV509yNmr8ty+ZZhS6FF1Ds7uTR/Bbt4WqGizM21Fm6CTVZe0pVOxPTrSJsMlh+60CQqmGrE0kzWXh3ZOkk3AoKXh+lH18In9hSXttpFS8IqzBnhmuMxjewuMlGzyKQMQFGseoVKcu7qD688aWDbBdry6imKWl1i0xbwgWKrclcWSNnWShoaf0Nk5XmWkZKNJEc1PaRIhot3LpKmRMiUP7y4wWXMZmqou+jlnE6e6ri2LA6EmBQlTw/GCJauK+QokCrHEysH2FUEYOTz6oZo1X0wRXRTUvRDXW7gODYl2l/1Asb9gk7Z0nJq3FMs/ZmgCTqwVL57atgeZuusLZC98DbmLXtO6XUvm6HvDnx7HlcWcDCgVVV+eT4JtPmb72q17IYiApCFbAkyXUeRHc3QraGQ4WobEc0IMGR1TccLoeK0xvxYqlFKU7YCHdk7yzFCJlZ1JdE3SkzGpuXU0Qet7era3zvYid8iVHUnSCZ3hooOuCTpTJmevzDPYkeB7jw/RlTZQSrFjtEoQqtbmreMHVJ2As1ckGCk7cxqBLYaNfVluunZTlNO2fYKRokOIoiNp8OKNvdxw2dplEU5hqPjBkyNMVt1ZN25ny6WLOXGIRVvMC4KlyF05GlZ2JOlIGTy0axJTF0ih4waRM1bJ89A0ycVru3CDkK0jZWwvMoJoO+RsFoIgZPt4hYrjk7F0TunJzNi9XEqaJwZB1Fq4VH7cy3WRE6oo8FYpNecFQZPFvhTXjy5Q/CCkqk68mtUCRihPWLypIabu+gL17Q8BUPjZ10mf/mK0dOc894yJaR8/hNIxcn9dThTgByE24AcBmowE1mQlsuGPDEAiB1xNQM2NWhCbLZHRdy6N4GxFEMJE1SWb0BuzXxKv0RJp6JKUEcWxOHO8d4ECxws4UKhz2fouLl7XzYVrO0kYkp89O85Pnx1l+3iVrpTB9oTBVM0lP83NUZeCuuczWnHIWBrPjZSXtNtmY1+WX79kNZoUPHWgiBeEdKZMujLLFwPVTlfRcyNlfr57klzSiGfdTjBi0RbzguBoc1eWhIYyMHWNrrSOUpG9ve1FzoRdKYOnhkoU6h4SKNS8WbO92uVr9++m6vooFWm/e80JconD7eSXgiAI8QNFOmFg6YLh8vO7RhMoCJbZDbFp1S2IZkZONJbQq+Z5R+jZlO7/d4oP/AcEB39Xzf4NhJ7D8nxKYl6onEwfJTdQ+GHQcJpVTFZdFAJNCPxAoRTomqIzbWJ7keOlQFDzAkQoEEJhaALbBUTUBj9V8/CDkGzCoDdjsb9QRxL9rH6E8QBFtAGnS8H1Zw3y+gtW8aOto/zN7c8yVnaQIhJ1UzUo2T41NyBt6lh6tFE7WrGpOQFb9pcwDYkgcrdcKtG2bbTMV+/dzWTV5bSBXGu+/KkDJYaK9rK0Kc7XVVT3ArYMlbjlJ9uxDG1Rs26xwcnxIxZtMS8IjjZ35WjZX6hTqHtcvK6TAwWb0bKDF4YYUrKiI8lgPkGx7lFxfMr1KFfGMjQMGbWGLIaK42NoUQtmECoqjk9piVoXDyWfMujOWGQsjd0TsYVxk6aT2kl11XYCo5Si/tx9TN71TwSl0dbtWqaLzqt/m9TpL1lSB+SYmJOJRmcjgYryHDUZVcuagdaWIelKmQRhiO2GrOlOUap7CBEZO+maQApBzYlCwnVNYOkaCoVSkkItikZIWxo1z48E4hG+O0VjLTU3QKF4dqTMZ+56juGSzWAuEXU6hFC2PaxGhMt41UEAwyWbmhuQTRr0ZE1qbkCh5vG9x4bY0JM+ajG1VG2KCxVIR+oqmqy6PLJ7irLt05226MslFjzrFhucHF/aFm2PP/542w96zjnnLGoxMTHLydHkrhwtzd2v5kA2KIJAoVRUaTN1jZpn4wdh48tdEAQqCjleJNHMXDQvp0kRmW0sk2tZzQ0Jyg5lWy6bMDwRibXa8wdvcj+Td96CvfORgzdKjdzFryN/+a8hrTjgNibmSDQz2ZroElCR22QQKCq+D0rRkTJRwGkDWRw/5NmRChUnwHaDxgwcIBoRMRLqniKT0OnLmkzVvNb9C3UPx5/7fNLKsQsU/9+jB/jXh/ZyoFBnRUcCy4jq5X1ZkyAMqLkhQkCp6hIEUStnytToy1hIIXC8gP6cxXjF4d9+vo/fv+5UdH3xsR7T2xQBSnUPNwhbGXHtmJ8tVCBFc5OKXFJn+1iFc1bmkY14IaUU20bLFOoeG3rSDDTaJxciImODk+NP26LtvPPOa6XUz7cTGQQnfu92zMnJYnNXjpa0qeP6IQ/vnqTmBthegONH82WFmsveqTp9WQtFZPterHuU3BD/KD5Klh7NA0T5YwJLlwRBsFTjZi0EkDQlisil6wWYwRxzAlB+9PszBFti7Xl0vfzdGN2rj+OqYmKWntks+5eClpsjkWDzGicTXx2cPy7aAQqPVZ1JSrbP265Yx6ONXMytQ6VGy37UNl51A+peiGVIkg3XybSlU3F8TuvPsnkgw5fu3hUZoBwBTULK0Ng6UqbuBTPmcZOmzmA+yWjZoWx7+EpRqnvkUwZ92QRSwnDRxgkit9ypqsuO8QrjFYfXnb+SK0/pWdT1QXOj1vY0nh6aYqrm4gdh5LCZMlnXk4qMUOYwP1uoQJou8MYrDnsnawwVbM5amWOwI8loyWb3RI3OlMHGQ2KP2nHQjg1Onh+0Ldp27tzZ+vMvfvELbr75Zn7/93+fyy+/HID77ruPv/mbv+GTn/zk0q8yJuYEZzCXwPFCRkoOrh+1fTRzwQRQ8ALCMCRhaBRtHykFuaRBzfGoHcVwkTrk/xfzVboybzFScjD0qLUlCBWur1ruYoIouDoKLRWYmsZUPa62xTy/6Ljyf1Hd8mOENOi85h2kNl8Rt0LGnHQM5gwqTkigFIEbLku1XwFhSCv0+tDnUEpRrvs865SpeQE3vnQj567u4Is/3cH20SpTdSeag1bRpmLoKkZKNoYmSegCx1es6Ejy+vNWcdeWEZ4eObKLcqhoCb+6GzBedUiZWuvznTR1VnVKhouCpKlFs3aGbIgmhdMwQbF0SanuUap7/HjrKI/snuLqU/u44bI1C64gTd+oDUJFJmFgJHS8QDFWtpmsOqzuSs1qfrZQgXSowFvRkaQnY/LkgRK/2FNgvOJiNCp8F6zppDNlHlb5m89B+3jHJsVEtC3a1q5d2/rzG9/4Rj7zmc/wyle+snXbOeecw+rVq/nwhz/M6173uiVdZEzMUnG8+rGHSjZ+GGJ7Pq6vECJqEVGoVlCo44UEoWhVxprtjYv1L/QChS5FKzDaCxSLkVLnrenkwZ2TuH6I4wctwdbcbTU0GV0ghCHruzPoQvHwvvKi1hwTsxR443txx3eTPu1FrduklabvV/8PRtcqpJk4jquLiVl6NBF1V1ywtpsDhRrPjlRIGhLXD5el++FIZyXbC6nrPoYm+fmuSV62uY/H9xZJWzrXnt7L3dsmsP2A8YrTcJKMcksFismajxCCA4U6n7h9KyV7/vNfqKKMy5ShYRsaFdvH8QIS0wRR1HUCF6/rouYGmJpE1wTPDJeRwiNlSEbKDo4XYuoaK/JRpfDu7ePYfsBvvWj9gq4Rmhu1hbrHms5kq03R0gVGymDPVJ1+P2Qwd/h30UIE0sqO5KwCb3VXmpUdSR7fX2RDT4ZXnNXPtx7ci+0F/HzXFJM1Fz8M0WU0hziQt47ooH28Y5NiIhbVsPvEE0+wfv36w25fv349W7ZsOepFxcQsB83dqCf2F9GlIJcw0KXgif1FvnLPLraNLp/QKNsew0WbQKlWBljIwR3KUIEThHhB1GefsfSWE9di0USjmkfULqMtcj7uqQMlhICOlIGlaxi6QBORYNO0KBjcauS/TdVcCieBtXXMiUno1Jj60Zc58JX/HxP/82n80viMn1sDG2PBFnNSIYjEWmfKoD+foC+bYFVnmiAEXVv8TNbR4IWKqZpH2tIZKzk8sneqJULyKZO+nEXdi4RT0tAamWkhXqAwGoNyP989xbaRMrY3twiQRGJViEj0daUtLEMiBUzWPBw/IFQK2/MZLtn0Zi1+84q1bOrLUnZ8DBmFXetSMFZxcf0QKQVpK6o8daYNJJGIuv2pEcIFmIINlWwsI/p3mZq2FscPorm9pIGpS4ZK9mH3PSiQZhdQSVNrtVYeSeBJKTmlN0Ox7jGQT9KZNnlo1xQjpToJI2rTTBiSkVKdh3ZN0ZEy5nTQnm5wMhvLHZsUE7GoT/Tpp5/ORz7yEWz74C+b4zh85CMf4fTTT1+yxcXELBXNdoM9kzWKNZfH9xf5+e5JHt9fpFhz2TNZW/CX8kKInBs9/GBmq2LzP0VUefMDRcbSsAyN/pwVDQsv8jltX+EGIaGK/t9e5HZrtBsKL9nUTU/GioJMTR1dkwShIiAaKE+ZOlM1j+HC4SehmJjlRClFdcuPOfBPv0Ppwf+EMEB5NqUH/v14Ly0mZkkw5OEXbIYGa7qTnNqfIZ8yGcwn8YKQbaMVFAo/XJ4q25FontPCRtSM44dMVN2WCBFCMJBLEIaRq3PK1MklNCxdkjI1DClBgeMHWIZGR8qacQ5s/lkTkfukLqNNyaylc0pfmpSpYxka+aROzQ0YK9uMlV0Gcwned80mThvIc/1Z/WhS8ONnxxgu2QwV6kxUXepulBHXlTIRQqBLge2HSCF4bG+BvVO1tt+Hqutj6pIL1nTSl01geyGFmovthfTlEly4thNLl7NWphYikNoWeI4/7eLjkKuKaTmrc9GMTRoq2qhDdpObsUkb+zLLG5sUszjL/89//vP88i//MqtXr+bcc88F4LHHHkMIwXe/+90lXWBMzFKwv1DnF3unGCvbkTBK6BhaFOg5VnHQpOCRPVPL1o+dMjVcX807WxYoxaqONH6omKy5eI1AUn+BOV8SyJgaVS/AD6J2zExCp1r3F9wiKYQgZWqU7Mh9qyNpMF528EOFLpuOVWBqEj8Ijpirs1gyBlSe39FvMccJd2wXk3d8Hmfvkwdv1Azyl/0quUt/9fgtLCZmCdBE1JkhBBh6w1VY0upuSBlaywmxJ2Py6N4pxioOCV2iVNjaFDxWiIYJCgJqtk+gFN1pc4YNfcrSySV1glBheyF+GI0EdKUt9hfrGJpEysj1uCttsG9K4Dacj6UAU5eESqELsP3o3HZKY76rLxdVG7vTRjQfLuCUvgy/esFqNg/MbG+UQkRVOlRkjjLNQKPuBoyWo1iAUCmCUPGVe3byG5etbatNsim8EobGRes6Kdv+jBmyiuNje+GslamF5MruL9TntPhvvg5L16g4fit2aKjoMFVzqTg+upT05xIM5Cymat6c10DHOzYpJmJRou2SSy5h586dfP3rX+eZZ55BKcWv/dqvccMNN5BOp5d6jTExR03Z9tgzUSMIQ7ozVutL0NI1zLRkouG2VLaXRxnU3IDpnSpznUSFEFQ9nys2dFNxAkbKNkNF+wj3mJ0QWNudxjIklqlFu5A9Gb70s+0LdqRM6AJTlyCidpuaFyKlRJORWKMxTB4ECj886CK2lGSSBhUvVm0xBwntCoW7/4XyI9+bkV6e3Hgpnde8E6Nj4DiuLiZmaQhUJILOHMwz2JnE90OKNZcdEzXcIKRY91vmE8+NVBirOPRnLSaqLlM1FykOt+pfLgRRNqUSoAlB3Q8YzCe4YHUnD+2caokQU5NRRUwXoKJWxt6sxap8gt2TVSxdQiOwW0rJYEeCvZP1aKxARa35rg+1QGFIwbmrOqh5kXhY05XirZevI2lqszpEN7tuglDxqrMHuHfHJMNFG134WIbEDRQjZZsgCKl7Idmk3qjahewcr/KVe3a1ZW0/XXht6suQSx4UVIcKr0NZiEBqV+BlEjq2H7ChJ8OqztRhIjJQil3j1SPOpB3P2KSYiEU3n6ZSKd71rnct5VpiYpaNiuNT9wKyiehX3vECAqXQRCRILEOjbPtUnOUZos0k9Eav/pFJ6NEX6LaxKoP5BIY8uMO4ULaNVTB1jXXdKdZ3p5FSoDW3bReA4waQhM6kQWfKYNd4jVA13bcUXqCwvYAgjPJ5wjCgtsT6qjNhMlyKRVtMhDO8jdF/+z+EtULrNr1jkK5r30XylIuP38JiYpYBBfTnLNb3pKm7AVJKruhMcd7qPA/tnOKZoRI7xqrUXJ+EoVH3AmquTxiqhX7dH/U6ITrFqEBh6hrXnN6PrssZImQgZ9GRNBgq1tE1SUfK5MwVeUqNTVM/CMkmzWizEOjPRcLmwFQdN4yMTjQpySd01nanyCZ0CjWvLfEwfQZM0zTOXJHH9cOGPX/kIlmouUghyCZ0etMWdTegP5fgnJV5to1Vuf2pEdZ1pRlqGG+kTZ3BXGLG31d2JI+qMtWuQGpX4Fm6NqMiN11EAtQdv62ZtOMVmxQTsWjR9rWvfY1bbrmFHTt2cN9997F27Vr+9m//lg0bNvDa1752KdcYE3PUZBqWtuW6T7HmRmHQDdGWMiVSSFKWRibR/kciDFXbX1xpU28rv9DxQ956xTq27C+zfazCM8OLN0cJwmjoecdYhWLdZVVXipylUVmgu1PdDxEoXD+gUPMo2h62F6A3hhc0Ec22SSmwDImzDNrKDpa+5TLmxMXoWoXQos+q0C3yl7+J3CW/gtDN47yymJjDSRlge7DYbzEpwA9Ddo1XsXSNc1blOXUgyz3bxnl0zxRTthcJtDD6nt47VScMFSlTI3SDBQk3Uzb29Q4xy1ooCuhKG1y+vhs4XISYumy5JG/qS5NL6tRdrzUP15mcWTXqyyZQKjqvvea8FZyxIse1m/sZq7kLEg+HuiB2pU3OX9OJvl+wa7xK2fbwAkU2ERmC1VyflKVzSm86qvrlEzyyZ4pP/mAr4xUH2w8iZ+VG3pypyxmu1EdTmWpXILUj8MJQtd1yOR9SitjW/zixKNH2uc99jj/90z/lpptu4iMf+UjrYrSzs5NPf/rTsWiLed6RtQy60yZPFErYnk/kT9XIGHMgYeqs6kqStQ7vCZ+NhUYHBH7IVG1+0eaFiv60xVUv7WN/oc4nvr+FrSOVhb3Y5nMqhespbMD264RK0JM1OVBemGgTAnQp+d4Tw3ihQjSCUb1GTo8mQzqTJt0ZE5Ra8vBuiDJ4JIu/6Ik5sVFhgJBa6+/STND5sndQe/qndF7zDvRc33FcXUzM7GhAwpCcuyrP/TunFvUYAkhbOteftYKzV+Ub5hMe//ijHTy0c5Ki7WFKidQFFdtrdWaECvyGcKt7Qdtz0fmkjhPQEoB+OFO4NWfkDp2VMyQIKQgbz29oUSfG/mKdtd3R2MyhImS87PDongI7xqvsGq9iapLNA1n2F2xqXoimBRiaxAtCyrZPqOD6Mwe4+brTWsJl9QI2WmGmyUdzBqwrbfKSTb30ZEwe3jWF7UeRAeMVl46kwfqeNF1pCwDbC3h2pIztBWzuz2J7Gg/vnqRQ9+hMGVywppOEoc0IwX7PS09ZdGWqXYE0n8CLZ9JODhYl2j772c/yxS9+kde97nX83//7f1u3X3TRRdx8881LtriYmKViMJdo5YyFYZQx0zzxCKJ2SS+YPTPlUA4NskwaCUbLNvftGOfZ0TLvvfoUNvfnZtznwd2Tbe9Yfu6n2/jsDRexuivFys7FOzFNL05pCCYqNsX6wg1jNSko2T5+GKKJKPfN0gR2oBpZbQLHDxgp2XjL5L6JEpi6WLQDZsyJiVIhlcdup3jv/6P/ho/PmFNLn/aiGTlsMTHPNzIJDS9QPD1cWfSGk6ULkoZGb9bitIEczw6X+eh3n2HrSIlCzUMphWYITBm1+tfcEE1E1TnHD0klDWyv/a00y9AIVFRjyydNbC+g6gat89eh/w/RcyGi+TRDl+STUftd1fHZOV5tiTY4RIQMwBWn9MwQGnU34DM/fI5nR8qU7YMbjJoUnLu6g/916ZqjEhZzzYBN1TyGiw6aFrVd9uVMQgSOF7J1uEwuYdCVNtk6XMYPFBt7M2QsnaeHpghCxZrOJFM1j10TNS5a28mmvkwrBPt3rsock8rUfAIvnkk78VmUaNu5cyfnn3/+YbdblkW1euTk+piY48GBYp3RshM5HTLTvTEERKgYKTkcKNZZ0z23mU5ziHmy6rKxN82+qToPj1ep2D5CwI6xKn9Zdfnwq86Y4VT1zFCx7bVu2X/w2KSpHeHIIzP9pKrrUQtj1V74zJ7tKapuQMbUKTuRG1gzWDsIwfMVXhCQsTQ6kgbVZchp60qb7Juqs9ig8ZgTD2foWSbv+Bzu0HMATN31Rfre8OHjvKqYmPbJJ3UqToizANF0KGEYxcBs6EmzbbTMP/xoG9vHKiQaDoqGJvFCReCGGFIiREhIw6wjgLofRCKnzQ01XUoQ0VmyM2UwXlXkNSjWgxnnlOZ4tCZgdVeqYR4CCSOy77f9gKoz//PNJjRuunYTtz0xzBP7i9Q8n5Shc86qPNefNXDUwmK2ilPCkGw5UGSs4jCQtfCVYrTkIERUcSzUXH767Bjnr8kzVLQZ7EiQSxqUbZ+pmksmYSClJJPQmay6lG2fXNKYEYJ9PNoJZxvhiGfSTmwWJdrWr1/Po48+ytq1a2fc/v3vf58zzjhjSRYWE7OUbBurMFk5eAaZbddwsuKwbaxyRNHWHGJOGpKfPTfOrokaXhidLNOmRtKUbB+t8A8/2sbvXrOxdYIZLtXbXqs9rY9l61HMtE1vX3GaOS4q5AhZpbOigJrjUQrnnm/QAFPT6EqZ7F+GnLakIRtBsUsj2lqB41IgBXEF73lEUCtS+MlXqTx+B9N/44SRQPkeQm+vhTkm5ngzUfUYyCUYLS3+e0tIQUfaZCCb4It372Si6pA0JZqQiIZlvQb4SrViWKIuC4EUConAD9uv8/mhYk1Xiqrj47bORQJDEwShQqkoH82Q4PhR/EAuoZOcZmChlKLYCJDe0LNwR/GNfVluvHr5hMWhFaepmsNo2WFVZ5KVHUmeHirjh9HmpGVoBGHIeNXhnu2TGJrk1P4cQgjcIMQPQoxGi6ahyeh9a7S5JE2NkYY5ybFmvhGOeCbtxGRRou33f//3ee9734ttRyF7Dz74IN/85jf5+Mc/zj/90z8t9RpjYo6asbJD3QvnbFEJFdS9kLHykbcGq67PeMVhvGIzXHRQKHKWTgjUvAA3CEkYkomqw+1PjbChkR2zEB+N/qzV+rPtHd0UV1OchA0r/u6MSa3gLvhx5ltGFKIaMFxanmDtB3dNHVXV8VBMTSBllNPjL1dLZ8yCUGFA5bEfUPjpPxPaB+c4jZ41dL38d0isOec4ri4mZuFU3ZDJmkd9oUGb08iaOh1Jg0f3F9g+VmFFPsl4xW21pvuBQpcCQSTWNE0SqhBdQsLQ6U5H7ZGjJXfeLS9DE/RmLF60sYdC3WPbSIVivUzJ9tEE9GYtpBRMVRyqXuN7M4Bnhkqs7ErRk7Gi+bO6R6jg0g3drOqcXRyEoWLvVI2d41F31oaeNKs6UzNmsJZTWEyvOD15oMj/e2gvZwzkeHRvAaUUa7tTTFU96g1nZClEFFVgyFZV0dSizUQvUFi6aOSqSsxGvs/0EOxjyaEjHCkzSc31Z8zZxa2QJyaL+k16+9vfju/7fPCDH6RWq3HDDTewcuVK/u7v/o5f//VfX+o1xsQcNaGaW7C1jmkcdyRShsZ4xaFY8xACkrqGlAIJaIZGtREZcGhbhCXaP2lXpmXFndqf5Udbx9u+72GIplkICBSGpi2LoYcfRqLNWyZ/6bITkGgjMqFdLL3RUhRG7S8xxxdn/9NM3vF53JHtrduEmaTjRW8me8GrW06RMTEnGlNHmX9Sdnz2TNZ48kAJ2w9Y352mK2Wyd6qGFAInCPEa88VCgIFASoFCkNCjalxvNsFkzSOYp6NAoNg6Uiab0DlrVZ5TBzLsnqzh+AGdSQNNCoaKdhT2Pe1+Xgh7J2rUXZ+0ZaBJybkrstwwx/zZttEy37h/D/fvnKRQdxEK8imDyzZ0c8Ola46ZoJguDO9IjTBecZisuWQSOpaukTQ0XD+MjFwCxXmr8zw9XGHHeIVzV3WQTeh0pkzGyjZGyqBi+/TlEmQT+oIdGZeK6SMcm/oyrZm9bMIgY+mtObvmhnLMicWiz4TvfOc7eec738n4+DhhGNLXF7t3xTx/KdXba0+Y77jolCcIlSBUjQHsWY5JGBqTVbfVFvH0aK3tte6ePFit+pULV3LLT3cuynZZNf5HNNZs+yEl2yefMijVvCWfDnMDEMvo71hx/SUTnJmEThBG4eCluod/TKJnY2ZDhQHj3/0UfmGodVv6zKvpfOlvoWU6j+PKYmKOP75STFY97ts2jgLqXkB3xuSpoWJkDiUFoYq+y0IFIlB0pU0yCSPKalNQcQKShkYQ+nO6SDaDsR0/5KHdU+yZqrOyI0lnymBtd4p9kzX2F2zCaccbWvQnIcALFFUn4JxVHZy7qnNOJ+Vto2U+fedzPLa3gBSC3rSFGwRM1Txue2KYkZLD/375pmNaCWqak9y3YxwvOJjnKho5rhXHpz+foD+fYKzikm6In8F8gnU9KSarDnum6nQkDdZ1p6g4/nFzZJyeQzfd1r/5eo73nF3M0bGoreuXvexlFAoFAHp6elqCrVQq8bKXvWzJFhcTs1Toor0vzfmOq3sBPRmTTELHC0LcIOrx90NF3QswdUnKjIK6p7dFjJXbb0l0pp1Uk3rU3nI0hEQnVMdXVJyAi9Z2cOrg8pwQl1P6+IFaMkmoFNBojbSWsIIXs3CE1Oi85h0AGL3r6H/zJ+h59QdiwRYTA6gwyjuTQuD4Ic8Ol3l0zxReECIaW3KKaAPR0gS5pM6pAzlufsVmThvMctmGbs5emSefNEgaWuQsOe3xNSLTkiYZSyOfNFANk5OEKSnZHn4Y0vjabLlTho1NwaylkzQ0QuDV5w7ynpeeMqvoCkPFbU8M8+xIGVOXZBMaI2WboaJN1fEp2i7375jgXx7YTXgMOyCa5iTdaYu6G1J1fEIV5ZxOVl2Sps4pvRlsL6QnY/G/LlnDWSvyFGoepbrH6q4Um/ujObFi3WsFfR+PNsSDOXSz12SSpobjB8dlzi7m6FlUpe3HP/4xrnv4Raht2/zsZz876kXFxCw1+wrtVbrmOy5t6vRkrNacQKHm4jf62NOWTsbSUAqmai6Xru9utUUcuuN1JKZ/KGtewBkr8mw5UGSi6h1V0Gn0/4pswuQTr9vEaz93b1si6NA8nrlonveXq9Z2lON9LQRQrHsYmsTQBZK4ReRYYu99Ei3didG1snVbauOl9L7+T0iecvGMPLaYmBc6UsD6njQrO5M8PVRi72SN8YpLwpDopsD1FE4Q5ZldsKaT/pyFHyh60hZdKYuUGbX5NU1LkmbU8tdqZW+4QEKzS0RnIJeg7gXUPZ+9k3WSusTUo8+lBo32y0iEBSg0KUhbGqW6T6nuz1lZ2l+o88T+YqPLQbFzvIYbhEgRzRcLoOp63LFllGtO6+dFm3qX++1tsbEvy3uv3shffncL28cquH6Irkn6cglO6c3QmTJ4brTC2SvzXHlKD1ceElUwmEsw1DAdOZ6OjLPl0E3neM3ZxSwNC/pXe/zxx1t/3rJlC8PDw62/B0HAbbfdxsqVK2e7a0zMcUWp9uTOfMdNz3h5yaYefr57ipobkLV0UpbGWNnB0jVWdaRmtEWcNZDinl3tOUFu7DZbf26KxJds7mX/ZI0Hdhfaegw4XGxpItolfXzvFPlrN3HR6jQP7p0/okMT0K654onQZHj2YJrJerSDGrtGHjv88gRTP/4ytS0/IbHufPre9BczNjNSmy47jquLiZmbdjeuloOOlMmp/VkCpZisumQTBiXbx/FDaq5CERmSaEJQsj3OWplj90SNjKW3zlUbe9N0pkzGKw6WJvEDhWq8ouljyEEYmZEYuqTq+uQSBrYXuSMbjb2U1uGHnCuDUCEEJPS5N12qrk/Vi1wpJyoOXqAw9Sj7M+pYCQlDRcX2uOvpUa44pWfJhM9s9veHPvbmgSwf/uXT+YcfbWei4jCYT9CbtbC9kOdGK4e1Ox7aXvh8aDecK4cOOG5zdjFLx4JE23nnndfYrRGztkEmk0k++9nPLtniYmKWikqb2WHzHTc942Wy6nLmihz7C3XGKy6TUy5JQ+NFm3oOG6Z+xbmruGfX022t4ZpzVrT+PP0L+JIN3Tw7Wmaq3t5rOfQiI1RRi+FQ0WbbWIWa397JsNkCc6SLFkMKhFAIIXCe50Iok9CoeoqEoaFrAj8Icfy4VWS5UIFP6effpnjvN1FuFH1h7/oF9s5HSG648DivLiamfZrfmM1vOFOLZnmXC0MKzl2dR0rJcKFGzQ1Y35PmQLGOLgUpU0NrXJPZfsCu8Rr9WYu0ZZBNGK1z1baxKuu6k+wv1CnbPuERIgDGKg5mo7JmGRqmJkmYGp4fIhtxAkKpRos5CAReEI0HZBM6F62du605beqkdI2S7eEGIZautebChYgy4pwwyoPbP1Vbsrmr+ezvp7O5P8fvvmxj6/jdE7UTKoB6thy6pKlRd4PjNmcXs3QsSLTt3LkTpRQbNmzgwQcfpLf3YOnaNE36+vrQtLi1Jeb5R1fanP+gNo87NOOlO23SkTRZ0ZHkmtP7Zt0d3NiXa3u39opTDpr6TP8C3jZWxVjg+JXgoOBSRC6PoYqiDcptCtkQOH0gw3MjlTkrbkKApeuYmsDxj84tbbm5d2eJhC7pSOr0ZBMUay6TtVi0LQf1XY8ydecteBN7W7fJRJaOq95KYt15x29hMSc0R1P5srTIREqh5jTlOJRDcz1btytI6jCfz1Xze7jdDu+mE+TKziRnrsi3KiRJQ+J4AVrD4t/SNZqFlJTQKNk+zwyXedNFq1uVpOnnqjVdSbaNVij5hz+fJiMLezcIGSranLe6g6QhSZoaG3vTFOs+hZpH2YnMTAQgFPgoCjUPTROcs6rjiDmnKzuSrO1Ocff2iWnv6MG5vGjUQKDLKANtKeauFmN/f6IHUB96jTJSsk8o4RkzNwsSbc0w7SPt0sTEPB+Rbc6UtXvcQr/U8ymD3qzJ6DyGJLqEwWzisOdqfgE/tLN9+//pgm36DnHkMqbY1Jdm92R7od8b+7Kcv7qDB3dNcaBgU/ei3VAJSAkZS0eXUS7RiUDG0nECxWjZIb1QJRwzL35pjKkffona1run3SrInPcKOl7yFrRk7ritLeb4cGiVarHoYmZL30JI6IKNfRn8AEp1lwOlI+dywkHDjUNpui0qJZBEIdOziUDZMO4wdYnrq2iea5bHSjS+h4IgbDkQn7Mq33Ii7M5YKAXDJZu+rMVk1W2ZX2lC4IVRy2Og4NzVHa1z0aHnqp8+O8pn7tpGECq8IGx1UkTdEiLKrgwUGUunbAes604jhODidZ0M5hPcvW2ciarbEL7RfU1dkEkYJAyNHeOVOUWBlIKLN3TzX48eaM3V6RqgDkavpEwdS5fRnNxRzl0djf39cufELTcnuvCMmZ1FfSI+/vGP09/fz2/91m/NuP3LX/4yY2Nj/MEf/MGSLC4mZqnIJdurALd7HCzsSz1rGXSl5xdtaVNnT6HOhv7Zd/52jxb410dH2nrOZnUNDr9QKtU9fvfqjdz5zPwiUBDZQG/ozfDKsxPsnazz8J5JxioOvh9dYHhBiONHsxU5S1Jynr/iTSO6yABJ3QsoBsvY3/QCpPL4HUze+XmUd/CC2Bw8la7r3oM1sPE4rizmeKKJaIPnaNsJj6b72tAkSUOjHPgEChK6xD5CuU0AmhAopVrfoc0qmCajHLRAKRJS0JU2KdQ9bDdoibyDG1uCNV1p/tclq9k9UeW+HZPsGq82WgQlSUMnVJGg8xAEStGRNPGDsOVEeO0ZfXzj/r1sG6uwujOJqUkmG+HProoyMrvTJut70vRkrRmvY/q5aud4lbSp0ZM1qTohhapLzQvwQoVGiKFFrrrjFZczVuR440Wr+OEzo2wbqzKQsxjMJ3C8aKYOIcgmDFZ1JFjZmaJse/zgyRE2vHTuDLDTB3KcuyrP4/sKFOt+yxBFl4Jc0qAjGYnFU/oyRz139UK3vz/RhWfM4SxKtN1yyy184xvfOOz2M888k1//9V+PRVvM846U0Z5tfrvHLZTBXAJNyCO2yVi6IGXOXfWRUhAsLqVj5uMQOYjtnGzPUTNtCBw/IAxDKk5AytK4cE0nO8ar7BirEKpoV7gjZfDijb1sHS5wz47CUa9zuTBktHOuyWj3u2rHrZFLiZbrbQk2mcrTedXbSJ99DULEFc0XMorFV8iOFgEkDUnK1HnyQBk/CFCNnE0hDvPUAKLvB4kgCCPB1igIoUQk5FKmRtaK8h79EAbyCVZ1JtlXqFOu+wRhiJQCTUo29qX5y9eezWmDOe7YMsxje4ut96Puhgh8erIWlq5Rd32UEly2sZu3X7mOrGW0KiTXntHHT54dZbzs0JE2GcgnqLk+ZdsnZWqcMZhDiCNXqLrTJkIIRktRtUw0xSegIVAoNAGnDWZbrYNru1P84MkRHt9XYLhko2kaKU1Dk9H7s2/KZrIWOfKOlQ9w7ur8nM6PKzuSXLCmC8cLGSnZVByfhKmRsTQEgpGyw2Auwa9esPqoq0IH7e9nF39JU2Ok4fh4KO0Yl8TEHGsWJdqGh4cZHBw87Pbe3l6GhoZmuUdMzPFFiTbdI9s8bqEMlWzyKR1DlwRBiCkhDKOLBSFA1yRCQCZhsL5n7pmAsWr7eW9zEQIb+zL8zxPtfVZ7sgkyls4PnhohUM36nUACF63r5LozBhjsSLK+J83qzhTv+9bDba/F1MH3ly8mYDZ0Lco7ShqysYv+/K0KnggopWbsYifXnUfqtBejpTvIv+jNaInMcVxdzPHG1KLZKy8I0aXA8UK8o/ia1UVUJdE1gaVLqo5/xDgQCRh6VAnry1qUhsuRWBGghMBoBEPLaeItYUiEEHjBwQcWjWwyKQQD+SQpS8P1AhKmTtKIrOHDULG6K4UUgrLtU6y79GQTvPelG9k8kOWup0f4xG1bKdTcKAPN0HC8gLoXsn/Kpj9nsaY7zUDOIggUWcuYUSm54pQerj6tj7ufG6fuBoTKR5OS1V0pNvSkmKh68zoD5iwDEJRsl46kgSYloS5x/BBBJCRPH8zx568+E9OMOk+anR7femgPj+0vkDU0UqbGRMUhDBWhUNRdSKQlk1WXbzy4h4F8YtY2yelz2kKISHQ6PmU7wPVDBnIJfveaTWweOPq5q8Xa3y/EuCQm5liyKNG2evVq7rnnHtavXz/j9nvuuYcVK1bMca+YmONHV8aad3hdNI5bDqquTz5pMpi32DNRZ0ZHngIRRllvZ63Is7pz9naGMFRMVI5etAHkTB23zSn8VV2p6KK89QZGF+hCCtKWwcXru2acyOoL6X8Kj72Vtu0rTANqboCuSYLjtf1/gqN8l+ID/4Gz/2n63vjnM4Rbz2t+P66sxWBpglecNUCg4Il9BcYr7qzzYQshYWhkEjq2FxCEqlXtmevbLCQSZV4QYuiS1Z1JwhCEjNwKXc9n+0QdpSK7e68x5CVFZMwRhlG7Yz6po2mRSAyJ3BP780kGchYg+JULVvL43iLbxyrUfJ+EoXHWyt6W8YPvh9x6zy7Ktkd/1uJAw1gkaWj4YUjJ9gkVXLC6AyVg13j1sAqQlIIbLl2D7YXsL9ToTJnkEgaahKGig2VINvZHc0yzVYbCUHHXM6Os7Exgez4VJyBpahiaQAqoOD4Zy+CdL9nQEmzT2TVeRSLoTBpMVD38ENKWDijqXvQa8gmdquPPOSsGM+e0t42WKdRdpJBs7MvwhgtXsrl/aWZeF2N/vxjjkpiYY8WiRNs73vEObrrpJjzPa1n/33XXXXzwgx/kAx/4wJIuMCZmKdCEiE7IgZpVJAiiE7a2gBDshZA2dbwgpFz3Z31+LwRNg8tO6T5iMOn0nd+j4fM/286VG3v415/vn/fYSt2J7KPP6KfiBLhBiKlJMpbGtrHqYSdnz29ftFm6hgoC/KDNAO85TAEWgq/A9qJ2Tz88uhmZFyq1bQ8yddcX8AtRVmft6Z+QPuOlrZ/Hgu3kRzJzbvZQErpkIJ+gK23hh2HD5AIsQ1I7UmlsHmwvoCdr4gUhVTdAlwJTU9hzfO1ojSG0iuPTn0kwUXFJWVo0i+srCo326BBwG+eHIIx6Jz0/aLV0VlyfjpRFV9rigjWddKXM1nfgXIHL04XTI3un2DVRpTttYmgSKUSrTdvQJBlLp+L4DJdtcgljzgDkjX1ZfutFB50BJ6oOjh/ieCF+KPnvX+znNn141spQc8br3FUdrOxI8uieAoW6R92NxG932mRtd5rTBg4XTfsLdcbKUXbZeMWh7vmYumy4VwpMTVKxfVbkk2zoSc87K3YsjDIWan9/NMYlMTHHgkWJtg9+8INMTk5y44034rrRzn8ikeAP/uAP+NCHPrSkC4yJWQrWd2XIJgzKttsI8Tz4M11GrS+5hMH6ruVp5RrMJdg/VWOqNrcdvgRGS1G7yWwnhKrrU3WWZv7qqf0l3n/tqehtBGfvnrQ5b00XUkpyyZkX47MNctsLuCBTgFpAtS1hSGpL4FBpe+Exbck8WfCmhpi66wvUtz908EYh8Yujx29RMccMQ0QVdj9ULdfB2dAl9OciF9yRss1QIx+sI2ngBiE17yg6BgRMVj36shbVRmzJoU0DsnEcRN8ZUkQW8hM1l0Lda1T8FI4fRu29zPwOcnyFJGjkkEUtmbqUTFUdspZB0ojEyrax6ryBy00mqi5eEJJsZKslDUnVDRqPFW0q1l1FzfGpOsER2xynC56nh0p874khdBmwoiNJytTnrAxNn/Fa32OwtivNUKlO3Y0qbn2ZBLsnD6/wNe/rBCGnDmQp7vKwKyFpKVEKAqVw/AApRLQGS2e07Mxr2X8sjDIWYn//QjcuiXn+syjRJoTgE5/4BB/+8Id5+umnSSaTbNq0CctantaymJijJZcy2NyfYcuBEl4QkjJlawDdC0IMTbKpP0MutTxGJHsLNfZO1o8oTvxA8fi+wpwnhLSpU14i0ZbQJUIKdF3gzzNgUnF8SvWA/CznqNkGuYMFRIIEYbCgSpd7FDv004kF28IIPZvS/f9O8YH/gODgxoO15my6rv0dzN61x3F1JxZLUS0+XvgKDNQMd8QmkdNi43YFw8U6mhTUvYBCzUUgMHSjZW2/GJr2+XU3wAtC0pYGSlEKFCiFLqLPtlJRhpgUjSpJQmfPRC0yTmpY44fNoWJm5r41/31CQDZfp4iqb0JI6n7A/TsmOX91x5y5V7OZWDQrbHU3IJsw6EpbuIFN3QsxdYkfhIiGID2lLzNvALKUgpUdSb7dsM/f3J+dtzJ06IxX9BgHv9jLtjdnha9534QRCZ5CzcMLQrwgmvNLmBpJQ6M3Y805K3a8aLeqdzTGJTExx4Kj+kRlMhkuvvjipVpLTMyysbIjyYs29uIGIaNFm6Lt4weNlpCMSV8uwYs39R61xfBcPLRzkto8s15uqBg+wglhZUeStKlRmqsPaAEM5HR2TVTx2nAE8EOYqjms7j5ctc12cs4l2xe+2gI7TOJWxmOLUor6c/cxedc/EZQOVtO0TBedV/82qdNfctiOdMyRaeaMnYhBE4rIsl9riKdDi94hUSu6QOEGClNEc200XAlLNY9gEcY/poR0IrKCj1oYFeNlByWiFkc4mBkpVPT+hjSz1CKBJhDYfsjKjgRDRSeaaZUCoRQeUbeFpYEmtWherplDJiI7+u60STZpULEjwfjizb287ryVh134z2Vicc1pfazrTvPsaJm0qZE0NQZyCSarDnU3oOL65BIGZ6/McfGGbixdm7ProslCK0OLmfFqMv2+G3vTbOrLcKBQJ5sw0ARU3ID+XGJGy+hynU8XQztVvcUal8TEHCva/s17/etfz6233koul+P1r3/9EY/9z//8z6NeWEzMUjK9t703bSG1yL1RSggD6M5a8+5sHg1DxXpb1R3PD+c8IUgpOHNFlqHSxFGvZ6IaMFSst3XhqIDJqotq7EqXbR83CDGkYLhkc05jPqLJaSvy/OjZybbWUZm7WzTmeYA3toux//rYwRukTu7i15K/4teRc+xGxxwZIQXqOJbaJFE16Wg2QHQJh47XKqLCVdj4ntAb1vgdSYOxskOowGmEOc+GaKzLalSdOtMmpqFhSknSlIyWHSxdtQSV33gghYoEjlLYXtjKUdMbTo+Fmkeh5pEwNHozJrYXkk3oVF2fUCnCsNEiLyVdKZOEKRkt2bhBNIeXMjT6cwlySQMhBBkrZN9Uncf3FXjdeStnvIb5TCyuO7OfoZLNnqk63WmTpKmRTejYfkhXyuLsVTnGK+4R59Kms9DK0EJnvKYz/b7bxqoM5hOUbI+y7QGCTEJnIGfN2jJ6onA0ojYm5ljQtmjL5/OtX+B8Pr9sC4qJWS4O7W13/GjXbOOKzKwtLktJu0kC3WnjiCeEl2zu485njl60lWyPPWPt5bRB5Jz2iz2Flj2z64e4fkhv1uKNF2VnnJxXz9ZHGXNCYvatJ33m1VSf+hGJdefTde27MLpXH+9lndAodewdU6ejyUgY1f3wMOHVLs48uz2CaEPM8UO2jVWj6lijXXGu1y5FJDJMCcl0Aj9QDGQthBAcKNh4gSKX0FBKkUnoXLimE6XgoV0TWIZOxfawaQRaCzCkICRqOzc0SdrSuXBtF7snaoyU7EjUaVHFK5/QqXsBXWmLih0FbwcKupIGg/kkyWlOin6oSFs6Q0V7Riv7dBOLjb1pKk7AVM3F1CQbe9NsG6tStn3+4BWn8s/37mbXRJXJamT9v647RdqK7Pc70+YR59Kms5jK0EJmvA7l0Pt2p61Gh2lUiQTR1uM8XzkaURsTcyxoW7R95StfmfXPMTEnEsfCsWo2to+V2zrO1OUR1yIaAd1He9EnlKLstl/mWt+T4tF9ZcbKDqYusHSN7oxJ0tD49mMHCELF6YM5VnYkCePz2QmJUgp7x8MkNlwww/2x46VvJ7npMlKbr4hbIZcALzjc+OJYIoWgJ2MyUnaohwdnuliCNU1PBZFCILWoEtasrjWdGLXG3Jiadr+UGQmyhGnwK+ev5LanRtgzVSeX0Km6UTWnZEe5aJdt6GF9T5rxikM2aSJQ6CmTbEJRtD1cP3KGFSL6Tj21P8tE1SUIFRet66Rke/xiT4FCzaU/l8ANQqSUnLcqT6WRr6YcxerOBIZ+ULAppajYPr1ZC02IGa3szVbFpCH5+e4CUzUXPwjRNUlnKop72TZa4ZfPXcFX3nYxj+ydYqLq0pkyeGjnFFuGSgt2LFxsZehozoOH3jdlRE6cdS84KUKoj0bUxsQsN3FjbswLjmPhWHUoTpu9SJZ+eDbOdDb3Z0ibGpWFZKHNgtQkqQX05T89VGYwn+T81R14ocLUJF4Qsn2swkM7J3lmqMQZgzk29mXpyS6PmUvM8uGO72Hqzs9j736c7l96H5lzrmv9TM90oZ965XFc3cnFkWzyjwVeoBgtu0z3C1qq9TQfRzUqVQldYmgC2/MRHDQAalbDmlVH0fhP0yRrutL82sVrOH9NJ7fes4vnRsvU3ABTk3RnTM5b3cn6njQQ5aiZuqTi+GgCujMWHSkjapNsKEhNwlkrczy0a4oDxToD+QT5pMk5q/I8urfARMXBDxUpU+OBXZNMVl2EEAgh2DFWY6AjQTZh4AUhFdsnaWqsyCcAMaOCVXV9xisOE1UXxwvIJAyMhI4XKMbKNiXbozttUnV9dF1yyfpuAPZO1vjX8X2Lciw82nbHxZ4Hj8c59FhyvDZ3Y2Lmo+2rtvPPP7/tXdZHHnlk0QuKiTkZOXUww21b5rdFP3XwyJED56/qJJfUqXkBzVqIUtD8aLY7p+IHIenEkQXidEZKDmet6my14ExWXR7bV6Tu+nSkDIIwakF68kCRYj0eVDtRCJ0ahXu+Qfnh70TDncDUj28ldeqLkNbJe1H2QqYjpRMqliw+ZC78QBFqAAKtEerWjAnQhUDTRNO8EUMT9OUsam7IuaujGdnVXSmu2tTLbVuG+Nq9e+jOGJzSm0HKg1XgbEIna+mMV6KolEqjb1MKQUKXaJpgVT6FoUlWd6VIm3pL3OSSBpv6Mjy8u8BUzWOk7ACQNDRWdyapuj4jJYehot2wxNfpyyXY0JNiouodVsFKGhrjFZeq49Ofs1rXS5YuMNMmIyUHpaLjpnO0joVxZWh5ONmFacyJSdui7XWve13rz7Zt84//+I+cccYZXH755QDcf//9PPXUU9x4441LvsiYmBOd3758A3931462jjsSIxWHtd1pSnaA4wWA4uBeimhZWM+H5wc8ta/Y1rHN45uVOaUU20Yr1F2frrSJAgo1F0OXbMpn+MGW4bYf93i2ib2QUUpR3fJjCj/6MkF1qnW7lu+n65p3IWKTkZMSCaQtnYyls2uihh+Gy/r5c7wAzw8Iw2kxGyKaCwsbBiKagJSlUbYDBvIJ3nDhQUdGXZe88qwV7B6v8+SB4uwbxwIEAi8IEYQkTA0/CJms+SQMje60yXDJ4YI1nVx7ej93bDkobhw/JJ/U8YIA0OlOGwQhTNU8NCnoz1kU6z4pU+eitZ3ommC45MxawYr+pBBzvqPRzw59BUvhWBhXhmJiXhi0Ldr+7M/+rPXnd7zjHbzvfe/jL//yLw87Zu/evUu3upiYk4Qnh0ptHfeDp4d548VzZ15VXZ/OtMkFazr4xe5Jqq6K8oSAjCnw3PYuwUbLAXJ/+6LN8cPWRUXZ9pmquWQSkZua6wdoUmJqUUjsoTvJR8LQBG4Qy7ZjiTu6k8k7Po+z76nWbUI3yV36q+QufQPSiPM2T1YUkX19qGBtV5L9RQfH8znKbus5n8uf1gsqadjq65KgMeQWhCFCk4RKsCKf4Hev2cTm/tyMxzlSC+CBgo0fKNZ1p6g4PrsmqtSrHlIIdE3gByGP7y9y5SndrarTxr5I3JRtj//+xYGWqRICpmo+dS8gVCFeoMhaOn0Zi7Ljs69QozNlzVnBqnkBPRmLCRF1ImQSOkajjbxi+2QSOt1pi5o3880+dC4NDnXodThn1fyOhXFlKCbm5GdRM23/9m//xs9//vPDbv+N3/gNLrroIr785S8f9cJiYk4mvv/UUFvH/csDe3nDhWvm3CFNmzquH7JttILb6DUSjaEQZwE24j4wXm2/jVGKaKg9Y+m4QYgfhBgJvTWY35dLkE1EXycZq33R5seC7ZihlGLqri9SfuS7MC0rK7nxUjqveSdGx8BxXF3MsUCKaE7KD0I60iZdXogb6IyWbJbzo6gJsAwZOUhKiaFFG0FJU2Nzf4YNvRmuOrWXzf1ZfD9kqNEO2KwYzdUCuKY7iR+G5BI6z45U6E6Z1L0wqrqJyAClVPc4d3VHS2Q1xc3eyRrjlahqtmuiSt318cPIuEQTOpoMKds+li7JJw1edlo/V23uZVVnatbv57Sp05Ox6MmYDBcdJmtRq6QmJX25BAM5i0Pn4JrraYrSX+wtUHMih17HD/B81XDoXRVXzWJiYhYn2pLJJHfffTebNm2acfvdd99NIpFYkoXFxJxMPLhrav6DgO1jsw+cNxnMJThQqDNcsmfkHSnVvtnJwTu1f2jNDulKmzw3WiFjaUgpqDas/5Omxim96VbrkjisAWhuFuk4HrMIhBAo32kJNr1zkK5r3kXylIuP88pijgWagM6UAQqUEK05rc2dCX5Wcwm85fk0NlugLV1jZUeCsh3QkTJYkU8wWXXZ0JPGdgO+/egB/v3n+3C8EMuIDEaawdTNrLJ1L0m3XBe70yYpU+MffrSN/YU6k1UXP1QEzRZxIUkbklDB00Olw4Kqm7Nk3SmTmhsJpLSlt9rNBVEb53DJxqi6/OzZMUp1f0ZuWhiqGS6KG3rSPDVU4sK1HVScADcIMTU5b+D0xr4sLzutj8/c9VzDoTd67T0ZnZSh88NnRlnbnTrifNr0tcTtkTExJyeLEm033XQT73nPe3j44Ye57LLLgGim7ctf/jJ/+qd/uqQLjIk5GfD99ob+gzCcc+AcYG+hxp7J2pwBtQta0wKu0aohrZ3ubaNlBFCoeY0LiQxd6ailTimFFAJLFwsXkTHLTsdLfpP6jofJnv9Kchf/CkKPnT5fKGQTOgP5JLYXkLI0RkoOG3rSrMinsLQpPC9ESlhq7dZ0huxMGaQtA12T2F6IrkuGSjaGLtncn8X2Qh7ePUmh7tGZMrhgTScJQ2tllb3stD6eGSqzfayC7QcNUWMxXLTZPhZVyoJGO6YQoEmB64foEp6bxX2xOUtmN9sVBTS9LL1AUXF8gjDENDQsXSOfNGbkpgGtyl9zPR0pA02KVvh0R8qg7gbzBk6HoeKZoTKD+cQMh95so5vh8f1F/uX+Pbz9ynWzVvq2jZYPW8t8wdwxMTEnHosSbX/4h3/Ihg0b+Lu/+zu+8Y1vAHD66adz66238qY3vWlJFxgTczKwtjvN9nF73uOyCf2IA+cP7ZikOl+ybZss1Dtu+rD708MlvvfYEI4fYmgSPwxbNtMrO5L0ZSz2FuZ/vTHLQ1AvU/jZ1zB715E9/5Wt27VUnpXv+mIs1k4SptvmHwkBZBI6UkY2GZamkU1EAqpoe6SsyAhjsWHb861R10TLyMjQJBXbZ/tIBT9QbOzNkLF0nh6aIggVazqTTNU8dk3UuGhtJ5v6Mvxib4HP3PUcg/kEKzqSpMwkNddny1CR7Y3Q6ubrFI0A72huLmqR3D8VzbBNpzlLdt+OcZJGlH9Z96LKWM3x8PxIWKYMjZSpYRoamzqSPDda4ZsP7KHuhUzVXAbzidZ6hoo2mhQM5hIUal7bTo7NjLcVHckZZiSTVZdtoxVGyzbbRiocKNY5Z2XHDDG2bbTMV+7ZxWR15lrmC+aOiYk58Vh0Ttub3vSmWKDFxLTJr160ih9unZj3uMs2dB9x4HzraPm4ui0250FWd6XY0JOe1Wb6zJU5Htg1iaUJnHhm7ZiiVEjlsdsp/PSfCeslpJUmdeqVaKl865hYsJ08NFsPZ3Nh1SUkDA1DCiqOT8X28fyQ7kyCl57ay2mDOZ4ZKvP4vkIj3Fqn7gVLbgwUApahoTeqQ14QEirFSNmmPxeNU5TqXsvcSEpJJqEzWXUp2z7ZhE7N8RkrO5y/uqMlajKWThAqlFIzQrqnh3ZLQBOCqap7mGhrzpI9O1Jmx1iVXELH9qM5troXoklBPmlELaWIltHSQM7ivh2T9GZNzl3VMWsYdnfG4q1Xrms7cHo22//JqsujewvUXT8KzkaRmlZ5fPuV69jQk+EHT44wWXUXHMwdExNz4rFo0VYoFPj3f/93duzYwc0330xXVxePPPII/f39rFy5cinXGBNzwnPWik6ylkb5CFUyQwrecOHqI55cU6ac82fHmrlspn/63Bhl2yNhaAgR4DeuouJuyeXFObCVyTs/jzv0XOs2FQa4w9tIbrjwOK4sZjnQBK3p0emiRZMgEQRK4QUhmtBImjqaFKzvzfCac1fwoo09rOpMcfWpfeydqvGVe3by1IESeyaqjJTdJV6nQGuIiSAMGS05VF0f1wso2z7375zE0iU1x2+ZGRmajGZmg0hElR0fU5d40/rCIxdbj46U0fpeDTnYjtn8ux8qtDCkOotF5sa+LO+9eiN/+d0tbB+rkDQkJHQQMJBNkE/qTNU8+nJWa21+qCjWXU7tz8wZhr19rIIUgtMGcoc952wcavt/aKyKG4TomkZHyiSbOCjGXn2OZPtYZVHB3DExMSceixJtjz/+ONdeey35fJ5du3bxjne8g66uLv7rv/6L3bt388///M9Lvc6YmBOaVZ0p3njRar7x4B7sWYZGNAm/fO4gL9rYe8THmTsD6Pgwm820Uoq6GyCArrQV7YajKNa9eM5tGQhqRQo/+SqVx+9ger0ldfpVdF79dvRsz/FbXMyyIIms8x1/Zs6aoUVGQEIIgkDh+ArX9zE1gUCCgru3jfPzXVMzZp5+47K1fPrO59g+Vlny7MRsQmdVV5Ky41OseTh+SC5pIBM6nWkDKSRTVZeS7ZOyfPJJIxKbUmJIwWQtqpIlG1XDJk0XW1OTrfeEWdpFw7AR6j3HXtjmgSwf/uXT+YcfbWei4pBL6Gwbq6JLwVTNO8xoqWz7oJg1Uw3mD8OejUNt/6fHqgAzHHqni7Ed49WjCuaOiYk5sViUaHv/+9/P2972Nj75yU+SzR7slf6lX/olbrjhhiVbXEzMyYKUghsuXcNo2eGpfZOMVbzWhUlXSufcNV3cePXGeVtYUtbStbYlBNjLoKGSphY5FTZc3HQt2vtO6BLHX9pAKA1YhoipEwIVBlQevY3Cz75GaFdatxs9a+h6+e+QWHPOcVxdzHJgyqhiLUS0OZIytUZ7oIgcEAMAhS4Vpi7xQ9UQMQo3UOSTOht6MofNPG3oydCXtehOW5Tr3hHNSKZ/Q8339SEFrO9J059L4IeK8YqNFILL1nfzyJ4Co2WbrrRGX9ak7HiMlmwypmzlmm0dKTNSspmqejhmyNaRMhv7snSlTUxNomuSuuO1ZtmarZGHCk8/UExW5q4gbu7P8bsv29iW0dJUzW0ZjsxGO2HYh71Ph2TRWXqU72bqgslqcJhwbIox4KiDuWNiYk4cFvVJfuihh7jlllsOu33lypUMDw8f9aJiYk5GNvZluenaTdz25DBP7C9ScwNSpnbYYPmRWEhw9XxIHWgzqi23AK2YSxp0pU0mqi4118cyNDQhMDTJUkusF6pgAyg9+J8UfvLV1t+FmaLjRW8me8GrENrxuUhLm5KqGwc5LDW6gExCo+6GoBQS6EqbpCyD8YpD0tBQKqTmRVJFNi7uE41qnCYkSUOjZPtIcfjM06vPkRRqHldu6Ga87DBVP/jFcKgA0hpGHwlD4vrhnAJPl4JzVmb5mzeeix2ElOoe33xgD51pE02TnNKXpux4rSDqnozFUKHOrsk6GUunYvtMVT1AkUvo6JpktOxQcQLOW91BZyqaNxst2xgaLRMVrbHgZqukrgl0KXhiX5FfOX/uvLOFGC2d0pthqGi3Kl9NlIryLOey9j8S07PoHt9XaLla9ucSnNKbbglHOCjG1vekZ1TolmotMTExz08WdWZPJBKUSqXDbt+6dSu9vUdu74qJeSGzsS/LjbPMgbU7JH7GYHszEvORTwikoHWRNx8vPa39FrusZbCxL4MYrVC0PRwvBBRhGF/MLyXZ836J0kP/TVgrkj7rZXRe9Xa0TOdxXVMImALcuAt2yZBAJmGQTeis7TaxPR8vUAghMDSBEFGroJTRpogkqsSYusT1ItOPpBHZ0Q8VbQ4U6gzmE1ScAEuXPLa3wGmDWWw/AKKcs1xDIHqhOkywBY1Kn6EJdE2nXPdbAgkOCrzutMl7X7aZdb0ZAJ4ZLuEEYctFsittcd7qDraPVpmsuQRhlPm4siNJyfapOFGrZHcjsHrneJWa41Oqezw7UuaMwSy6lOQSBmEIFdubITCFiOaEE6ZOLqEzVLTnne1qx2jpujP7AfjKPbt4bjSaJ0uaWkvUHcnafz6awrE5Z7hzvMo5K/ONf9vG+ztNjK3uTM2o0C3lWmJiYp5/LEq0vfa1r+Uv/uIv+Nd//VcgGnjds2cPf/iHf8gb3vCGJV1gTMzJxmxzYO1yz/bxJVlDd1JnQ1+GO7e2F/p96ca+th97ZUeS81d34ngh/UHAWNnFC0N8P6TmOQvKhzsS01uiTnZUGOCO7sQa2Ni6TSYydP/S+5CJLIlVZxzH1UVYmsDzw2h26Hnyb6LLRqVIRb8nIZHwOHUgwzPDlWP+u2NqUQZYO0+bMTXOWZXnxZt7WdeTboVJ/+OPt9ORNNg1XmOy6gBgN1wKlVIEYfT2u36IGyg0KbB0SbHuYXsh9+2YQAqBrgmkENheQOZxHdcPsb2AIFTkkjoZS1BzfWw/JAhCEIKEJrH9qMpT90IyZjSXZnsBrq8IVWSxn0vq/OWvnMk1p/e3Xs+hZhsQCbfOdWZrhqvuBbzt8nXcet8uUsZB4w0hIifH7aNVRso2+6ZqdCQNLj+lm7f2r+UffryNp/aX0BoW/0ITjVgDDV2TDOaTaJIFzXbNZbTUFEDNqthsou5oLPalFKztTvMbl63lK/fsamW+zSXGplfolnotMTExzy8WJdr++q//mle+8pX09fVRr9e56qqrGB4e5vLLL+ejH/3oUq8xJiamQcVemobAmq+4cENP26JtQ3f7J/7p8xkTFYfVXSk0Kdg1XmO4HF1kymktTEfF80QcLCf23ieZvOPz+MURVrzj8+jZ7tbPUhsvPY4rO4gmYGNfikI9IGNpbB2pHu8lkbUkUkgShiRt6ZQdH9sNyCYNNvZleW6kSqiO3S+QIWFlZ4IwhOGSTRgqckmDjKUhACklK/IJJqoum3qzvPnyNVy4pgtdP1hl2TtZI6FrJAyNi9Z1UrZ9xioOz42UqXsBticxNOhJWzhBiFJQqHvYQdhwcFSUbY8gjOIA8kkdCeybrGH7IQqFFOAFCksXpC2dpKGoeQEJQyNjRmHUv3zuSr735BB1N6A3Y5IwNKZqLlM1j4yl82e/fCbXnTEw4/UfarbRbOUTQpBN6AyXbM5d1UG+MS+2sjM1Y26sKfAKNY+dE1X+16VreMmmXqQUGLrkj//zCYJQkTZ1TEOAEq3K3sqOBCAWPNt1pA22+UTd0bIQMbbca4mJiXl+sCjRlsvluPvuu/nhD3/II488QhiGXHDBBVx77bVLvb6YmJhprO5KIom0ytFcbnq+Iqm1N6iWT2jk0wszQDn0gqPm+tFuvYou8JOmhlLRbMZihdvRvgfPd/zyBFM//jK1LT9p3Tb14y/T+8u/fxxXdThSQEfKQNc0spYgZWl0JA3qnn/c3EJ7syaWplF1fWpuQCZhsLE3Q7HuUah5aETmHPOxVEVDQ0LS1HE8xfreND0Zi+GiTaAUuqbRm7VYkU9Q90LW9mTmDESeLnw29WXIJQ1yjSyx50bKTFVdlIrcaFflktTcgLLjYbtBVAWjYcEvoWKHlG2PjKVRqLnYvsIyJKYe2e3rQscPo9ZLQ5P0pA3Gqx6n9me5+bpTuXh9F7fes4tdE1Wmah6GJjl3VQdvvWLdjApbk0PNNuaqHlm6Nqe5hmhUCHszFqf0Hswee/HGXq47Y4C7t48jATdQ6FLQn0uwoSfNRNVdltmuuURdGKolEVALEWNH08ERExNzYrBg0eb7PolEgkcffZSXvexlvOxlL1uOdcXExMzCr12whr/+wbNHzHtrB0ujbSfH3qxFdhGulYdecPxizxSP7S9GDm9KRUG4C37Ukx8V+JR+/m2K934T5dZbt5sDG8ld+Jplec5mq2mrlXAB902bGgP5BIWaj2VIVnWmsHSN4aIdteT5AWGoGrlhy7L8GWgCTE0ymLdwfINC3eOslXnWdCZ5dG8RQ5M8N15luUYsBZH1fhBEJhiWIdGlJGlqrOhI8M4Xb+BFp/Rw384J7np6hKGi3aiCiXlb2uYSPoYm6UhZXLy+Gz+IWlR7MxY/3z0VtUw2KoqaiGbgHD9qIzQk9GQSJC0N23ep2j6nDeT4xd4Co2UXIUBK8ALJzgmf3kyCt16xDl2XXHN6P1dt6uWRvVNMVF260yYXrO6cURk8lHaqR2GoFmyuIaXghsvWYPsB+wt1OhttlboUDJecYzrbtW203Hp9th+Q0LUZ8Qrtcqjw29yXjStnMTEvcBYs2nRdZ+3atQTBC9m3LSbm+GCaGt1pk7JTn//gIyCFoKPN6tkpfdlF71BP3/0dLtpkLJ2qG+AGCrXIgSLJzMyl4CQqt9V3PcrUnbfgText3SYTWTqu+k0y51yHkHO7h5pSICXYC6hu6RJ6MhaWLjE0iUJRsf22A5b7swamrjNRcUkaOi/e2MOvXbKaO54a5f4dE/TnDs40KqU4ULCX5d9LAwxdoAvQdI2koTFV8zB1ScLQMDXJtrEqa7pTvOy0Pr714B627C8hObJAXehSBdF7amoSpQlCpUjoGm6oqDoBWcvglN4Mui558aZerjylZ8EVmbmEzzmrDppk/ODJER7ePcl4xUEpRXfaxA8VJdsnCCJffCmiz6epSyw9qvbtm6rTkzE5pSfNs6Nl/EARBBCqEEuT9GYt1nYfrObouuSS9d1zLXXO9R+petRuRe7Q92ljX5bfetH61vsyWXWP+WzXttEyX7lnF5NVl8F8gpSZPCxeoZ11LJXwi4mJOblYVHvkn/zJn/ChD32Ir3/963R1dS31mubk4x//OH/0R3/E7/3e7/HpT38aiHbe/vzP/5wvfOELTE1Ncemll/IP//APnHnmma37OY7DzTffzDe/+U3q9TrXXHMN//iP/8iqVatax0xNTfG+972Pb3/72wC85jWv4bOf/SwdHR2tY/bs2cN73/tefvjDH5JMJrnhhhv467/+a0zTPCavPyZm50SF0SPkDbVLxfHpzSZIGpL6EUKZNAkv3tSzJDu8G3rSDOQTDBVtao6Ps8iL9xBOur7IoFZk8vbPUdt697RbBZnzrqfjJb+Jljyya6gAzliRY3+hjldzW/bn83Faf4bNAzmGig5TNRc/DLF0reUSeCR0CeeuzCM0jcF8gmtO7+fKU6LfFSnEYTONfhByz/YJhksOSzlK1mFJAgSajP7LJQ3OXplnuGSze6JGNqHjB+GMi/ekKbln+ziOF5LQQCmBM8cLnk/YzUWoFH6gcBv/GHU3IJPQGcwlDj72Ilva5hM+G16a4X+eTLJlqEQ2odOZMnH8kJ3jVWwvaM2KBaEiaGye+KEibWr8Yk8BL1Ss6kghJFHpVQhUCCMlm28+sIc/ftUZs34ntNsWON/rXqy5xmJmu5aqlTEMFT94coTJqsumvkyrQnhovMKGnswRH3+phF9MTMzJx6JE22c+8xm2bdvGihUrWLt2Lel0esbPH3nkkSVZ3HQeeughvvCFL3DOOTMDYz/5yU/yqU99iltvvZXNmzfzkY98hJe//OVs3bq1Ffx900038Z3vfIdvfetbdHd384EPfIBXv/rVPPzww2hatHN9ww03sG/fPm677TYA3vWud/GWt7yF73znOwAEQcCrXvUqent7ufvuu5mYmOCtb30rSik++9nPLvnrjYmZjTu3jGJ7AQldoAmBF0aObVIIDCmoHikVdxoVFzb2ZliRT7K/UMMN1GFOepqAlfkkL9m0NDEeqzpTnDqQZfdkDYHC1MBdYMH+UFvxhdCOEFlqBNFF/3wvU+gmzv4trb+bg6fSdd17ZrhFTkcTrWvphu27YLhsY2mClC6pueG8z6lLuGR9N0Mlh4vWdlBxAtwgRBfw/z12gEL9yE57hiZ4+VmDXLah57AL3dlmGi1d45VnDXLn06PsnqzNs7pp7w1H/vc2DA2CqN3W0jX6sgk6UgZ1L+Di9V286uxBTh/MzVjjJWu7WduVZutIGYVA0wRiFlfHhcy0icZ/oYLKtKy65vsoBYyWbG756Y4lqZgcSfhIKdjQG828BY1fekuPstrqXhQLEKjoOE1Gm58V2yeb0Nk+ViWbMOjOmIe1Jo6UHO7bMcneqRpru2ee95e6OrRYc42FCOGlXPP+Qp3tY1FlcPr7BtEs3mA+wbbRyhFjB5ZK+MXExJycLNry/9AvpeWkUqnw5je/mS9+8Yt85CMfad2ulOLTn/40f/zHf8zrX/96AL761a/S39/PN77xDd797ndTLBb50pe+xNe+9rWWUcrXv/51Vq9ezZ133sn111/P008/zW233cb999/PpZdGbmxf/OIXufzyy9m6dSunnnoqt99+O1u2bGHv3r2sWLECgL/5m7/hbW97Gx/96EfJ5ZYmPysm5kiUbA9UQwxIgXUUJ+5VnSmuOrWX/3liqJX9FLnpCXQJKVPn2jP6WdW5dMPtnUmTbMLA9SSO5+MuQkVpDZv/aKXtV0GWPtp7fjQRCav5Kl/STNJ59W8zedcX6LzqbaTPvgYh5p4N6k6bIEAQtUTWXR/bDbF0iZACc54KKsC67jSXndLDT54da9mKd6QMao4/b+uqIaPqlO2FC3bX60yb/O0dz847O9cU9aYucP3DBZUmQJOCzf1ZMgmDHWNV/EA17O19zlnVMWdVRtclb7tyHX/+7adwGy6LumRGULQuDgq2dn5NE7rAD9WcYdNR66RcsorJfBWirGWwpivF3slaK8A6n9SZqrk4DaMOS5OEIUxWXZKmTsrU8BuulrMJj3zKYKLisHO8OkO0LVd1aDnNNZZ6zVXXx/YDUubsreRJU2OkZB8xdmAphF9MTMzJy6JE2//5P/9niZdxZN773vfyqle9imuvvXaGaNu5cyfDw8Ncd911rdssy+Kqq67i3nvv5d3vfjcPP/wwnufNOGbFihWcddZZ3HvvvVx//fXcd9995PP5lmADuOyyy8jn89x7772ceuqp3HfffZx11lktwQZw/fXX4zgODz/8MFdfffWsa3ccB8dxWn+fLZQ8JqZdThvIImXUyqRpBytPsLDqUzYho+H9S9cwWnbYOlzG9QJCFBKBZWhsHshyw6VrlmxHd3+hTqHuccWGLoaKNiNFmz0TNdpPTopeYzPct+mi2e4LH8ib7C0cfWtpu+gNUXGorbxfHGHqx7fS+dK3oecPuuylTn8JyVMuRlpHvhizJBjTzB78UCGEJGlI3CAKUk4a4Pkuc4235ZM663rSnD6YY0PvzBBhP1CkLY1Sw+xm+kM0TTaatyeMuWfsYPaL7ledM8it9+yiUHdbZiBNIxQ1TYxbuohmH5XC1CJB1KwuapGjO1IIAhXZvL/uvJWcszpPb9ZqqyrzxgtXc/+OCX6ydQzHDwhDgZSN52h4S5qaRm/GYPekPe/mgKlL3FkMgiTR74FCsXuiymvPW8n28epRVUzaqRBNz0v0w5Cpmkeoory0uh9V2/TG3F1fw2Xx6eESupSY2lxrOvwX6kSsDi3HmmfLoZtO3Y3y7Y4UO7AUwi8mJubkZUGirVar8fu///v893//N57nce211/KZz3yGnp6e5Vof3/rWt3jkkUd46KGHDvvZ8PAwAP39M+2F+/v72b17d+sY0zTp7Ow87Jjm/YeHh+nrOzw8uK+vb8Yxhz5PZ2cnpmm2jpmNj3/84/z5n//5fC8zJqYtrj99gL6sxXDJwfUCDF1rXex6bbpBAlx9WtTyuLEvy03XbuK2J4d5Yn+RmhuQMjXOWdmx5EPvzQuSDT0ZVnWmKNs+d28b47nR9jK9TF3gNSoui5mJuv6sfv7p7r3zH7hEBCoyyDB1jdALCHyX4v3/QfH+f0P5LoQBvb/yR63jhRCIeQQbRIYbTZQC1wsQIhJHoyWHiuMzmEtQdQPqboAuo8pkoCIhmbY0NE3i+iGDuQS6LmdUxIaLNjXXo1Av4PhhFFAtohbMZr6e7Yfkk1FW2EJZ25XmJZt6+N6Tw/jTLBybgg0gYciGo2LQcJycVmlrBGVrAnryJn/0ytPpTFkLnkWSUvDeqzeS0DV2jldJmRr5lEHWNHh2tIyhS37l/JXoUnDzvz02b1VYCNGqyE1vq4w2GhSagNGyw7OjFVZ1JhddMWm3QnRoXuKqziSaFExVXZ5suLiesSLHio5ky2VxVUeKQtWjVPdIGNph7ZHFmkdH0mBDz8Eq24lYHVqONc+VQwdzu14eylIIv5iYmJOXBX3y/+zP/oxbb72VN7/5zSQSCb75zW/ynve8h3/7t39blsXt3buX3/u93+P2228nkUjMedyhX7pKqXnbNw89ZrbjF3PMoXzoQx/i/e9/f+vvpVKJ1atXH3FtMTFzYZoa73npRj5x21bqrg9+0LpCDBoW3u2MtV26/uCc2sa+LDceg2DWQy9IckmDVXmzLdGmAYaUeItscLQ0GC55C7rPYg0omgiiStT6nhSP3/cjhr7/edypodbPnf1b0Jwi2Y5uFFCp+229OtdXeEGUUud4IQroz0aiJZvQ2T9lc6BkN6piAtVwCtS1yKhDSElX2sTUJUMlm9VdqRkVsbSp05NJMJhPsGeqTgjoDcEWqih4WQjBxes7WduVPsJKZ0dKwY0v28hYxeHubRMz8vaaa06bGiXbRxfMWi1URLfrmqQzZS1aDGzsy/LbLz7oOOj4ARV8XrK5t9Va+cTeAvN9FDQBK/IJivVK5MooZn4OBaBp0abDM8MlejImjh8suGKy0ArRbLOFacvg+rMGoRG8Pd1l8doz+vjWg3u5Y8sIExWHbNLA0CReEFKuR5W6Szd0z2iZPhGrQ8ux5sW6Xk5nKYRfTEzMycuCRNt//ud/8qUvfYlf//VfB+A3fuM3uPLKKwmCoGXosZQ8/PDDjI6OcuGFF7ZuC4KAn/70p/z93/89W7duBaIq2ODgYOuY0dHRVlVsYGAA13WZmpqaUW0bHR3liiuuaB0zMjJy2POPjY3NeJwHHnhgxs+npqbwPO+wCtx0LMvCsqyFvvSYmDl5y+XrAPinn+1gpOwQhgqpCQazCU7pSfHDZ8fnfYzhsjPj78cimHW2C5Kq217JTBDtMjct1YPmlb4AoeafVXMD2HJgYa3JVqOyt5hLTUNCX9bCKwzz8y9+nv2P33Pwh0LSfelrWXX1W0hmMti+ImNqeH5AzWvj/RCCmuMhhCBhaKzsTHLWihwTVY8L1nTxaxdn+KsfbGXPRK3RnnmwMqlLydquFKcP5ijWvVkvSld2JNnYl2W84uIFitGKgx8eLIMJAas6knzg5actWthv7MvyZ685k4997yl+8uxEqypp6WBokrLjRzNmjflN1OFtmjSMPabqDqtZ/O/ufIYXVc9HimhnRDaeV6nDGwVHqy5SQNqUeKHCDxVSHKy6+UH09yBUbB0ps6YzteCKyWIqRHO9vubjHfqamy3Tzw6XKds+zQ+aJiXnrji8ZfpErA4t15oX63rZZCmEX0xMzMnLgr6R9u7dy4tf/OLW3y+55BJ0XefAgQPLUj265ppreOKJJ2bc9va3v53TTjuNP/iDP2DDhg0MDAxwxx13cP755wPgui4/+clP+MQnPgHAhRdeiGEY3HHHHbzpTW8CYGhoiCeffJJPfvKTAFx++eUUi0UefPBBLrnkEgAeeOABisViS9hdfvnlfPSjH2VoaKglEG+//XYsy5ohKmNijgVvuXwdv3bham5/ZpjhosNA3uK60wb4x58815ZoU+rYx1rPdkFStNurfgkJYQi6FAShalVnxCwXz7OhgAOFhWXb+WH7xiWGjOaWvMaFuR667LnzW+z/6f9D+QdfY2rN2fRc926MnnXUhcCu+yR0iRSClKlR8+aXiOu60+SSOl1pi/6cdViA8Ma+LJam8ZfffQrbC5BSoklBNqGzoTfN6s4UFcfH9sJZL0qn/zsBdKcNxqoujhcSKsWKfIKbXn4qmweOrnV2Y1+Wf3rrpfz9j57jmw/uYarqRSHQoWIwHwnR7z85jCkFhha1HjY7GzQRVfwcP+QXu6c4Z+XC2zQPfc1zbVrU3MgiP2VoeEFwmClJ8/o5oclGhqIfGZs05sWal9dBGAWRd6dNhgo2F67tXHDFZLEVorle32y3LbRl+kSsDi3nmhfrejn9/kcj/GJiYk5eFiTagiA4LJNM13V8f3naHrLZLGedddaM29LpNN3d3a3bb7rpJj72sY+xadMmNm3axMc+9jFSqRQ33HADAPl8nt/+7d/mAx/4AN3d3XR1dXHzzTdz9tlnt9wkTz/9dF7xilfwzne+k1tuuQWILP9f/epXc+qppwJw3XXXccYZZ/CWt7yFv/qrv2JycpKbb76Zd77znbFzZMxxwTQ1Xn3Oyhm3ZZPtBWa3e9xS07wgue2JYR7fV2Ck5Mx/JyCha3huQDhNsEF7gq2Ju4DQ6bQhyCZNvCBkojq/sBSNOAFDlwzkEjx2y59Q2P5o6+f9A4Oc9tobGe+7EISIQovDSKAEIXRlTNKezni1PO9zXXFKN73ZxBEDhF+0qYfXnr+Sh3ZNsrIjiaVrZBPRxWk7F6XTLxy3jZbpSLtIIdnYl+ENF65kc//SfOdJKXjfNZv5nRefctgGxK337+L7Tw6jlAIh0ZvlNWjMNUYbD84C/l0XtUYhSBoavlKYoUSFihDVqvaJxlDpQD7BQC7BT58bp+r4rQgrOwAAefpJREFU6I3W1KAxgyeAfMqg6gTomuCidV0Lrpgcq6rWQlqmT8Tq0HKv+Wg7F45W+MXExJycLOibXSnF2972thntfrZt8zu/8zszstr+8z//c+lWOA8f/OAHqdfr3Hjjja1w7dtvv72V0Qbwt3/7t+i6zpve9KZWuPatt946o6XzX/7lX3jf+97Xcpl8zWtew9///d+3fq5pGt/73ve48cYbufLKK2eEa8fEPF/ozyVas0dzIUV03PFEEc3TtIvtzXQynG5u125qgFhA6NaFaztZ0ZlmvGxz5zNj8x6vVFTl6M9aKOCs636duz/3KFLTef///t8MvvTNPDvpU6g6DJVsMpaB7QegQmxfkdC1qFo3Lc7gsPUDpia47qx+Llvfc8QLOikFrzhrgKGi3TCs0AiUou74bV+UHssLx9k2IFZ0JDA0SahC/EBF83iN1sSgoYIMKVnRsby/yxt60vRkLcbKDn4YYPthy8UyoUtMXdCRtOhOW/TlEly8rot7t43jhY3jiP5dDV1i6RodaYPOlMnpAwsXvseyqrUQ4XEiVoee72s+Fi3rMTExJxZCqfZ92N7+9re3ddxXvvKVRS/oZKdUKpHP5ykWi3GFLmbJuX/HODd84YEjGmhI4BvvupTLNiyf6+tcbBst8+k7n+PZ4TJ112ei6hKECqdN5dWcaWs6SAoRtU220+yZ0AV2G1WZhA6vOHMQL4zc8u7dPnHExw/dOinlsG71SrwwygDrTZvsuuNWPvx77+SM00/nb+94lo6UgeMF/PjZMQo1l0BFM1JNZ8aL13aybbTCvoLdeuym/X2TU3pT3PZ7V6Hrc2e4TWfbaPmonEHnywJbTlw34OWf/ikHinWsVnvkQct/J1Cs7Ehy+++9BNNc+pnqJmGo+MC/PcrtW0YIg5CEqaPJqN3Rdn2kJrnu9H5O6cvwwM5JPD9g22iFihugC0HCkJi6/P+3d99xctXl4sc/p02fne272fQGCYSWhBKKgFRplosFEEG9KirNhnr1J8rlivfqVSxgB/VasICKYCEUQSC0QID0hPRkS7bNTp9Tvr8/zu5kN9lkN2Wz7Xm/XnnpnvnOzHfn7C7nOc/3+zzUxEMcPylBc6rAsZPKue7MmQdc7r939cjdM0QH2//tYAznz8uBGo1zFkKMLYONDfYr0ybBmBAjW9wyBgxgvO5xh5vnKX79/BZe3dpJwNCIhy2ytounFIXs4JZY+7PWMHtlXWzlDTKDNrjA8MRpVXzi/CPJ2S5PrG5hyca2fqNCpRTZ1U/T8cRPCdRMxX33V6iNB5lbk2D+lAq+/NavM6s2zuqmLvKOS3OXy9ItHbQkC7u9nL8PrjlV4Mj6MppShe7qkH1nHTA0jp1Usf8XlN3rSVV3NY/B3qcbTC+woRQIGPz7GdP5+j/WULBdQpaBafhLS/O2S8Qy+ODp04c0YOuxqym867dPcBUKjXDQJGAaVEYDzKmP86dlO0jlbRIRf+liwfHIFP19cDXxAC3pIlWx4EEtvRvJGaLRmB0ajXMWQoxPI6eckxDioN39z7WDHnfX1ScPPPAQ2taR5bkNbRgaVEaDpLsLNqTzg98Tm4iY2J6/XFJ5ftYlbOnkbG+fyyR78lLB7ibNexsbC/qFInRNY059GS9ubMftJ2Artm6h49EfkN/8GgC5VCu5N57HPe4MzjuqjncumFy6KI8GTDoyRVY2dpHOO/0G1UrBhu49ajXxIK1deZxeA00damIBuvL2oHtH9c7ITKwIEwmYZIsOKxq7aOzK7zMjM9heYENtV6XUjexM5ck7CkPTmFAe5oOnTy89PpR2bwrf0lXA9jwsXae2LMiERIj2TJEXNnYwoSxETSxAR9YmElSguQS7O8A3dua56JiGQxL0yp4nIYQYfyRoE2IMeWFTxyEddyhtaM2QzNoETI01TV1+oOWp/eqFVnQVc+rLSBcdHNfDNHR0DdY1p/Fctc9cWiwYYFZdlGVbkniOt8dYDT8buK1zV/W9ieV923V4hSydz/ya1NK/gLertmR81kLiddNJ5hx+/9JW/u2ESaUL6LpYkB2deXLFXZUHe0rH9+w91PD3abWkCtTELGriQVIFF9fz93LFgwa6prG1PUtqEBU397ef16F67lDYW6XUw5Fhg75N4SeWh2lM5sl2Z/omJEJ4+O0kuvIOs+tixIImqbxD0fWwuj+fzpxNruhyyXETmFq1/73t+iMZIiGEGF8kaBNiDMkUBhcCDXbcoZazXVpStp+9OqDrfY3WdB5D11GA7XjkbQcFBC0dXSlyTt/gTcMvv37MpATXLprKDfcto+B4fd7eMjSiQYO87bGlPUPI8HNzT631i5Aopcis/Ced/7wXN91eep6ZqKPi3A9TNfcUKiIBUnmHdc1pXtrSXtozuGx7JwXHLxvfJ8WndvXwArBMDbuoSOVdghZEAkapqEy2u1Oz7SnShYEzkwfSz6u/5wJ05WyKrkfA0ImHzH0+d6j0V6jkcOmp2LijM0tTskB7tojjeZi6zo7OPPWJoN9/TXlEAn5xkLLdqrNGQyabWjPk7ANrDi+EEEJI0CbEGBK0dLLOwBeGQWtwhSwOpSkVYbK2i+35mSZD694qNshSSIYGDYkgWzpyFN1dFfxM3c+26UDAMggENIq2g+35WSOAWMDg/adNI2DqOO6eWTa3O5gydY2C7dGUyjOtJsb2zgLFnZtof+T7FLatKI3XzABlp7yTspPegW4FcV2F4ypMQyNbcFnbnCoFbW2ZIgCJsEnOLvYJ1LTueSsFqnuutqdImH5TbEcpNDRCpkZX3sXQNCLBgTNMB9rPq/dz87bO6sZUnyClMhJgWnWEguP2+9yhMpzFIiaWhymPWCxe2Vzai2kZJrbr0dyVY2tHllNmVuE43qhqMC2EEGJ0kf+CCDGGREwYzMLHyDD85jel8riun+HSDuB6OxY0yRZddF0jrBul4Mf1lN/U2vB7kFmGjhkwcRXYjovC70tXHQ/yl2WNpaxVby7QkXUoC5kYmuLFje10ZG0MzcNNtfUJ2MKzT6Hizf+OVV5fOlb0/OBMww9El6xv49SZ1cyqjVMVDWAZOoa2a2+dru9KNCoFqlcSztT9uezOMrRSUDiQg+nnFQ2YFB2Pl7d04LiKWMgsBSktqTxtmQKTKyOHLQAZ7oIoQN8ou7fuPhLxgEllRYAVjV1EAwbpglvKTsaCxohsMC2EEGJ0kaBNiDHEMnX8EGQw4w6vDTszaJqGZfgNpb3uEu6DETT96+ac43FUfRzbVbjKL0qRKzqs25nB8xSe5i/nK/XRsgwSYRNPQTJb5P6lW/f5Pqm8g6XD/z23GV3TKBSKhGcsIDz7FOzWzVSe8xHCMxf2+9ye/WkBUyNTcLn3mU28/7RpzJ9cwbSqKGuaU4S6i6b48/ODTJddwVzA0NDQUFrPZ+MX/dc0PzgNWQax4MB/tieUhaiOBVnZmGRWTYyysFVaJjlQP68JZSEKtkdH1mZKRRhd17vPgYEV0djSkaPO8ZhwGHr9jYSCKD2FSE6cVkFjskBHtki64GDqOnVlIerLgnTmbN48t5bVzSn+sbLZ7yPXzdA1jqiLj7gG00IIIUYXCdqEGENClgUMXKjCH3d4hUwDQ9cIGjqOp7A9hTOIvmkAUyujbO3IUR0LoOs6wV4xp+OpUt8uU9e6M0B+sKNQJHMOldEAb+xM05Iu7vN98k3raV/xBDOv/ASRkMnmVg8KNlUX3oAeiKCZe//cer6TcMDk2EllvNGa5ZEVzVx35kyuPW0ad/xtNUXHo+h63UGr/wwNv7dbVcTCA9IFh4CuYRp6KZvouJ7/feragEFbT2ZqQ2uaLW1ZNuzMMCER4oj6OGHLGLC5dmNXnqClUx626Mja3Zk2Hdv1SOcdyiMBAqZOY1d+SPe0jZSCKL0LkUyqiJSKjPTs8XOVYlNrhmzPfrVScRm/LcBgl/8KIYQQ+yJBmxBjSEU0AGQHOe7wWji1gljQJF1wKA9beArSBZtMceCiKI6nUIp+93MZutZ9Qa8oOB52ryyH1v24oWs8s651r6/v5lJ0PvUL0sv+DigajzqemuPOKu11MyKJAeeoAbrm/2+64PYp2HHO3DoAfvbMJlY1dZHM2biuQtf9IGReQxkXHTuB/1uyBV3T0IC84+EphaZpRIMmSvnZrn3FAL0zU1MqI9TGg6xpStGYzLMzXeCIujjzp1Tss59XpugQMHUWTK1kY2umT2aptizE1KoIXTl7yPe0HUwxlUNp96WmuxcZyRUcAobOSxvbcT3FBUfX7bE8cv3OzGGtuCmEEGLskaBNiDGkoSIMGzsHN+4wm1IV5fTZ1TyysplkziYSNBnsIk3XUwRN3W9qrBRFxystj0SpUsNoBdjdpf81/OIlmq6hKUVHbs8MpPJc0q8tpvOpX+DlukrH1z71Z9ITT+y3R1t/dCAaNLAMnaLrLy2cVBnuU+zjnLl1nDm7hpe3dtDS5e8Nq4wFqYuHmD+5gvWtaf72ehOa5vehS4QtNB2UBwXXI2T5PeT2VoGwv8xUPGRRHQvSlbNZvzPNjJooHz5jBuY+lsf2BCkhS+fEaRV7ZJbSBYeC7Q35nraDKaZyKE0sDzOzJsbyHUliQbNPANmz1HRKZYSWrjwTEiF0Xacs3PfzHY6Km0IIIcYWCdqEGEPK+ik6cTDjDiVd1/j42bNoz9gs354kb7vkB5FlA6iMBaiOBdnUlqUrZ5N3FJ5S3Vkpr9SI2lW7sl09XyvHI2d7TEqE6V2mpbBjDe2Lf0CxaV3pmBYIkzj1CsoXXornDX5lWzRoEA9ZuJ6i6Hqg9V/swzR1Tppe1f9rBEyqY0GqY4HS3inH8frsnQJtr8HS3jJTmqaRiAQ4oi5Oa6o44LLG3kHK7NpYn8zSQPvhDqWDKaZyKOm6xgXz6tiRzLGuxf98wwGDXNEtLTVdMLWCPy3bTmQvczlcAaYQQoixS4I2IcaQYyeVA1sGOe7wm1Ub5/9dMpe/vd7Ei5va2dKWYVN7bsDnnTStkkkVEb7+jzWkCy6RgEnQ1Cg4inTeKWXWdl951hO7JPM2i2ZVcf8rO3CySTqf/Dnp1xbTOyyLzD2TirPfjxmvxtD9YEfzVJ/WansTMHVA+dUNLYPykLnfwU3vYGnh1PJ+l9jt6/UOVWZqMEHK4SiqMZgM1+GqyDirNs77T5tWqmLZ3JUnaBocMzHB+UfXETQN/r68adgDTCGEEGOX/BdEiDHEMvU+fcD6ozE81SN7zKqN8/GzY2zvzLHkjVa++KfXKQ5Q8PLVbZ3YjmJ2XYyWZJ5k3iGV9zB0v5FxW8Zf+hi2dFSpBIS/NyxnuxQdj3jQolLPsuzHH8HLp0uvbVVPpfK86whNOabPe+5PSJIrOtieAQpqy4I0pwpUxYL7Fdz0DpbWdxcPKY9Y5Iou63dmBgyWDmVmaqAg5XCU2h8pwWOPWbVxpr0pystbO2jLFKmKBpg/uQLT1PE8NWICTCGEEGOTBG1CjCENFaEBl/Sp7nEjQWUkgK7tO8zUgG1tOZJZh1NmVBKbUUVjMk/WdolYBh3ZAk+saUUpvzG1qWvomoZSfgET0/AvoDe1ZZkzYzJrZywgvfJJtECE8jOuIn7CxWhG3z+FSvkz8ga5PtL1wPD8nmYNiTDHTio/oODmYIKlQ52ZmlUbZ8ZZsWFrat0zh+EOHnv01y/uxY0dpX5xPQHm2uYU8ZCJoWu4niKVd/Y7gBdCCCF2J0GbEGPIss2dgx43f3L/e6uGWu+L3y0dmT49rfqjAXnXo5gp4Hqg6zoTK3btySq6HobmN7U2NA1PKZTXvTQyl8SMlmFoOqGATlnIYtGVN/HyAxEq33QVWrQCQ9ewdI1k3k/3+Qsd/eIng93TVhMP8pZj6jlxehVz68sOKrg50GBpKDJTuq4Ne+GMkRA8DrZf3Jvn1PKzZzaxYkcXtuthGTrTqqO8c07tYQ0wxyvPU8P6cyKEEENJgjYhxpCNOzOHdNyhtvvFb9EN87qe3GdKywNsxyNo6XTl7T3aFVRGA4QDJtmii2loBAwDPIfm5//Cjsd/Tv0F1zHnjEs5oi7Osi1J5s2aRuCaz5PK24Qsg6BpUHQcUvkMHpAImxi6jqsUtuOR7rV2s3dZf0/5c9OA958+nfefOv2QXSAeaLA0kjJTh9JwBo+D7RfnefD46haiQZNFM6rQdQ3PU3TlHR5f3cLUqsio/fxHg/4yoTNrYqVMqBBCjHYStAkxhuQG2hy2n+MOpf4ufl3XQxtEnJMuOkQCQTqyfv+x3kv/4kGTikgAzytg6DrJja+x7eHvkW/ZBEDLY/dwzXsuZ+GUSpZu6mT5jiTHT06wYWeW9myRnO2gA5GgSd52KbqKsAEhQ0fX6BO0GRr0bBrsCTNrYhZXnzR1xNzRHwmZqbFkMP3i1jWn6MwWac8UOaIu1mdcvVKHrRH4eDXYTKgQQoxmErQJMZbog1zQN9hxh1B/F7+aphE0DAq2s8+liMoDDcWEslC/S/+OmZSguXEHT//qTppeeazPc2efeCbvmN+Aaeql5YNtmSJH1sdwPejK23Rki8yqj9OczLOxNUvedskpf4llNKCTLXr+kklFn+13EcvghnOOIBDYs+n3cBoJyxrHisFU5dzYWqQrbzO1KjqsjcDHo8FmQiVgFkKMdhK0CTGGJLOD6wM12HGHUn8Xv7anSEQsbNcla++jGIkGRQ9OmlFFY2e+z9K/o+oibH/mAX72ja+RyeyqClk9bS7Xfvo2PvLOC0p32XdfPlhw/IqKJ0+v4vyj6wD422uNvLipg3TRJhawOGl6BQVX8eeXt9GUKpT6w9WXBfnQm2Zy9aJpQ/OBiRFhMFU5dc1fTit92g6/wWRCJWAWQowFErQJMYZEgoP7lR7suEOpv4vfgKETCZiURwJkk4V+n2doEDJ18rZL0NL50OnTeWR1E03JAs2rX+LuL3+Z1atXlcaXV1Tyic9/ifdd+wGmVO15d32g5YMff3P/j91w1qzS+9Yngpw/p37EZdjEoTeYqpyzamO0dOWlT9swOFT9CYUQYqST/4IIMYYcM7GMPy9rHNS4w62/i994yN+Ptr1j74VRDF3D0DUcT/Ha1iT3Pb+VTW0ZbNdj0x/vpbk7YNM0jY985CPcfvvtVFXtuzLmvpYP7u2xQMDgkmMn7sd3LMaCwVTl/LcFE1m8okX6tA2DQ9mfUAghRjL5KybEGFIdCww8aD/GHUp7u/jNFm1SBW+vz7Ndheu5hCydh1/bge0pqqIBwgGD6Fuvo3X500RrJ/O1/72Tj15+/mH8jsR4MZiqnLqmjZhG4OPJoe5PKIQQI5WmlDr8FQnGsa6uLhKJBMlkkrKyw5/tEGPblT94mmc3JQccd+q0BL++7vTDMKM99S7NnS3YPLW+lWxx70Eb+EskC5uWEvCKLDjrLei6Xnqsc8dGOqxq5kxIcM81J2Ka+j5eSYgDN1AfsN4/2z37JWfVxkZ1u4XRYPfqkbsHzFI9Uggxkg02NpBMmxBjyBtt2UM6bij03lP219cbeWLNToIGFPbShcBJNtP62I/JrHsOM1LGsSedTjCWKD1e3jAdI2+zsTXDy1s7OGn68DQNF2PfQFU5pd3C8Bir/QmFEKI3CdqEGEMcd98Zq/0dN1R6Ln4NXUOhAA2tu5Z+T+rfswt0vfAAXc/9HuUUAXCyXWx85i/MueC9fV4vHDBozxRpyxQP43chxJ6k3cLwkIBZCDHWSdAmxBgyozpK25auQY0bCeoTQXTNLzKia35pf09BZt3ztD/6I5xkc2msEa1gzls/ypFnXLzH6+SKLpahUxU9/Hv1hBAjgwTMQoixTII2IcaQk2dW8eIggraTZ46MJYTnz6mnKrqaxmQeXYNi+w7aHv0x2Tde3DVI06k/9e1MOfd9YEVQSvUpNuB5nt8suy7O/MkVw/BdCCGEEEIMLdmxL8QYct7cCQy0GEjrHjcSBAIGHz5zBpahkVr3Alt/8rE+AVtoyrHMuu5uTnrPzXzs/GOIhy22dORI5W0czyOVt9nSkaMsZHHNqdOkCIkQQgghxiTJtAkxhlTGghxRF2NNc3qvY46oi1EZCx7GWe3bNadOpzVd5Md2ltZABC/XhRGrouqcD1J7/NnMrI5xwzmzOWduHZMqIvzsmU1sasvQniliGTpH1sW55tRpnDO3bri/FSGEEEKIISFBmxBjyMTyMJcdN5EHXtnKlrYsdq96IwEdJldFeOvxE0dEz6J0Ok0sFgPgU+cfyVuOrufGrk+waf06Zp5/NQ01Fcyui3P5/MkcUe9Xfztnbh1nzq7h5a0dtGWKVEUDzJ9cIRk2IYQQQoxpErQJMYb0bmA9sypHsuhQKLoEAwaJgElNIjzsTX7T6TS33347P/3pT3n99depr68H4KiJCR65+9YBq7+Zpi5l/YUQQggxrkjQJsQYs3vPopHS5Fcpxe9+9zs+9alPsX37dgA++9nP8vOf/7w0Rqq/CSGEEELsSYI2IcagkdazaMWKFdxwww088cQTpWOBQICpU6fuUQ1SCCGEEEL0JUGbEGPUSMhadXV18ZWvfIXvfOc7OI5TOn7RRRfx7W9/m1mzZg3j7IQQQgghRgcJ2oQQh5xSil/96ld85jOfoampqXR8+vTpfPvb3+aSSy6R7JoQQgghxCBJ0CaEOOQymQy33HJLKWALhUJ8/vOf5zOf+Qzh8PBXrhRCCCGEGE2kTrYQ4pCLxWJ8/etfB+Btb3sbK1eu5Etf+pIEbEIIIYQQB0AybUKIg+J5Hr/4xS9485vfzJQpU0rHr7zySqZNm8Zpp502jLMTQgghhBj9JNMmhDhgL7/8Mqeffjrvf//7+fSnP93nMU3TJGATQgghhDgEJGgTQuy39vZ2PvrRj7Jw4UKWLFkCwO9//3teffXVYZ6ZEEIIIcTYI0GbEGLQXNflxz/+MUcccQQ/+MEPUEoBMGfOHB555BGOO+64YZ6hEEIIIcTYI3vahBCD8sILL/Dxj3+cl156qXQsGo1y6623ctNNNxEIBIZxdkIIIYQQY5cEbUKIAX3pS1/i9ttvL2XWAK644gq+/vWvM3HixGGcmRBCCCHE2CdBmxBiQMcff3wpYDv66KP53ve+x1lnnTW8kxJCCCGEGCckaBNC7MFxHExz15+Ht7/97Vx++eWcdtppfPzjH8eyrGGcnRBCCCHE+CJB2zjneYrtnTkyRYdowGRieRhd10bt+4iD09zczC233EJnZyd//vOfS8c1TeP3v//9MM5MCCGEEGL8kqBtHFvfkuIfy5t5Y2eavOMSMg1m1sS4YF4ds2rjo+59xIFzHIe77rqLL33pS3R1dQHw8MMPc/HFFw/zzIQQQgghhARt49T6lhT3PrOJ9kyRCYkQkUCYbNFh+Y4kO5I53n/atEMSUB2u9xEH7sknn+T6669n+fLlpWPl5eWl4E0IIYQQQgwv6dM2Dnme4h/Lm2nPFJldGyMesjB0jXjIYnZtjPZMkUdWNON5auAXG+T7zKqJohR0ZIsoBbNqoofsfcSB2bFjB1deeSVnnXVWKWDTNI1///d/Z+3atVxxxRV9xnueYmt7ltVNXWxtz8p5E0IIIYQ4TCTTNg5t78zxxs40ExIhNK3vvjJN05iQCLG+Jc32zhyTKyMH/T5hS2fp5k7as0Ucz8PUdSojAeoTwUPyPmL/FItFvv3tb3PbbbeRTqdLxxcuXMhdd93FSSedtMdzZImrEEIIIcTwkaBtHMoUHfKOSyQQRilFKu9QdD0Chk48ZBIOGDR35ckUnYN+n9Z0gbZMgYLtEQuZWIaJ7Xq0pPIk80WqosE+7yMFS4beU089xS233FL6uqqqijvuuIMPfOADGIaxx3hZ4iqEEEIIMbwkaBuHogGTkGmwozNLY7JAR7aI43qYhk5FJMCERJCgaRANHNyPR8QyaE0XyBYcauJBbFeRt10MTaMiYtGSKoDyx4Fkcw6Xc889l0svvZSHHnqIj3zkI9x+++1UVVX1O3b3pbQ9mdl4yCIWNFnXkuaRFc3MqI5JcC2EEEIIMUQkaBuHJpaHKQuZ/HV5I7qmEQualEcsHA9aUnm2dWQ5/6g6JpaH9/oanqfY3J7hpU0d5G2XI+piLJhSiWnu2ibp73jSKLqKxmSenO3hKYWuaYQtHU+BQkMh2ZyhUigU+MMf/sCVV17ZZynsd77zHW699VYWLFiwz+cfrqW0YnyRjLoQQgixfyRoG4ceW93MIyubaEv7RUHajCItXTpV8WCpMs2+Skysb0lx9+Pr+df6NtIFG6UgYOrMro3xsbNncc7cOgBytkskoNOYdCk6HuGAQcjQsT1FR9YmYOo0BHQyRYcnVu2UbM4h9ve//50bb7yRdevWEQwGufzyy0uPTZs2jWnTpg34Gr2X0vbnUC2lFeOHZNSFEEKI/SfVI8eZx1Y1c/vDq2jL2MSCBuGAjqYU6YLLtvYspqFx4rQKOrM22ztzezx/fUuK/3xoJf9Y2Uy64N8lj4cMlFKsbOziK39ZyWOrmgEImjqdWQdT14gFDTxPkXc8lILyiEXYMsgWPbpy9qCzOWJgmzZt4u1vfztvectbWLduHQCf+cxncJz9D6x6ltJm9xKU5YruIVlKK8aHnoz68h1JyiMWM6pjlEcslu9Icu8zm1jfkhruKQohhBAjkgRt44jjePzsmU2k8jYRSydg6uiahqbrmIaGq6ApWSBgGBQcd4/siecp/vZaI8u3J3E9j5Cp4SmF1r3EMmhotGcK/OyZTaze0cWvn99CSypPpuDgeIqAqVMdCzC5IszE8jCWoQGKrW1ZWtJ5HFeh1J45vnCg//mIvvL5PLfddhtz587lT3/6U+n4GWecwZ///GdMc/8Dq4nlYWbWxGhM5vc4N0r5y15n1cb2uZRWCDh8rUaEEEKIsUhuj48jL2/tYFNbhspIgJ3pIumCiwJMHTQ0dA0yRZdnN7RyRF18j+zJ9s4c/1y7k66cjaug6Digga5B0DQIWTrKVaxqSvK/i9eQs11iIZOi7WK7CsdzcT2FoWukCw6moZMtuvxx2XY2t2Zp7MxTGw8xqzZGZTRQel/J5gzsL3/5CzfffDMbNmwoHauvr+cb3/jGHvvZ9oeua1wwr44dyRzrWvxsaDhgkCu6NCbzVEYDnH90nSxbFQOS/ZFCCCHEgZNM2zjSliliu56/nNHzcDyFoeFn2zQN09BRSpHMORQdjwlloT7PX9XUxfqdaRzP/1rX/R8gz4O87ZIpuLieS7bg0pouMqsmRlnIojoe9O+qaxpZ238sFjRwPUXR8WhIhJlcGcHtbgWwbGsn7ZkiINmcgRQKBS655BIuu+yyUsBmGAaf/OQnWbNmDVddddUBB2w9ZtXGef9p05jXkKAza7OpNUNn1uaYiQkpECMGbdf+yP5vvkhGXQghhNi7ER203XHHHZx44onE43Fqa2t529vexpo1a/qMUUrx5S9/mYaGBsLhMGeddRYrVqzoM6ZQKHDDDTdQXV1NNBrlsssuY9u2bX3GdHR0cPXVV5NIJEgkElx99dV0dnb2GbNlyxYuvfRSotEo1dXV3HjjjRSLxSH53odCVTSAZeik8i66rmPoGq5HdxVHcFyFpkEiZBAwdRq78qXnep7ixQ1tFLsjNg0/2NN1DcPQUAps16PoKFylmFAeoixsURkJ4LiKhvIQUyojTOquXAl+oZKpVREaysPMrosRD1ugFF05m7XNKbpyRda1pCWbsw/BYJBoNFr6+uyzz+bVV1/lf//3fykrKztk7zOrNs5Hz5rJJ847ghvOmc0nzjuC686cKQGbGDTZHymEEEIcuBEdtD355JN8/OMf57nnnmPx4sU4jsP5559PJpMpjfmf//kfvvnNb/K9732PF198kfr6es477zxSqV0b2m+++Wb++Mc/ct999/H000+TTqe55JJLcF23NObKK69k2bJl/P3vf+fvf/87y5Yt4+qrry497rouF198MZlMhqeffpr77ruP+++/n0996lOH58M4BOZPrmBaVZT2bBENRTxoYhn+vjTH9bBdj2jQ5NSZNQRNvc8d7+2dOTa3ZQmZOprmB3k9e5w08ANABY4HYctkWmUUTdOYWRslHDD8zJmGv1zS8djemac8EmBWbRxN06iMBjl+cjl1ZWFMQ2NbR5YdnXnJ5uxGqT33/X3jG9/giCOO4L777uOxxx7j6KOPHpL31nWNyZUR5tSXMbkyIkG02C+yP1IIIYQ4cJrqr/LDCLVz505qa2t58sknedOb3oRSioaGBm6++WY++9nPAn5Wra6ujv/+7//mIx/5CMlkkpqaGv7v//6Pd7/73QDs2LGDyZMn89e//pULLriAVatWcdRRR/Hcc89x8sknA/Dcc8+xaNEiVq9ezZFHHsnf/vY3LrnkErZu3UpDQwMA9913H9deey0tLS2Dzmp0dXWRSCRIJpOHNBMyWI+taua2h1bSlMwRMg0sQ8N2FQXHJWgZvGl2DTXxIJ1Zm0+cd0Rpb8nqpi5uf3glm1uzJLNF0kUXpfz9bABKgQcEDI05E+IsnFpJLGiSyjvsTBfY0ZkjW/CXR+Vtj0jA4JQZ1dTEg33mp5SiM2uzsS3DB0+fzptm10hw0G3NmjXccMMNXH311X1uKAB4noeuj+h7MELs0Y9x9/2RcoNGCCHEeDPY2GBUXeUlk0kAKisrAdi4cSNNTU2cf/75pTHBYJAzzzyTZ599FoClS5di23afMQ0NDcybN680ZsmSJSQSiVLABnDKKaeQSCT6jJk3b14pYAO44IILKBQKLF26dK9zLhQKdHV19fk3nM6ZW8cHTptGyDRJFxzaMzaZokPQMpg/pYLp1dF+73hHAyZRy/R7q1X4Sxw1wFX+Pw8/gJtZE+WU6dWsa0nz4sZ2lmxoY3VTF9mCQzhgUBkNcvacWo6dmCBk7fnj5++t06iJBZlZI33ZANLpNJ/73Oc45phjWLx4MZ/5zGf2+DmSgE2MBrI/UgghhDgwo2bzgFKKT37yk5x++unMmzcPgKamJgDq6ur6jK2rq2Pz5s2lMYFAgIqKij3G9Dy/qamJ2traPd6ztra2z5jd36eiooJAIFAa05877riDr3zlK/vzrQ6p9S0p1janmTexjA2tGQqOi2XomBpsbsvgeB5TKqN77CGbWB7mmIkJNrZlyBRcTF0jHjJRKDTAdhWarhEwDSZWhHh8TQupvE1VNEAibJEruGztyBEJGLxz0iTaUkVWNHYRC5p9CmX0LJM6ZmJi3C+TUkrxu9/9jk996lNs3769dDwYDLJhwwaOP/744ZucEAdoVm2cGWfF2N6ZI1P0ez1OLA/LDRohhBBiH0bN7fnrr7+e1157jd/85jd7PLZ7dTzV3TtsX3Yf09/4Axmzu89//vMkk8nSv61bt+5zXkOpp0/SlvYsruehlCKTd2hNF2hJFdnemWNLe46zj6zd4463rmtceEw9s2tjdOVtMkWPoKUTsgzArzzZkAgRD1k8urKF+rIgM6qjeAp2pgq0pAugIFNw+OWSzbRlihi6xrqWNKm8jeN5pPK2FB7ptmLFCs455xze8573lAK2QCDAF7/4RVatWiUBmxjVZH+kEEIIsX9GRdB2ww038OCDD/LEE08wadKk0vH6+nqAPTJdLS0tpaxYfX09xWKRjo6OfY5pbm7e43137tzZZ8zu79PR0YFt23tk4HoLBoOUlZX1+TdctnfmeGVrB1vbs6xqTNGetXE9hab84FPXIFuw+curO1jfktrj+bNq47z7xMkkQn4Bk0zBIVNwsEydGTVRTplRzYREiE1tGSYkQpw4rZK59WXdFeEMJlaEmVgRJu94bGhNAzChLCTLpHrp6uriU5/6FMcffzxPPPFE6fjFF1/MihUr+M///E8iEelhJYQQQggxnozooE0pxfXXX88DDzzA448/zvTp0/s8Pn36dOrr61m8eHHpWLFY5Mknn+TUU08FYMGCBViW1WdMY2Mjy5cvL41ZtGgRyWSSF154oTTm+eefJ5lM9hmzfPlyGhsbS2MeeeQRgsEgCxYsOPTf/BBI5W3Wt6RpTeXJOy7KUyj8kv+ugpytSGZttrZneWRFM57Xt0bN+pYUj69uwfGgPGxREQ0yuTLKaTOrOH5SOZ5S5GyXouNidO+xauryK8XVlYUIWQZB00DX/OWWrqeoigW56dzZUka+2xe/+EW++c1v4jh+5c7p06fz4IMP8tBDDzFr1qxhnp0QI4/nKba2Z1nd1MXW9uwef7eEEEKIsWBE72n7+Mc/zq9//Wv+/Oc/E4/HS5muRCJBOBxG0zRuvvlmvvrVrzJ79mxmz57NV7/6VSKRCFdeeWVp7Ac/+EE+9alPUVVVRWVlJZ/+9Kc55phjOPfccwGYO3cuF154IR/60If44Q9/CMCHP/xhLrnkEo488kgAzj//fI466iiuvvpqvv71r9Pe3s6nP/1pPvShDw1r9mx/pPI27ZkijlLYjsLrZ0zRgx3JHC9v6WB7Z65UPbKn6tu2jizhgJ85yxQctndk2dyWIRYwKAtb2J4ib3t0ZAqELYOObJFYyAKgYLvkbBfXg4ChMyER4o2daXRNY0796PgMh9oXvvAFfv7zn1MsFvn85z/PLbfcQigUGviJQowijuPx8tYO2jJFqqIB5k+uwDT3/x7i+pYU/1jezBs70+Qdl5BpMLMmxgXz6sb1zR8hhBBjz4gO2r7//e8DcNZZZ/U5fu+993LttdcCcMstt5DL5fjYxz5GR0cHJ598Mo888gjx+K7/YH/rW9/CNE3e9a53kcvlOOecc/jZz36GYRilMb/61a+48cYbS1UmL7vsMr73ve+VHjcMg4cffpiPfexjnHbaaYTDYa688kq+8Y1vDNF3f+hlii6u52Hb/QdsPToyRdZ37zWDXXvh2jNFjp2YoCmZZ8WOLtxeN7RztkdbxiYRsTANnZWNKUxDx3E9HF2jNVUkZ/vl/sMBgzXNKaZVRyk4bp9+cONJZ2cnK1as4LTTTisdq6ur49e//jVHH30006ZNG77JiRHN89SoLeTx2KpmfvbMJja1ZbBdD8vQmVYV5drTpnHO3L0vNd/d7u0DIoEw2aLD8h1JdiRzeyyzHs2fmRiYnF8hxFg3qvq0jQXD2aftiTXNfPT/llJw/GWR+xILGvzkmoWcMqOare1ZvrV4LeURi42tGZ5cu5O9rUDSgKMb4iRzDoau4bgeOdvD8Tw8T2HoGlWxAKBhdhcjuPXSo0sZvfHA8zx+9rOf8bnPfQ7P81i7dm2pjcVIJhdFI8NQZZcOx/l9bFUzd/xtdamybE+ftrZMkXjI4vNvmTOowM3zFN//5xss35Fkdm1sjwq061rSHDMxwXVnzkTXtSHPyMnvxvCSjKsQYjQbbGwwojNt4tAKmjpKMWDABpAtuGQKfgYsU/SbYmcLOkveaN1rwAb+a29qy3LO3FrWNqVpytqkC37GTtPA1HXa0jYRS6PgQl1ZiAllu5b/jfWLn6VLl3L99dfz3HPPlY59+ctf5jvf+c4wzmpgclE0/DxP8cwbrfzmhS1kCg4zqmM0BPedXRqsw3F+HcfjZ89sIpW3mVIRLvUWjId0ogGDLR05fv7sJs6cXTPgUsntnTne2JlmQiK0R/VeTdOYkAixviXN9s4cBcfdr4zc/hroszuYv2lj/e/hobC/GVchhBitJGgbRwr2vhZF9uUBT65p4Zy59UQDJkFD5+Wt7eSdgUO+dMElV3SJh0x2prubbys/C+d4HgXHI12AkGlgux6NXXkmV0b2evFz3lF1hAPGqL5waWtr4wtf+AI/+tGP6J3cvvzyy/n0pz89jDMbmFwUDb/1LSn+/noTf13eRHumQCJsYTuKmbVRKqNBYkGTdS1pHlnRzIzq/WtKf7jO78tbO9jUlqEqGtijGbyu61RFA2xszfDy1g5Oml61z9fquZEUCfTfyzEcMGjuypMq2DyxaiftmSKzaqKkCy4d2SIBQ2dWTZT1OzMH9Jn1GOize/OcWlY3pg4oGO45569vT5KxHaKWyTETE1x4TL38vnXrvXS/d8Y1HrIO6ndCCCFGIgnaxhGlFO5+VFb7/dLtzK4r46qTp1ITD7JjVX7Qz93UliGdd0kXHDQN6M7wleIVBXnHZXNbhvUtKVY1dvHw643kiw5lYYuykIXreSzZ0MojK5uoiQcJmPqoy/C4rstPfvIT/uM//oP29vbS8Tlz5vDd7363VAxnpJKLIt9wZjx6FwEqOC51ZSE0DVpSflBy/ORyKqPBPtmlwS43Hsrzu/tntjNVwHb9Pa39CQcM2jNF2jLFAV87GjAJmQbZokO8u9BRb7miS9A0SOcd3tiZJmzpLN3cSXu2iON5mLpOZSRAfSLY72c2mPM90Gf3ytZOvvPYOiYkQjSUh/crGF7fkuLOR9extjnV52/2xrYMq5tT3Hzu7FHx92+o7U/GdTwtwRdCjE0StI0jXQWnT/GQgeQdj7ueWM+J0yqZP62CXyzZPOjnNiULlAVNHEftdTml40FjssB3H1tXugMesnRMQ8fQNFylyBYcHE9hGhqnTK8iZ7ujJsOzdu1arrzySpYuXVo6FovFuPXWW7nxxhsJBALDOLvBkYuioV06OFBw0DswmFgeZntHjoCpo2sagahOe6bIGzszVEQCpexSpugMOsgczPld15zipc3tlIWtQQes/X1mwe4lj34Wfs/lj7mii2X4GbeBTCwPM7MmxvIdSWJBc489bY3JPMdMTBALmrSmC7RlChRsj1jIxDJMbNejJZUnmS9SFQ32KYY02PO9r88OIFtw2JkqcMLk8lJgOZhg2PMUv35uC69u7SRg6sRDFpahYbuKVN7m1a2d/Ob5LXzh4qPG9I2SwRhsxnW8FrsSQowtErSNI+2Z4qD2s/VQCjqyNj9fspG3Hj+RoKGRH+R/+1zPY1JliO3J/D7fUwGt6QK6pmG7HtmiS8gyqE8EaUvbpAv+1+2ZItmiS1n40GR4DkfmpKqqio0bN5a+ftvl7+Lm//gKM6ZOwTT3zA6MROP9omgolw4OJjjoHRgoBaahY7uKoKmhaRqxkEl7pkgq72e0g6ZBS1eeB5Zu542daRzPJWgYNJRHOPeoWk6ZXsWOZI4NrRmAUm/Fhr2c35ztsqKxi//+22oUEAuanDitkrfsY4lef59ZpuD3iLRdxY5kntkBA13XUUpRdLzuIKrA3Poy5k+uGPCz03WNC+bVsSOZY12L//n0FDVpTOapjAY4/+g6AoZOa7pAtuBQW7YruAqaBoGoTnNXHhRELGOvc9/b+e79u6GUIpV3KLoeAUNHoUgVHAKmjr3bXauBbnZs7cjy3MZ2dE2jKhroNWeNQDRAc1eBJRva2dqRZWpVdMDPaiwbbMY1GpBLHSHE6Cd/ycaR5mRuv59TdDyWb+/i/KPqsYzBBzWGrgHaoILE5q48AdPA1HXKQgZ5x6MtXaToeESDBkVXkczZFBwXsA46wzPYO+kHG9hVVVXx1a9+lW/e+R3e8uH/QG84mt+uzBBau3bULPEczxdFQ7l0cLDBQe/AQNegIhJgZypPoPti3jJ0MgWHguPSkbUJWwbf+McaWtP+EsOi4+Ephbalk8WrmkiELQrdrTeUBhHLRClF2NKZXNk3AGjPFPnX2p20pAqY3d+frmus2NHFS5s7+H+XzN3j57e/z6y9u4VIR6aA4ylyRZeVjSnKwiaO65G3ve5gx6AmFmBTe2ZQvxezauO8/7Rppd/l5q48QdPgmIkJzj/a/93a3JbB/zu0t/PjP6YGcb7XNqf53UtbedsJE4kHLSKWQcg02NGZpSlZ6LP0MmjqpPM28ZBFwNgzq7ivmx0bWzN05orUxIL9Zj8TEYu2dIGNrZkxHbQN5u/vYDOuE8v7vykhhBCjydi70hJ7VdyftZHdFLCjM0dTMk9gP5rfamgks/Yg5wWucomHNHRdI2Dq5G0XT0HIMvCUR9Hx//U40AzPYC+WBxvY9TQJfurpp/nNXf/Dg/f/gYkTJ5QeP+uyd7Ox8kSSBcWEiDXqiniM54uioVoauj/B4O5B86zaGOmCQ3umSCxk4il/+fH2zhyxoMWKHUk6czYVYYu2TNHP8iiFrina0jbNXQVClk5DeYiwZdKRKZLM2Tz7RhvnBgyqYn4lV6UUL2xsozGZR9MgEjCxTD/Lly04vLS5nbufeINvvPO4PhfSu39m7Zkiy7Z2kis6xEIWU6t0dnTkSOUdGpMFNEDXIWaZHDUxTs7xuPeZTYP+vZhVG2fGWbG9XtznbJfqWABNo/SZWYaO7Xqk8w6xkElVdyuTja0ZXtvWSUP5nue7I1tkZyrPih1J1janqIwEmVEdRaF4aVMHAUMjHrZKSy/b0wU6sw7lkQDx0J7/mR3oZoemYO+NWcZ+l57B/v0dbMZ1vC8jFUKMDRK0jSMxc///w6UBrqd4YWMr7n48Lxo0aMsOXFAAdl2C5IouYcvE0PylmZrmL7N0XA/L0LAMja6cTdH1KDouAUPfrwxPfxfLSimUgvKwyfqWFL9cspk3z6nj7ysa6cja+wzsHlvVzF0PvchTv/42bcseBeBN7/oQP/rJTzlnbh2ep3h0VSvJghq1RTzG80XRUC0N3Z9gcPeguTIa4PjJ5aXMVWfO73e2cGolW9ozpPIOdfEA7Rkbx1NEA/6Nlvasjd1900bXNbIFj/KwTn0ihAK68jYvbOzgtFlVRIImTZ15NnYvoayIBEo3bIKmRsCw6MjaPL1+J1vaMkyrifX7mSmlWN+SJld0qOzODGYKHkVXYRmUlluWRwKgFOmCx8yaAG2Z4n79Xujd/R77Ew2YVMeCVMcCNCYLdGSLpAsOpq5TWxYiEtDZ0ZHnnqc3ki44bO/I0ZmLcERdGZXde+vaMwWWbe0kW/B7T9aXhYkEDJbv6GJjq7/kc/cbWpZhYJkOmYKL63o0pwv+37eAQX08tM+bHTOqoyQiFl1Zm1CZsceNkmTWpjxsMaN6bGbZ9ndJ8mAyrkIIMRZI0DaO7OgaXBDVmwJs1+MfK5op2IO7w6sB8xrKeXVb+4Bje5i6jusp0gUbQ9dRgKlppPIOIcsgZBmsaU6TLbo43XvfZtbGyBUHDiV7ltm8sTPNa9s7aUiE+yzbaurKkcz6weDKHV08vroFXdc4uqEMpUDX/IvLuniQ9TvT/P6lbRzXEONjX7yDrY/+HK+QLb3X9g2r+Y/fL+Wr71zAEXXxg87U9Mw9VbD9zEDQJB6yDmoP3v4u+zwcF0U9Gcu2TJGqaID5kysG7NU11IZqaej+BIP9Bc1lYZM59TE2tGrMqI1x5UlTmFwZ4ba/rCBg+suSc7ZH0NTRNA3HVShPde+J07B0jZztUnQ8gpbR3ezeDwh2JPOYukZTMo+nFPGgsUdAomkakYBBKu/w0uaOPkFb78/M3xNbJBaySjdI2tIFHM9fChkK+H0jy0IWAdMvqrKhNcORdbFDVtymd9C7cGo56YJb2ndWdFweW70T2/UoOC6255EpOqxpStOesZnXUEY4YLC6KUW26BILWRQcj7BlEA9Z1JcpXtvWSWXMIhHyA9megLAuEWJ6TYTXt3Xxy+e3YHsenqfQdY2QaXDspPK93uyYVBHhlBlVLF7ZTFu60J3B87ODqZyNp+DkGVVMqhh7hX8OdEnyQBlXIYQYCyRoG0fcA1hWo0F3uX6NgAWFfVSD7GEZGpMqQjhuGc2ptkG9T6F76WO24KJw0TSwdH+5ZNFV6I5HZ9YmZPnFC8rC/o/uz5fseylV72U2Lek8G1syJLM2tWVBNuzM0J4pkik4KKUIGDrpgs2OZA5D12hLF6iOB0mELNAgb3vkbZfXXniW2/78XfItm0rvo4eiVJ/1PuLHvYWdOcVtD63gypOnsD2Zoy4eKGUIA4ZOPOQvMxwoU7O2KcUflm7ltW2dNKcKOK4ibBlMqYpwwuSKA2ree6CVEIfyouixVc387JlNbGrLYLselqEzrSrKtadN45y5dQf9+gdqqJaG7m8wuLeg+eTpVaWgeXVTF67yC2wUuvex6d3zVd0L7RR+9trQNBxP4Xb337AMnYCpU5cIcsVJU6hPhFi8oonlO5IErP7L8xu6hupu27G3z6wiYvlZ8u7lgQXHI1VwiFgmrvKwdI2C4+Eq1aeoiuMpCo57SIrb9A561+/MMCERojxikS04PL2+jVTBpjJi+YGRrmM7io5skS1tDjvTBcpCJp1Zm4jlB02TKiKl5Y62p7BMDddVHFkXR9O0Pr/jb+xMk8z530+Jp7BdxZrmFJvbsv3+zum6xpUnT6ElVWBtU4pU3uk5exi6znENca48ecqYDEgOZknyvjKuQggxFkjQNo5UhPe/YqGGf6EX0P0y45bh0ZXfd3YrFvQvvhbNqubxtYML2noua5zuJtxBw78wLLoeCoWhg4aHp3TqEmFm1kSpiAT2ucRw92U2saBJY2eexs4s61rS2J5H0XZxu9/Ts116ts35DbA9OrJF2rqLOlSS4o2Hf8i2lx7t8wnFjzuPqrOuwYwk8Dy/kfjmthx3PbaenOOxbEsn8aBBeSSAaehURALMqo1hGRoBQ6crZ7O6qatPIPTYqma+89g6dnTmyNn+5+1XuFPd/bq8/W7eu7YpxV1PrKctU6AhEWZ6VXS/WijsflHkeYqt7dmDCuIeW9XMHX9bTSrvL/PrWXq5tiXFHX9bDTBsgdtQLQ09kGBwoKA5GjCpCFukcnZ3NVb/59DQ/P2lPQzdrzrZE7yBn0n3X8NiZk2MyZUROrNFQv/yv1czpO0xRz+w1JlVuyvLtvtntq0ji8IvhtKzp0zXNCpjAdrS/n47TdNK87AMnXTBIZV3Dmlxm/6CXtvxyNoOibBFfVkI21X+70/AQGXwl5IWHaqill8ZsuAS9KC6V3GQgKGXgmTbU1THdrUq8DyPFza2YbuKaNAgYBhomkIpDcfz6MwW+f4/13Pm7Jp+M8qzauPcfO5s/r7cb66dLbpEAgbHTiwfFQWMDtR4r1YrhBD7IkHbOHLSjErufXbL/j2p+6IvHjJRwM7Uvv9jGTD8i8CmVJ7J+QMvTuEpDac7API8hecpYqEAM6qjTK6MlC6c9nbntb9lNo7joGv+/p50wUXv/v789+u7vd9/X0jlHIKmjq55PHf3TRTaduz6XutnU33edYQnHomrwPboo6vQE9wqCo5HuugwIRFmZypPKm8TNHUiQZPfPL+FguuVAq4j6mN87/H1bOvwl13qmkaou3S4sj1czyFgFFlTdFi+PTmo5r1rm7v4z4dW+Y2GAzqt6SKVkQAza6PMro0Nen9dT1ZvVWMXL23qYGcq32fu+3NB6TgeP3tmE6m8zZSKMLruX7zGQzrRgMGWjhw/f3bTXi9sD4ehWBp6oMHgvjIJE8vDzKqN05opErP9wCdnu6VAX+Ev89WBousRDZgETL1Uqt7QNY6dtCtQXDilklm1MVY2dpEtegQtHUMDV0HB9nA8xdENcRZOqdzrZ/b315vYmWqiuStPImxREw9iGhoRyyBj6n7BlIhVWn5pux6mptGRLXLy9KpDWtxm96B3+bYky3d0EQsaNCbz5Gw/O5nvvkESMP1spN9KQfOXiXa3D5hW5f/9iYdM4kGTxnwea7dztb0jR0fWxtQ1ogGzz7kMKA3XU6xrTvPSlnZOmVG91zl/bJwt+RvP1WqFEGIg8pdvHAlbFhFLJ7t7dLEX/uWevw+mMhqk6Lh+X6PdaPgXhAFD9ys9uh5tqSIPv950wHN1PUUwoBMJWCRzNrbr351evxNiIYuKiFW6MO3IFknld1WqdByPv67YweIVTcTCBp2ZAmuaU7y2PUmu1748F/ZaiE1Bqb9Sz+cVO+XdFB7+Fnq4jPI3vY/Yseeh6QbOIFed5m3F1rYs1fEAO9MFlFJMr4xgahAwDToKBZ7uzPCbFzfTliqgaf5yVB1wXb/peFfRQQO6crZfqEUpauOBUsamv70fG1rT3PXEG7yxM015xCIaNLEdj+2dWVrSflanLh7k1W2dPLVuJ9Oro2hA1nb7XCj2LK18ZWsHa5tSOJ5iQiLEkfVlhCx9vypiep7i7ysbWduSIr5btglA1/0myxtbM7y8tYOTpleVnne4L2KHYmnooQ4GeweC4C9n3t6ZI5mzQYN40MQ0dP/3xPWIBHXyjkcya+MpxXGTy7lgXn3pezJNnY+dPYuv/GUlbZkCXlGVsnf+z1yIj541a6/B9KzaOB87O8ZxU8r5zQtbyBQcpldFWd2UojGZQ9c1gpafvS+6Hqau0ZGxCVo6E8vDQ1LcpnfQ25TMY3sebWk/WAuaOp4HOaVKywssA46aUEZXziGZ8/fm9fTEK+tetRAJmtTEgzR15dF1rRR8r25O4SmIh8w9vo+epdFdOYf1Lem9Bm27z3k8GM/VaoUQYiAStI0jM6qjTKuO8kZLisIgSkHqun+BURENEg4YKBSmDs5uMZ8GGDrdAZt/X78pmTvgwtQK/45+3nYJGBqG7hdT0DToyhV5YWMbEcsga7vkijbpgscXHnidBdMriAcNHlzWyNaOnL8XDnhmfft+z8Xp2ommmxixXY1+o0efjZvpIHbsBRjhA1ue5Cho6lUQ5rUdKSDlZ0Lwg9/dg0AXsG2vlMrTAFtz6d6SxJIN7bSkCkyvjvnHNIgGDNY1p9jakeUfy/2CBpGAQTRoUrBd2jN+Fb2c7dGYzBMPGHgKdqbz5Iv+Dii/6l6QmTUx5kyI8/jqFtrSRToyRSxDozIaIJmzeX17kuMnlw86Y9cT/D21roXObBHb8fcKVnb/nPUIB/ym6m2ZYp/n7e9+vIEMJhAciovnQx0M9g4E17ekiAVNWtMFDF1jQiJMwNTpyBbpzBTJFFwyBZdEOMCiGZVccfKUPT7DnmWp9z69kTd2pim6HmHDXxJ57WnTB1y2qusaZ8yuYUIiVDpvAdMP1IKWzpH1MdJ5l53pApmCQ9gyOWNWdb9zOdSmVkVAaWSLDuVh/2ff7i7WYuh+e5SAqTG1MoIHLNvaSTpv4yrI2X4j88ZknimVEd48p5aV25O8uKmDdNEmFrCYXBHijZ1p9O5KuK7n7yzU8P+euZ7/9yxk9r9ncLwaz9VqhRBiIBK0jSM9VcnWt6QGNd7xoCpqoqFQStGeLpLvZ3Wkh99rrbeC46Ed5Io224O27K433N6R85ctKrAMv1BJ1vaXfrVnk7yyLdnv3PaHcmy6XvwjySW/JTzrZGouu6X0mKbpJE6+/AC/m728X6//78GARV56ntPTck/DD25X7uhiVWPKXwLXXaEuHrZ4Zn0r61tSlIVMtrV7NCdzdOYc8kUHx/Nfq+BApuBidmcYTN2fR8H299G8tq2TR1Y2URa2mFkdZVNbhnjYImgapap/b+xMs3BqxYAVMXvvM6yKBQkYfqXQTNGl6OapLwuVArdc0cUy/Izb/pYBH6yhCgQH61AHg7sHgmHL6JM1nVAWYkcyx4bucv7Tq6NMrojs9SL4nLl1nDm75qAqe+4+p9ZUgWVbOtnQmiFguCQiFhMSIc6ZW8dpM6sPywW5oWmUhUzSBZuOnF/pUimF4yocr3tfrelneiojfpuFlTu6aEkVaO7KUxEJlrKim9uyPL+p3Q9sHY+AqTOhLEzQNMgUHIqOv5y0p42J2b1XNxG2WDi1YsC5jjdSwl8IIfonQds4ondXaxtElXzAv6BPF/w9BBt2pmkfZLNsgKLH/kdMA+i9qrPoHliz8H3JbVhK+6M/xOnw961lVz1F/vgLCU059pC+z6Gk6J359D8PU1PYjkeqYPPDJzf4mQGgI1P0z8teOApaUgVMzb+4bEOjPWsztTJcKgXfni3SlbPxPBOlIGjqpap/qbxDJOgXCkjl7T2KlAB99hkqBcu3JWnLFCkLGeQdj/ZMkQYr5JeHzxQ5si7O8RPL+fHTG/e7DPhADlUgOBxLNvdloEBwSlWUKVWD7/FlmnppeeohmVM9nDqzelg/s6ztUhG1aEnlyTteqeCS1quAi2VotKQLaJpGediiJh5iwbQK3nbCROJBv+3GE2ta+i2ks60zi+N52K7ye0qaOoYOruffINF1jWMnle/XeRhPpIS/EELsSYK2cSSfd3jo1cZBj6+LW2SKHpmCTargDioLNBrZnU10PP4Tcuue23VQ04nPv5hA7Yzhm9gBcnrquwOb27P7HLu35+sKNE2Rzjts78yTKTisbU6xviVNpujQkvKr/ZWFLGriARzP38uoFf0s659e2UFrukDOdruLyJjMqI7y6rZOEmGLtkyRgKFz3ORynl7fSlfev7DNFh0/ACw4lIUsrjl1Gs3pwkH3u9vdgfaD2t1wZ+pGqwPJMB7K4DhiGWSLLvGwRZnyM72eUgRMhe0obNejI1Pk5c3tBEyDoGlwZH2cdy2cXDqv+yqkE7F0VjSm0DUN0wDH83BcPygMWjrRoMnUYdyrNtJuNPRnvO3nE0KIgUjQNo789uUtpPI2OoNLgumaRl08SFumiK5ByNIp2h6D7LE94nl2ga7n76fr+T+gnF37zIKTjqLyvI8SqJ0+jLMbZt17cRylyBfd7n5aELZ0LMNvhO56fk+rvO1SGQtg6RrrWtJ05WyM7uu/DW0ZmpMFCraL0kB5/n67sohFJGCWlp690ZKmI1uk6HpYps6RdXGuOdXv07a6qeuQlwE/mH5QPYZqyabY06EOjv0/YRqWrlMbD2C7ft862/HY0Zmj6PoZ7M5MEbM7aEvttjb85a0dbGrLUBUNlAK2Ho7n39TQ8JheHSNVsEtLJycmwkwoD9GRtQ9JA/H9JTcahBBidJKgbRzZ1p7DAwZ7PzWZdcjbnn/BDYQsg9y+1teNIrmNr9D+j+/hJJtLx4xoBeVnf4DoUWftcSE/3ni99syli7vasjuOh9ZdSKFHpuAQsgx2dOboyvllzpu6CmzYmSZnu36hGkPD6W7Mni44aLpGJGDQksoTDhicfkQ1OzpytGWKXL5gIlcsnEqge2/boSoD3ju70JTMk7MdGg4wEDxUmToxsKEIjnO2S3UsgKZBR9YmFjIJGjqNyTxZ269maeoaE8rDBE2dvO2yYWeaXz+/hS9efBS6rtGWKWK7Xp/iOT1c5VfbBJhaFaaurLJP421XKTa1Zg57vzG50SCEEKOXBG3jSDTkX1wMNlGWdTzyjofevdcjV3QO9Ta1YeMVMrsCNk0nvvAyyk+7Ej0oy3F62/1nxVYQwL8g7b3HsD1TYHN7jpDpN0hu7vKzaxpgmToF2w/YtO7NQ9mCQzpvMCERYntnnsdWNqPQKI+YvLK5k+0deRZOr2RufRkTykIHXQZ89+yC6ym2tucIWwaTK/fcVzRQIHgoMnViYEMVHEcDZnd11ACNyQId2SK5olPKEseCJmga8aBJ0DKIBU2au/I8v6GNbR1ZplRFqYoGsAydXNElHuqbaTM0DU/5S/wiQbPUIqBHrnBoG4gPhtxoEEKI0U2CtnHk7Nl1fO/xDTj7sTmtVNFQ7epbNhZEjjyN0NRjUQoqz/0IgZqpwz2lUaO/QjauB9s60tiuXx2v4HilIE11L63U8H+WdM2v0NeR9dsOpPMOroJo0KAiYrG2Jc3zG9t56LUdTKmMcuykck6cXtFvGfAdnXmCls6sOr9oQX97c/rLLmQKDht3ZnhxU4e/TDMaIJV3/OWZukZTV55jJ5XvNRDMFJ1DvmRT7GmoguPe/cAWTi0nXXDZ1JphZ7pA1NJxPL93m+MpsP39lomIRVu6yIbWDFOqosyfXMG0qihrW1JEA0afJZKm7mfbwqZBfTzU572Hq9+Y3GgQQojRTYK2caQyHmRmTZQ1zenhnspho5Qit3YJ+S2vUnneR0vHNU2j5u1fRAuEx/1SyEPBA7JFv/1C76qeSu1aallaYtmdocvsVmJUeR5bOrJ4niJo+BfM2WIXm9syPLa6mROnVpII+w2O7S6Pgu3RmS3geIofPbWByrDFsZPKufCY+tISr71lF8rCFidNr+DJta38a10rVVGLdNGl6HgUHY+aeJB3LozvNeNwqJZsin0bquC4dz+w9TszTEiEiIb8c5XrbiOicNnemUPXNMKWQSTYdxmkaepce9o07vjbarZ05PpUj2zLFKmOBv2+mK2ZEdFvTG40CCHE6CZXFOPIxPIwlx03kd++tIUt7bnhns6Qs9u20f7oD8lvegWA8MyTCM9YUHpclkIeWgeah9W6n5uxd5W9LDh+Oi9ne2QKDk5XgU2tGapjAaZURplVF+P5xjaauvJ+9g4IWgZrWtKsbk5x87mzmVUb32d2oSoWYk59nBc3tZMu2ARNnZBlUJ8IEg1aPL66halVkX73+PTO1Bzokk0xsKEIjnv2Njqe4i3z6ks949J5G13TKDoeQVMnaBkYmoarFOmCTWeuSF1ZiOnVu5bT9jQY/9kzm9jUlqE9U8QydhXSmVoVGTH9xuRGgxBCjG7y13kc6bm7vLIxSUe6QGqMFBXZnVfMkXz2Prpe/DN4u+4aZ9ct6RO0iZFhX8GeYtfeOU9B3vFY35Ji2daO0vJLDXDxy6oXHY+XNnfwm+e38IWLj9pndkEpRXNXHttVxIImuqahoRE0DaZWRmjLFPe6x6d3pmb3JZvDlUkZiw5lcOx5imfeaOWxVc00JvOlDNr06iinz67GMjR2dObZ0pHFKC117Pnp1HA9j4qIxcRE3/c6Z24dZ8ys5pHVTTQlC9Qngpw/p75USGek9BuTGw1CCDG6SdA2Dm1qy5Cxx17AppQiu+opOp64BzfdVjpulNVQ+eYPET5i0TDOThwshd+YOGTsCuRM8FsJqO4WBa6foVvyRhtbO7L7zC5s7ciyqTWDAuJhvxiD7Sp2pgqkCy6za6P73OMzqzbO+0+bNmIyKWPRoQqO17ek+PVzW3hiTQs52yUaNKmJBXFCJn95dQe261EdD9CVtwmZBkopiru61qNrUFcWojwSoLEr3+fnob8S+ptbc6US+iOl35jcaBBCiNFNgrZxxPMUX/vbKtY0pcdco+zizs20P/pDClte23XQMEmc9G+ULXonuhXa+5PFqOF4inSv+w0eYKCh6UB3X7lc0aU5lWdja4Y3za7pN7uglOKNljQF16M6GiDe/VjQ1AhEA7RnimzvzFMVtfa5x2dWbXzEZFLGqoMNjte3pLjn6Y28tNnPzk4qD5O1XTa1ZcjZLvGgCWh0Zv3KkfGQQcH2CFi63xxb16krCzK9OkoyZ/f5eRhtJfTlRoMQQoxeErSNI5va0jz7RhueUqV9RGNBsXULjffe4Hdu7haesZCKcz+MVdEwjDMTh4dCw18naeh+oZNs0UUptdfsQktXgaauAkHTIB62+iwV0zSNWMikNV2gPGwNuMdnpGRSxrIDDY57CtFs78yhA+GATlNXgZztkCk4FF2/ebxpaLRl/OW2ZSGLkGVQHQ8yZ0KcoGEQD5mkC37fyp6fh9FaQl9uNAghxOgkQds4snhlC3nb88tRe+COkajNqppMePp8chtewkzUUXHuh4nMOnm4pyUOg56MsY5C7xN4UWp63F92IW+7lEcswmaITNFBKdUncDN1jUzBoaE8PKR7fHo3/JaL5307kOC4pxBNRSTAxtYMuaKD44Gha/5NKwUFV1F0/d6DhuE3zQ5bOoahETQMysJWv3u+RnMJfbnRIIQQo48EbeNIV94GBToa7ijOs9kdOzDLJ5QulDRNo+LcDxNYeSRlJ70D3QoO8wzF4aSUfwNC6QrX8/cfVYQDfRoa755d6MrZ/Ob5LWgarGtJ054pEguZWIaO7Xp0ZIqELYNz5tYOWRDV316omTWx0l4ocfB6CtFURQJkiy62o4gGTWzXw3EVvXf2ahqETb27YqmLUgWyRQdNo989X1JCXwghxOEkQds4cmR9HF339/2Mxiybl0/T+fSvSL38MDVv+zyRXoVFrIoGyk+7YhhnJ4ZD72W+rud/HQuazJkQJx7sW3ikd3bB8xQvbuxg+Y4kx01KsGFnlvZskUzBQdf8CpKnz67m1JnVQzLv0bYXarTqKUSTt7s7wmsAqhTo9+hJlAVNnYBpkMzZ5G2XzW1ZGsrD/e75khL6QgghDif5r8k4cuHcer4WD9LYVRjuqewXpTwyrz9Gx5M/w8smAWh/7MeEpp8gBUbGIQ0/m+aq7mvwXspCBrPqYiyYWrnPZY2997q1ZYocWR/D9fxsdEe2yKTyCFeePGVIsmyjdS/UaNRT5n7JhlbClo6G3/vPU7sitp6fJ13TQNOwdI2gpaM8xUXH1nP2kXX9LluVEvpCCCEOJ33gIWKsCAQMPnrWLMKWMdxTGbRC03qafvkZ2v727VLApllB4ie8BU0bPd+H2Lf9CU3KQgaVsQDRgEHQ0gkHdKIBnVjQYEZNjDn1ZZx7VC3bO3Osbupia3sWr59yqT173eY1JEjmHNoyBXRN4+TpVbz/9KHLdO3PXihxcHqC86poENeDspBJJGDg9kqzaZq/x83QNTzlB3WWYRAJmkypjDK5MtJv8Nzz2pXRAOta0qTyNo7nkcrbrGtJSwl9IYQQh5Rk2saZqxdNoyNb5JuL1w33VPbJzXXR+dT/kV72d3rXuYzMOYOKsz+AWVYzfJMTB6x3lmx3AUPD8xSO6jve6L7mdVT3/9c06uJBpk/396h1ZIrYroemaZw0vYqTpleyeEXLoPaKDUclPdkLdXjNqo3z8bNn8Z8PreSNnWnClo4etXA8f0eboUGxey+k5ymiAQNPQXkkwPTq6ICvLSX0hRBCHA4StI1D1589m+89uo7iCNzXppQi/eo/6Hzy53j5VOm4VTWZinM/Qnja8cM3OTEgjV1Zs93btxsaRAIGecfD647atO5NaQr/gln1vIZfwZ+gpeO6yq/uiL+EbVpllGMnJ6iM+r2zunI263emOaqhjLcfP5H/e37zfu0VO9yV9GQv1OF3RH2c/3fpXO564g3a0gXqy0KsaepiY1sWpSAa1KmOBrBMnYLtYruKRTMqmVwx8M+FlNAXQghxOMhVwTik6xpzJ8Z4dVt6uKeyB03TyG98uRSwaYEwiVOvoGzhpWjGnhe4YuSxDI1E2GJKVZhVTWkc10PXNDSg6HigFPGgQdAycD2FZWgUHJec7REwdCIBg6Dpr9zuyjsUlIfrQcTUqYhYlEX8Ko+O53U30i4wtSrK5QsmsXhFy4jfKyZ7oYbHEXVl3PDmWaWsWEU0SHvWJm97RAIGCv/n0zR0jmqIc8V+7GmUEvpCCCGGmgRt41Cx6I7IgK1HxTn/Tm7jUsKzT6HirA9gxquGe0piEPxiDoAG6aLDptYc5WGLungQBbSkCrSlC0Qsg8pYkAmJMDOqo1iGTsFx6cz6FfsuPa6B17Z18sTqFkxDJxayqI4GmF4doTVt05Wz2dKeJWjqfZaiBU1jVPTN2lvD71zR7be0vDh0ds+KtaYKvLK5g+U7usjaDhHL5NhJCS6YVy9LG4UQQowoErSNQ994dMVwTwEA5bmkl/0NI1pJ5MhTS8fNsloaPvRDzPjQlFsXB8bQ/J5oPcseNSBgQNAyKNgetqdwPHA8haUrQmGNuRPKMHSdoKlzyXENPLKymemVEcIBk3iod5bJoiIaYFNrhiPr42zvyDG1OsrE8jBB0yiNnVypWNucYmpVlLce30A8ZJWWoq1u6ho1e8VkL9Tw6ZMVq4dTZ1bL0kYhhBAjngRt48z6lhQ/emrrcE+D/LaVtC/+AXbLBoxYJaFpx6MHd2U/JGAbXpYGdveeRw2IBHQ8BXnbD9ks3d+HptAoOh5FV5XKxehAZTRIMGDS1JXnuEkJ2jI2zV15GspCRILmPvdypQsOG1ozzKyJ7TFO0zQaysPsTBWIh6w+GbPRtldM9kKNDLK0UQghxGgwMq5exGHheYq7H18/rHNw0x10PHkvmeWP9zrWTm7DS0TnvmkYZyZ62726o6dUnzLpPY2si+xZzUbTwPH8fUK5osuG1ixH1sXY2VWgJh5ia0d2n3u5YiHzgDJmo3GvmAQMQgghhBgMCdrGkc3tGf6xsnlY3lt5LqmlD9H59K9QxWzpuFU7g8rzPkpo0txhmZfoX+/KjwrI2wpd21UZsqfKY4/exy1Tx3YVHZki1bEg7ZkirgdF12PhtAoyRWefe7mCpnFAGTPZKyaEEEKIsUqCtnHkuQ2tZIruYX/f/JbX/aWQrZtLx/RglPI3vY/Y8Rei6dIke6TqrsiPafjNh23HI2BoFF2Fq3aV5+/du9r1FEXl0ZYpEgmaKKXoytsETYO5E8qYURPd514uz1MHnDGTvWJCCCGEGIskaBtHXtjQdtjfM/XKX2l/5O5eRzRix55H+ZnXYEQSh30+YmA6uzJtOqDpEA0YZIsuQVPH9VSpKIm+W8Cma36TbLr3ujV35amIWHRki5w8vaq0Z2tfe7kONmMme8WEEEIIMdZI0DaOrG7sOuzvGZ59Cto/70UVcwTqZ1N53nUEG4487PMQg6fr4HVHbQoIGH6g5imFZRrYRdfPvukQtgwytovndS+NNPTuDJxC1xR52yWd15mYCPcJtAbay3WwGTPZKyaEEEKIsUSCtnFkR0duyN/DzXRiRMtLX5uxSirO/iAAsWPPk6WQo4DTa0ObAiqjAQqOR9Z2KdgeIcsgahnkXY+C45aycRoaYcvA8TwKtguaRsjQSUQs3nLshP1emigZMyGEEEIInwRt40iyuGelv0PF6Wqh47GfkN+2goYP/RAjFCs9Fj/+wiF7XzG0jO7iI4auUR4KEA3qzJ9SyeTKMNs6cry0pYPWVAG9e4yGX6U0ZBk0lIc5oj6O63rUxIMH9P6SMRNCCCGEkKBNHCTl2HS9+EeSS36LsgsAJP/1SyrPu26YZyYOVE8eS9f8/myWoXPspDLOPLKGV7d20pG1yRRdGirCHFV0eDZTRNMgEbawDL8R9ozqKJMrI6QLDp1Ze8T0RhNCCCGEGI3kSkocsNyGpbQ/+kOcjh2lY3okQWDC7GGc1dhmAENZ/9PoVVgkYOokIkHCAZMrTp7CGbNrWDC1os8+s0jA5PjJ5RQcj1m1MYKmH7RpmjZie6MJIYQQQow2ErSJ/WZ3NtHx+E/IrXtu10FNJz7/YspPvwq919JI0Vd/JfIH8xyF/8taFQuQLNh4Hjjdza69fT25m675lSCd3d63d6XIHiFLZ0IixFENCSoiFm3pQml5Y3/7zHJFl58v2UR7psiEhIGrFLmCI73RhBBCCCEOEQnaxpHTJod4Zmv+gJ/v2QW6nr+fruf/gHKKpePBSUdTed51BGqnH4ppjno6YBl+kGLogFKURwNMSIToyru0pwvkHQ/bVRTdwUVv5RGLYxrK0DSN1lSBrlyBvAuZvONnxMJm91JEBw8/0NN1CBo64YCB43oUXUXc1KmLB2jJ2AQMnbqyIK2pAtGgRXnEIhG2aEiESEQCaJpGKm8Tssw+yxv722cmvdGEEEIIIYaOBG3jyOUnH8EzW1874OcrO09q6YOlgM2IVlB+9geIHnVWnwbI45mh+T3NTEOnLGJRFQ3guIqaeJCgqTOlUqe2LERDeYjtHXnWNnaydGuSbNFl9/hNAwKmxsSKCP/xlrlMq47wj+XNvLK1g3TRQXNdoiGTsGUQC5mYhk4kYJIpuhi6xpF1MX//WcHB9SBo6cyqiaFpGvOnWVx0zAQqowH+9MoOtrRnOKIuvl+NrHuTSo9CCCGEEENHgrZxZGJVhLClk7MHs6BuT0YkQfkZV9P+2I8oW3AZidOuQA9KZT9L8wOikGVimTooRTxkMqUqyvwpFZw7t45wwNgjmPE8xfbOHKuaunhxYzsrdiTZ3JYlW3QJmP4SxROnVfLOBZM5ot7PVvUERqsau3hpUwdv7EyxrSNHKu8QCRjMqIkxtTKCAjqzNoaud89SozoWIBo0mVUb65MBC5g69z6z6YAaWfcmlR6FEEIIIYaGppQaujrwYg9dXV0kEgmSySRlZWWH9b0dx+P9P3uRFza2URhgWZ5XzNP1wgPE51+MEUmUjivPxeloxKqaNNTTHRbTq0LEQwHa0nlyBQdP84Mrz1NousaMmihh06AtW8T1/KxafSLMsZPKOX5KOVXRAOmCQyxkEg9ag8429QRwqbw96OeXnlOwSecdYkGTeMgqZcV6sl4Ry0ABOdvdawZsfUuqtLyx4LgETWOP4E4IIYQQQhxag40NJNM2jpimzrWnTaOxK8+OtjTZfsoQKqXIrn2Wjsd+gpvaiZtqpeotN5Ye13Rj2AI2Q/P3iPnhhoZlaLieAjQCpt/YOWSZVEZNmpIFcra/TBAgFrI4blKCRbOqWbyiiWffaCVvKxT+HrRE2GRCeYg3z6nH0P3Kh6m8Q9H1CBg6YctgVVMX7zpxMvMaEkwoC9HYlT9kSwEPJEs10HP25/VkeaMQQgghxMglQds4c87cOgB+9swmnlnf2qdyoN22lfZHf0R+0yulY+kVT5A4472Yscohn5uBH5A53f9r6hrHTIxTHQ/T3JVnc1uGouOhaRqV0QBH1sVY05zG8RRHTYgzsTyCoUNTV4E5ExJcePQEPPyM4vTqKJMrIui6xrsWTGZTW5rFK1voytscWR/n6IYy7nr8DbJFh3jIQtM0ysJWaW6pvE1FJMC8hkQpGBprSwFleaMQQgghxMgkQds4dM7cOs6cXcPLWzv45G+XsaW5neSz99H10p/B25V+C007gcpzPzIkAZupw/lH1XPlyVO4f+lWnl7fRrrgoBRETJ3JlWGqYyEiAYMJiRCzamPUJ0KsbuzCVTC9KkpZOMB5R9WBgs6cTVumMKiqhbquMaMmzkfO3PW45ylm1sRYviNJLGgecEEOIYQQQgghDjUJ2sYp09Q5cVol10/bySe+80m6GhtLjxlltVSe8++EZy864KqQibDF595yJCdMqSAaMKkImvxkyQa2teeZVBniw6fOJBLxM1mnzqxmS3uGFzd1kLddZtfFWDilkk3tmV77rPJEAybvWjiFYycnqIkHS0v4gINe1qfrGhfMq2NHMnfQBTmEEEIIIYQ4lKQQyWE2nIVIdvfud7+b3/3ud7sOGBaJk/+NslMuR7dCB/SapuY3gL7+zbO5etG0g55jT7GNw7XPSgpyCCGEEEKIw0UKkYgBXXjhhaWg7ZJLLuHOO+/knB+vPqDXigR0JpaHWTitgmsWTWfOhEMTkB7ufVZSkEMIIYQQQow0kmk7AHfffTdf//rXaWxs5Oijj+bOO+/kjDPOGNRzR1KmzfM83vve93LllVdyySWXlI5/5/F/8c1Hukpff+xNATa2l7O9I09DWYAzj6xlS2eOVM5hRm2U6liIGdVREuGABDhCCCGEEEIM0mBjAwna9tNvf/tbrr76au6++25OO+00fvjDH/KTn/yElStXMmXKlAGfP5KCNiGEEEIIIcTwkaBtiJx88snMnz+f73//+6Vjc+fO5W1vext33HHHgM+XoE0IIYQQQggBg48N9MM4p1GvWCyydOlSzj///D7Hzz//fJ599tl+n1MoFOjq6urzTwghhBBCCCEGS4K2/dDa2orrutTV1fU5XldXR1NTU7/PueOOO0gkEqV/kydPPhxTFUIIIYQQQowRErQdgN17lyml9trP7POf/zzJZLL0b+vWrYdjikIIIYQQQogxQkr+74fq6moMw9gjq9bS0rJH9q1HMBgkGAwejukJIYQQQgghxiDJtO2HQCDAggULWLx4cZ/jixcv5tRTTx2mWQkhhBBCCCHGMsm07adPfvKTXH311SxcuJBFixbxox/9iC1btnDdddcN99SEEEIIIYQQY5AEbfvp3e9+N21tbdx22200NjYyb948/vrXvzJ16tThnpoQQgghhBBiDJI+bYeZ9GkTQgghhBBCgPRpE0IIIYQQQogxQYI2IYQQQgghhBjBJGgTQgghhBBCiBFMgjYhhBBCCCGEGMEkaBNCCCGEEEKIEUyCNiGEEEIIIYQYwSRoE0IIIYQQQogRTII2IYQQQgghhBjBJGgTQgghhBBCiBHMHO4JjDdKKcDvfi6EEEIIIYQYv3pigp4YYW8kaDvMUqkUAJMnTx7mmQghhBBCCCFGglQqRSKR2OvjmhoorBOHlOd57Nixg3g8jqZpQ/5+XV1dTJ48ma1bt1JWVjbk7yeGlpzPsUPO5dgi53PskHM5tsj5HFvG4vlUSpFKpWhoaEDX975zTTJth5mu60yaNOmwv29ZWdmY+eEWcj7HEjmXY4ucz7FDzuXYIudzbBlr53NfGbYeUohECCGEEEIIIUYwCdqEEEIIIYQQYgSToG2MCwaD3HrrrQSDweGeijgE5HyOHXIuxxY5n2OHnMuxRc7n2DKez6cUIhFCCCGEEEKIEUwybUIIIYQQQggxgknQJoQQQgghhBAjmARtQgghhBBCCDGCSdAmhBBCCCGEECOYBG1j3N1338306dMJhUIsWLCAf/3rX8M9pXHljjvu4MQTTyQej1NbW8vb3vY21qxZ02eMUoovf/nLNDQ0EA6HOeuss1ixYkWfMYVCgRtuuIHq6mqi0SiXXXYZ27Zt6zOmo6ODq6++mkQiQSKR4Oqrr6azs7PPmC1btnDppZcSjUaprq7mxhtvpFgsDsn3PtbdcccdaJrGzTffXDom53J02b59O+9973upqqoiEolw/PHHs3Tp0tLjcj5HB8dx+OIXv8j06dMJh8PMmDGD2267Dc/zSmPkXI5cTz31FJdeeikNDQ1omsaf/vSnPo+PtHP3+uuvc+aZZxIOh5k4cSK33XYbUtPPt69zads2n/3sZznmmGOIRqM0NDTwvve9jx07dvR5DTmX+6DEmHXfffcpy7LUj3/8Y7Vy5Up10003qWg0qjZv3jzcUxs3LrjgAnXvvfeq5cuXq2XLlqmLL75YTZkyRaXT6dKYr33tayoej6v7779fvf766+rd7363mjBhgurq6iqNue6669TEiRPV4sWL1csvv6zOPvtsddxxxynHcUpjLrzwQjVv3jz17LPPqmeffVbNmzdPXXLJJaXHHcdR8+bNU2effbZ6+eWX1eLFi1VDQ4O6/vrrD8+HMYa88MILatq0aerYY49VN910U+m4nMvRo729XU2dOlVde+216vnnn1cbN25Ujz76qFq/fn1pjJzP0eH2229XVVVV6qGHHlIbN25Uv//971UsFlN33nlnaYycy5Hrr3/9q/rCF76g7r//fgWoP/7xj30eH0nnLplMqrq6OvWe97xHvf766+r+++9X8XhcfeMb3xi6D2gU2de57OzsVOeee6767W9/q1avXq2WLFmiTj75ZLVgwYI+ryHncu8kaBvDTjrpJHXdddf1OTZnzhz1uc99bphmJFpaWhSgnnzySaWUUp7nqfr6evW1r32tNCafz6tEIqF+8IMfKKX8P3SWZan77ruvNGb79u1K13X197//XSml1MqVKxWgnnvuudKYJUuWKECtXr1aKeX/MdV1XW3fvr005je/+Y0KBoMqmUwO3Tc9xqRSKTV79my1ePFideaZZ5aCNjmXo8tnP/tZdfrpp+/1cTmfo8fFF1+sPvCBD/Q59o53vEO9973vVUrJuRxNdr/QH2nn7u6771aJRELl8/nSmDvuuEM1NDQoz/MO4Scx+vUXgO/uhRdeUEApmSDnct9keeQYVSwWWbp0Keeff36f4+effz7PPvvsMM1KJJNJACorKwHYuHEjTU1Nfc5TMBjkzDPPLJ2npUuXYtt2nzENDQ3MmzevNGbJkiUkEglOPvnk0phTTjmFRCLRZ8y8efNoaGgojbngggsoFAp9loSJffv4xz/OxRdfzLnnntvnuJzL0eXBBx9k4cKFvPOd76S2tpYTTjiBH//4x6XH5XyOHqeffjqPPfYYa9euBeDVV1/l6aef5qKLLgLkXI5mI+3cLVmyhDPPPLNPY+cLLriAHTt2sGnTpkP/AYxxyWQSTdMoLy8H5FwORIK2Maq1tRXXdamrq+tzvK6ujqampmGa1fimlOKTn/wkp59+OvPmzQMonYt9naempiYCgQAVFRX7HFNbW7vHe9bW1vYZs/v7VFRUEAgE5GdikO677z5efvll7rjjjj0ek3M5umzYsIHvf//7zJ49m3/84x9cd9113HjjjfziF78A5HyOJp/97Ge54oormDNnDpZlccIJJ3DzzTdzxRVXAHIuR7ORdu76G9PztZzf/ZPP5/nc5z7HlVdeSVlZGSDnciDmcE9ADC1N0/p8rZTa45g4PK6//npee+01nn766T0eO5DztPuY/sYfyBjRv61bt3LTTTfxyCOPEAqF9jpOzuXo4HkeCxcu5Ktf/SoAJ5xwAitWrOD73/8+73vf+0rj5HyOfL/97W/55S9/ya9//WuOPvpoli1bxs0330xDQwPXXHNNaZycy9FrJJ27/uayt+eK/tm2zXve8x48z+Puu+8ecLycS59k2sao6upqDMPY425BS0vLHncWxNC74YYbePDBB3niiSeYNGlS6Xh9fT2w512d3uepvr6eYrFIR0fHPsc0Nzfv8b47d+7sM2b39+no6MC2bfmZGISlS5fS0tLCggULME0T0zR58skn+c53voNpmnu9QyfncmSaMGECRx11VJ9jc+fOZcuWLYD8bo4mn/nMZ/jc5z7He97zHo455hiuvvpqPvGJT5Qy4nIuR6+Rdu76G9PS0gLsmQ0U/bNtm3e9611s3LiRxYsXl7JsIOdyIBK0jVGBQIAFCxawePHiPscXL17MqaeeOkyzGn+UUlx//fU88MADPP7440yfPr3P49OnT6e+vr7PeSoWizz55JOl87RgwQIsy+ozprGxkeXLl5fGLFq0iGQyyQsvvFAa8/zzz5NMJvuMWb58OY2NjaUxjzzyCMFgkAULFhz6b36MOeecc3j99ddZtmxZ6d/ChQu56qqrWLZsGTNmzJBzOYqcdtppe7TfWLt2LVOnTgXkd3M0yWaz6HrfyxnDMEol/+Vcjl4j7dwtWrSIp556qk/p+EceeYSGhgamTZt26D+AMaYnYFu3bh2PPvooVVVVfR6XczmAw1PvRAyHnpL/P/3pT9XKlSvVzTffrKLRqNq0adNwT23c+OhHP6oSiYT65z//qRobG0v/stlsaczXvvY1lUgk1AMPPKBef/11dcUVV/RbznjSpEnq0UcfVS+//LJ685vf3G8J3GOPPVYtWbJELVmyRB1zzDH9lsA955xz1Msvv6weffRRNWnSJClFfRB6V49USs7laPLCCy8o0zTVf/3Xf6l169apX/3qVyoSiahf/vKXpTFyPkeHa665Rk2cOLFU8v+BBx5Q1dXV6pZbbimNkXM5cqVSKfXKK6+oV155RQHqm9/8pnrllVdKFQVH0rnr7OxUdXV16oorrlCvv/66euCBB1RZWdmILhN/OO3rXNq2rS677DI1adIktWzZsj7XRIVCofQaci73ToK2Me6uu+5SU6dOVYFAQM2fP79Ual4cHkC//+69997SGM/z1K233qrq6+tVMBhUb3rTm9Trr7/e53VyuZy6/vrrVWVlpQqHw+qSSy5RW7Zs6TOmra1NXXXVVSoej6t4PK6uuuoq1dHR0WfM5s2b1cUXX6zC4bCqrKxU119/fZ9yt2L/7B60ybkcXf7yl7+oefPmqWAwqObMmaN+9KMf9Xlczufo0NXVpW666SY1ZcoUFQqF1IwZM9QXvvCFPheCci5HrieeeKLf/05ec801SqmRd+5ee+01dcYZZ6hgMKjq6+vVl7/85RFbIv5w29e53Lhx416viZ544onSa8i53DtNqZHc+lsIIYQQQgghxjfZ0yaEEEIIIYQQI5gEbUIIIYQQQggxgknQJoQQQgghhBAjmARtQgghhBBCCDGCSdAmhBBCCCGEECOYBG1CCCGEEEIIMYJJ0CaEEEIIIYQQI5gEbUIIIYQQQggxgknQJoQQYtzSNI0//elPh/x1zzrrLG6++eZD/rq7u/rqq/nqV7865O/T27Rp07jzzjsP6jW+/OUvc/zxx5e+/vSnP82NN954cBMTQogxTII2IYQQQ+7ZZ5/FMAwuvPDC/X7uoQgSDtS1116LpmlomoZlWcyYMYNPf/rTZDKZfT7vgQce4D//8z+HdG6vvfYaDz/8MDfccEPp2IYNG7jiiitoaGggFAoxadIk3vrWt7J27dohncvBuuWWW7j33nvZuHHjcE9FCCFGJAnahBBCDLl77rmHG264gaeffpotW7YM93T2y4UXXkhjYyMbNmzg9ttv5+677+bTn/50v2Nt2wagsrKSeDw+pPP63ve+xzvf+c7S+xSLRc477zy6urp44IEHWLNmDb/97W+ZN28eyWRySOdysGprazn//PP5wQ9+MNxTEUKIEUmCNiGEEEMqk8nwu9/9jo9+9KNccskl/OxnP9tjzIMPPsjChQsJhUJUV1fzjne8A/CXGW7evJlPfOITpYwX7Lm8DuDOO+9k2rRppa9ffPFFzjvvPKqrq0kkEpx55pm8/PLL+z3/YDBIfX09kydP5sorr+Sqq64qLansmcc999zDjBkzCAaDKKX2WB5ZKBS45ZZbmDx5MsFgkNmzZ/PTn/609PjKlSu56KKLiMVi1NXVcfXVV9Pa2rrXOXmex+9//3suu+yyPq+xYcMG7r77bk455RSmTp3Kaaedxn/9139x4oknlsZt27aN97znPVRWVhKNRlm4cCHPP/88AG+88QZvfetbqaurIxaLceKJJ/Loo4/u8/NJJpN8+MMfpra2lrKyMt785jfz6quv9hnzta99jbq6OuLxOB/84AfJ5/N7vM5ll13Gb37zm32+lxBCjFcStAkhhBhSv/3tbznyyCM58sgjee9738u9996LUqr0+MMPP8w73vEOLr74Yl555RUee+wxFi5cCPjLDCdNmsRtt91GY2MjjY2Ng37fVCrFNddcw7/+9S+ee+45Zs+ezUUXXUQqlTqo7yccDpcyagDr16/nd7/7Hffffz/Lli3r9znve9/7uO+++/jOd77DqlWr+MEPfkAsFgOgsbGRM888k+OPP56XXnqJv//97zQ3N/Oud71rr3N47bXX6OzsLH1OADU1Nei6zh/+8Adc1+33eel0mjPPPJMdO3bw4IMP8uqrr3LLLbfgeV7p8YsuuohHH32UV155hQsuuIBLL710r9lRpRQXX3wxTU1N/PWvf2Xp0qXMnz+fc845h/b2dgB+97vfceutt/Jf//VfvPTSS0yYMIG77757j9c66aST2Lp1K5s3b97r9y2EEOOWEkIIIYbQqaeequ68806llFK2bavq6mq1ePHi0uOLFi1SV1111V6fP3XqVPWtb32rz7Fbb71VHXfccX2Ofetb31JTp07d6+s4jqPi8bj6y1/+UjoGqD/+8Y97fc4111yj3vrWt5a+fv7551VVVZV617veVZqHZVmqpaWlz/POPPNMddNNNymllFqzZo0C+nzPvf2///f/1Pnnn9/n2NatWxWg1qxZ0+9z/vjHPyrDMJTneX2Of+9731ORSETF43F19tlnq9tuu0298cYbpcd/+MMfqng8rtra2vb6Pe/uqKOOUt/97ndLX/c+H4899pgqKytT+Xy+z3NmzpypfvjDHyql/PN73XXX9Xn85JNP3uP8JZNJBah//vOfg56bEEKMF5JpE0IIMWTWrFnDCy+8wHve8x4ATNPk3e9+N/fcc09pzLJlyzjnnHMO+Xu3tLRw3XXXccQRR5BIJEgkEqTT6f3eU/fQQw8Ri8UIhUIsWrSIN73pTXz3u98tPT516lRqamr2+vxly5ZhGAZnnnlmv48vXbqUJ554glgsVvo3Z84cwF+u2J9cLkcwGCwtF+3x8Y9/nKamJn75y1+yaNEifv/733P00UezePHi0lxOOOEEKisr+33dTCbDLbfcwlFHHUV5eTmxWIzVq1fv9TNbunQp6XSaqqqqPvPfuHFjae6rVq1i0aJFfZ63+9fgZzABstlsv+8lhBDjmTncExBCCDF2/fSnP8VxHCZOnFg6ppTCsiw6OjqoqKgoXazvD13X+yyxBPosWQS/8uPOnTu58847mTp1KsFgkEWLFlEsFvfrvc4++2y+//3vY1kWDQ0NWJbV5/FoNLrP5w/0/Xmex6WXXsp///d/7/HYhAkT+n1OdXU12WyWYrFIIBDo81g8Hueyyy7jsssu4/bbb+eCCy7g9ttv57zzzhtwLp/5zGf4xz/+wTe+8Q1mzZpFOBzm8ssv3+tn5nkeEyZM4J///Ocej5WXl+/zvXbXs5xyXwGwEEKMV5JpE0IIMSQcx+EXv/gF//u//8uyZctK/1599VWmTp3Kr371KwCOPfZYHnvssb2+TiAQ2GOPVk1NDU1NTX0Ct933k/3rX//ixhtv5KKLLuLoo48mGAzus7jH3kSjUWbNmsXUqVP3CNgG45hjjsHzPJ588sl+H58/fz4rVqxg2rRpzJo1q8+/vQWEPUVYVq5cuc/31jSNOXPmlFoUHHvssSxbtqwUIO3uX//6F9deey1vf/vbOeaYY6ivr2fTpk17ff358+fT1NSEaZp7zL26uhqAuXPn8txzz/V53u5fAyxfvhzLsjj66KP3+T0JIcR4JEGbEEKIIfHQQw/R0dHBBz/4QebNm9fn3+WXX16qnnjrrbfym9/8hltvvZVVq1bx+uuv8z//8z+l15k2bRpPPfUU27dvLwVdZ511Fjt37uR//ud/eOONN7jrrrv429/+1uf9Z82axf/93/+xatUqnn/+ea666qoDyuodrGnTpnHNNdfwgQ98gD/96U9s3LiRf/7zn/zud78D/CWN7e3tXHHFFbzwwgts2LCBRx55hA984AN7LShSU1PD/Pnzefrpp0vHli1bxlvf+lb+8Ic/sHLlStavX89Pf/pT7rnnHt761rcCcMUVV1BfX8/b3vY2nnnmGTZs2MD999/PkiVLAP8ze+CBB0rB9ZVXXlkqUtKfc889l0WLFvG2t72Nf/zjH2zatIlnn32WL37xi7z00ksA3HTTTdxzzz3cc889rF27lltvvZUVK1bs8Vr/+te/OOOMM4blHAkhxEgnQZsQQogh8dOf/pRzzz2XRCKxx2P/9m//xrJly3j55Zc566yz+P3vf8+DDz7I8ccfz5vf/OZSCXqA2267jU2bNjFz5szS0rm5c+dy9913c9ddd3Hcccfxwgsv7NE77Z577qGjo4MTTjiBq6++mhtvvJHa2tqh/ab34vvf/z6XX345H/vYx5gzZw4f+tCHStmvhoYGnnnmGVzX5YILLmDevHncdNNNJBIJdH3v/5n+8Ic/XMpWAkyaNIlp06bxla98hZNPPpn58+fz7W9/m6985St84QtfAPys5SOPPEJtbS0XXXQRxxxzDF/72tcwDAOAb33rW1RUVHDqqady6aWXcsEFFzB//vy9zkHTNP7617/ypje9iQ984AMcccQRvOc972HTpk3U1dUB8O53v5svfelLfPazn2XBggVs3ryZj370o3u81m9+8xs+9KEP7f+HK4QQ44Cmdt8UIIQQQogRL5/Pc+SRR3Lffff1W9hjNHn44Yf5zGc+w2uvvYZpynZ7IYTYnWTahBBCiFEoFArxi1/84oD26Y00mUyGe++9VwI2IYTYC8m0CSGEEEIIIcQIJpk2IYQQQgghhBjBJGgTQgghhBBCiBFMgjYhhBBCCCGEGMEkaBNCCCGEEEKIEUyCNiGEEEIIIYQYwSRoE0IIIYQQQogRTII2IYQQQgghhBjBJGgTQgghhBBCiBFMgjYhhBBCCCGEGMH+P1451WihlU0OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot actual vs predicted prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Price (Scaled)')\n",
    "plt.ylabel('Predicted Price (Scaled)')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of predicted vs. actual prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([-2, 1], [-2, 1], color='red', linestyle='--')  # Plot diagonal line for reference\n",
    "plt.title('Predicted vs. Actual Prices')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Plot horizontal line at y=0\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Used Beyond Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning:\n",
    "\n",
    "a. We'll perform grid search to search the hyperparameter space efficiently.\n",
    "\n",
    "b. Define a grid or parameter space to search over, including parameters like learning_rate, num_leaves, max_depth, min_child_samples, subsample, colsample_bytree, etc.\n",
    "\n",
    "c. Use cross-validation to evaluate each set of hyperparameters and select the combination that minimizes RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM regressor\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', metric='rmse', n_estimators=1000)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=lgb_reg, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best RMSE score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best RMSE:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Learning:\n",
    "\n",
    "a. We'll train multiple LightGBM models with different hyperparameters or random seeds.\n",
    "\n",
    "b. Combine predictions from multiple models using techniques like averaging or weighted averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Define different LightGBM models with different hyperparameters\n",
    "model_1 = lgb.LGBMRegressor(learning_rate=0.05, num_leaves=50, max_depth=5)\n",
    "model_2 = lgb.LGBMRegressor(learning_rate=0.1, num_leaves=100, max_depth=7)\n",
    "model_3 = lgb.LGBMRegressor(learning_rate=0.01, num_leaves=31, max_depth=3)\n",
    "\n",
    "# Train each model\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# Combine predictions from all models using averaging\n",
    "y_pred_ensemble = (model_1.predict(X_test) + model_2.predict(X_test) + model_3.predict(X_test)) / 3\n",
    "ensemble_rmse = mean_squared_error(y_test, y_pred_ensemble, squared=False)\n",
    "\n",
    "print(\"Ensemble RMSE:\", ensemble_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation:\n",
    "\n",
    "a. We'll perform k-fold cross-validation to estimate the model's performance more accurately.\n",
    "\n",
    "b. Split the data into k folds, train the model on k-1 folds, and validate on the remaining fold.\n",
    "\n",
    "c. Average the RMSE across all folds to get a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize LightGBM regressor\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', metric='rmse', n_estimators=1000)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(lgb_reg, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "avg_rmse = -cv_scores.mean()\n",
    "\n",
    "print(\"Average RMSE (Cross-Validation):\", avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 230086, number of used features: 1152\n",
      "[LightGBM] [Info] Start training from score -0.001135\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2536\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1139\n",
      "[LightGBM] [Info] Start training from score -0.001032\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2546\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1144\n",
      "[LightGBM] [Info] Start training from score -0.000421\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2544\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1143\n",
      "[LightGBM] [Info] Start training from score -0.000769\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2564\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1153\n",
      "[LightGBM] [Info] Start training from score -0.001172\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score -0.000409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2554\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1148\n",
      "[LightGBM] [Info] Start training from score -0.000573\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2552\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1147\n",
      "[LightGBM] [Info] Start training from score -0.001505\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1152\n",
      "[LightGBM] [Info] Start training from score -0.001203\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2570\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1156\n",
      "[LightGBM] [Info] Start training from score -0.000482\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2564\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1153\n",
      "[LightGBM] [Info] Start training from score -0.001455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2560\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1151\n",
      "[LightGBM] [Info] Start training from score -0.000844\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2546\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1144\n",
      "[LightGBM] [Info] Start training from score -0.001157\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2560\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1151\n",
      "[LightGBM] [Info] Start training from score -0.000524\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2556\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1149\n",
      "[LightGBM] [Info] Start training from score -0.001458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2560\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1151\n",
      "[LightGBM] [Info] Start training from score -0.000701\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2558\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1150\n",
      "[LightGBM] [Info] Start training from score -0.001479\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2554\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1148\n",
      "[LightGBM] [Info] Start training from score -0.001604\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2558\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1150\n",
      "[LightGBM] [Info] Start training from score -0.001059\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1152\n",
      "[LightGBM] [Info] Start training from score -0.000895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2548\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1145\n",
      "[LightGBM] [Info] Start training from score -0.001228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2544\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1143\n",
      "[LightGBM] [Info] Start training from score -0.001216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2562\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1152\n",
      "[LightGBM] [Info] Start training from score -0.000863\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2554\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1148\n",
      "[LightGBM] [Info] Start training from score -0.001191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2556\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1149\n",
      "[LightGBM] [Info] Start training from score -0.001577\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2534\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1138\n",
      "[LightGBM] [Info] Start training from score -0.001028\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2558\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1150\n",
      "[LightGBM] [Info] Start training from score -0.000647\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2546\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1144\n",
      "[LightGBM] [Info] Start training from score -0.000760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2554\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1148\n",
      "[LightGBM] [Info] Start training from score -0.000994\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2568\n",
      "[LightGBM] [Info] Number of data points in the train set: 230087, number of used features: 1155\n",
      "[LightGBM] [Info] Start training from score -0.000675\n",
      "Cross-Validation RMSE: 0.3147 +/- 0.0035\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 30\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize an array to store cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data_fold = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "    val_data_fold = lgb.Dataset(X_val_fold, label=y_val_fold)\n",
    "    \n",
    "    # Train the model\n",
    "    bst_fold = lgb.train(params, train_data_fold, num_boost_round=num_round, valid_sets=[val_data_fold])\n",
    "    \n",
    "    # Predict on the validation set and calculate RMSE\n",
    "    y_pred_val = bst_fold.predict(X_val_fold, num_iteration=bst_fold.best_iteration)\n",
    "    rmse_fold = np.sqrt(mean_squared_error(y_val_fold, y_pred_val))\n",
    "    \n",
    "    # Store the RMSE score\n",
    "    cv_scores.append(rmse_fold)\n",
    "\n",
    "# Convert scores to numpy array\n",
    "cv_scores = np.array(cv_scores)\n",
    "\n",
    "# Calculate mean and standard deviation of cross-validation scores\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "print(\"Cross-Validation RMSE: {:.4f} +/- {:.4f}\".format(cv_mean, cv_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation RMSE (Mean)\n",
    "The average RMSE value across all folds of the cross-validation process. In this case, it indicates the average difference between the actual flight prices and the predicted prices made by the model. A lower RMSE value indicates better performance, as it means the model's predictions are closer to the actual prices on average.\n",
    "\n",
    "##### Standard Deviation of Cross-Validation RMSE\n",
    "The variability or spread of RMSE values across different folds of the cross-validation. A smaller standard deviation indicates that the RMSE values from different folds are closer to the mean, suggesting that the model's performance is consistent across different subsets of the data. In contrast, a larger standard deviation may indicate that the model's performance varies significantly depending on the subset of data used for training and validation.\n",
    "\n",
    "Overall, a cross-validation RMSE of 0.3132 with a standard deviation of 0.0012 suggests that the model has good predictive performance and is consistent across different subsets of the data. However, it's essential to consider other factors such as the specific requirements of your application and whether the RMSE value meets your desired level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-choosing row-wise multi-threading: LightGBM automatically chooses row-wise multi-threading to optimize performance. It mentions the overhead time spent on testing, which is negligible (0.002944 seconds). It suggests setting force_row_wise=true to remove this overhead if needed.\n",
    "\n",
    "Total Bins: LightGBM indicates the total number of bins created for splitting features. Binning is a technique used to discretize continuous features into smaller intervals, which helps in building the decision trees.\n",
    "\n",
    "Number of data points in the train set and number of used features: LightGBM shows the number of data points (rows) and the number of features (columns) used in the training set.\n",
    "\n",
    "Start training from score: LightGBM starts training from a certain initial score, which is typically the mean or median of the target variable.\n",
    "\n",
    "Root Mean Squared Error: Finally, LightGBM prints the Root Mean Squared Error (RMSE) calculated on the test set. This is the evaluation metric used to measure the performance of the trained model. In this case, the RMSE is approximately 0.31698. Lower values of RMSE indicate better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"C:/Users/Redmi/Desktop/IS460-G1-Machine Learning & Applications/IS460-main/IS460-main/data/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297527 entries, 0 to 297526\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Unnamed: 0            297527 non-null  int64  \n",
      " 1   airline               297527 non-null  object \n",
      " 2   flight                297527 non-null  object \n",
      " 3   source_city           297527 non-null  object \n",
      " 4   departure_time        297527 non-null  object \n",
      " 5   stops                 297527 non-null  object \n",
      " 6   arrival_time          297527 non-null  object \n",
      " 7   destination_city      297527 non-null  object \n",
      " 8   class                 297527 non-null  object \n",
      " 9   days_left_binned      297527 non-null  int64  \n",
      " 10  duration_sqrt_scaled  297527 non-null  float64\n",
      " 11  price_boxcox_scaled   297527 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 27.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>days_left_binned</th>\n",
       "      <th>duration_sqrt_scaled</th>\n",
       "      <th>price_boxcox_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.498010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.735912</td>\n",
       "      <td>-0.497464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.710632</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.685797</td>\n",
       "      <td>-0.497646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   airline   flight source_city departure_time stops  \\\n",
       "0           0  SpiceJet  SG-8709       Delhi        Evening  zero   \n",
       "1           1  SpiceJet  SG-8157       Delhi  Early_Morning  zero   \n",
       "2           2   AirAsia   I5-764       Delhi  Early_Morning  zero   \n",
       "3           3   Vistara   UK-995       Delhi        Morning  zero   \n",
       "4           4   Vistara   UK-963       Delhi        Morning  zero   \n",
       "\n",
       "    arrival_time destination_city    class  days_left_binned  \\\n",
       "0          Night           Mumbai  Economy                 0   \n",
       "1        Morning           Mumbai  Economy                 0   \n",
       "2  Early_Morning           Mumbai  Economy                 0   \n",
       "3      Afternoon           Mumbai  Economy                 0   \n",
       "4        Morning           Mumbai  Economy                 0   \n",
       "\n",
       "   duration_sqrt_scaled  price_boxcox_scaled  \n",
       "0             -1.735912            -0.498010  \n",
       "1             -1.685797            -0.498010  \n",
       "2             -1.735912            -0.497464  \n",
       "3             -1.710632            -0.497646  \n",
       "4             -1.685797            -0.497646  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "\n",
    "# Drop Unnamed: 0 index column\n",
    "X = df.drop(['Unnamed: 0', 'class'], axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables if needed\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 164687, number of negative: 73334\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2847\n",
      "[LightGBM] [Info] Number of data points in the train set: 238021, number of used features: 1168\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.691901 -> initscore=0.809022\n",
      "[LightGBM] [Info] Start training from score 0.809022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the LightGBM classifier\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997647296070984\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       1.00      1.00      1.00     18186\n",
      "     Economy       1.00      1.00      1.00     41320\n",
      "\n",
      "    accuracy                           1.00     59506\n",
      "   macro avg       1.00      1.00      1.00     59506\n",
      "weighted avg       1.00      1.00      1.00     59506\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18185     1]\n",
      " [   13 41307]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       1.00      1.00      1.00     18186\n",
      "     Economy       1.00      1.00      1.00     41320\n",
      "\n",
      "    accuracy                           1.00     59506\n",
      "   macro avg       1.00      1.00      1.00     59506\n",
      "weighted avg       1.00      1.00      1.00     59506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\redmi\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/7b/0e/25d6b5678ed3c7e12bc94d047d0e9492e89cc78b7ea0034ac0f1cf2ff304/scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\redmi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\redmi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\redmi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\redmi\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Downloading scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.2/10.6 MB 36.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.7/10.6 MB 42.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 40.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.1/10.6 MB 42.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 39.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 39.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.6 MB 31.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 31.2 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "Successfully installed scikit-learn-1.4.1.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 164687, number of negative: 73334\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2847\n",
      "[LightGBM] [Info] Number of data points in the train set: 238021, number of used features: 1168\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.691901 -> initscore=0.809022\n",
      "[LightGBM] [Info] Start training from score 0.809022\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model with evaluation set\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='logloss')\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100000x80000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(1000, 800))  # Adjust the figure size as needed\n",
    "\n",
    "ax = lgb.plot_importance(model)\n",
    "plt.xticks(fontsize=5)  # Adjust font size as needed\n",
    "plt.yticks(fontsize=5)  # Adjust font size as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\redmi\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install graphviz and restart your session to plot tree.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[280], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpathsep \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:/users/redmi/anaconda3/lib/site-packages\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Replace this with the path to Graphviz on laptop system\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Plot tree\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m lgb\u001b[38;5;241m.\u001b[39mplot_tree(model, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m), show_info\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_gain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\plotting.py:817\u001b[0m, in \u001b[0;36mplot_tree\u001b[1;34m(booster, ax, tree_index, figsize, dpi, show_info, precision, orientation, example_case, **kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m         _check_not_tuple_of_2_elements(figsize, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigsize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    815\u001b[0m     _, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39mfigsize, dpi\u001b[38;5;241m=\u001b[39mdpi)\n\u001b[1;32m--> 817\u001b[0m graph \u001b[38;5;241m=\u001b[39m create_tree_digraph(booster\u001b[38;5;241m=\u001b[39mbooster, tree_index\u001b[38;5;241m=\u001b[39mtree_index,\n\u001b[0;32m    818\u001b[0m                             show_info\u001b[38;5;241m=\u001b[39mshow_info, precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    819\u001b[0m                             orientation\u001b[38;5;241m=\u001b[39morientation, example_case\u001b[38;5;241m=\u001b[39mexample_case, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    821\u001b[0m s \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[0;32m    822\u001b[0m s\u001b[38;5;241m.\u001b[39mwrite(graph\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\plotting.py:721\u001b[0m, in \u001b[0;36mcreate_tree_digraph\u001b[1;34m(booster, tree_index, show_info, precision, orientation, example_case, max_category_values, **kwargs)\u001b[0m\n\u001b[0;32m    713\u001b[0m         example_case \u001b[38;5;241m=\u001b[39m _data_from_pandas(\n\u001b[0;32m    714\u001b[0m             data\u001b[38;5;241m=\u001b[39mexample_case,\n\u001b[0;32m    715\u001b[0m             feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    716\u001b[0m             categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    717\u001b[0m             pandas_categorical\u001b[38;5;241m=\u001b[39mbooster\u001b[38;5;241m.\u001b[39mpandas_categorical\n\u001b[0;32m    718\u001b[0m         )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    719\u001b[0m     example_case \u001b[38;5;241m=\u001b[39m example_case[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _to_graphviz(\n\u001b[0;32m    722\u001b[0m     tree_info\u001b[38;5;241m=\u001b[39mtree_info,\n\u001b[0;32m    723\u001b[0m     show_info\u001b[38;5;241m=\u001b[39mshow_info,\n\u001b[0;32m    724\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m    725\u001b[0m     precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    726\u001b[0m     orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m    727\u001b[0m     constraints\u001b[38;5;241m=\u001b[39mmonotone_constraints,\n\u001b[0;32m    728\u001b[0m     example_case\u001b[38;5;241m=\u001b[39mexample_case,\n\u001b[0;32m    729\u001b[0m     max_category_values\u001b[38;5;241m=\u001b[39mmax_category_values,\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    731\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\plotting.py:469\u001b[0m, in \u001b[0;36m_to_graphviz\u001b[1;34m(tree_info, show_info, feature_names, precision, orientation, constraints, example_case, max_category_values, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Digraph\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must install graphviz and restart your session to plot tree.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\n\u001b[0;32m    472\u001b[0m     root: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    473\u001b[0m     total_count: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    476\u001b[0m     highlight: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m    477\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Recursively add node or edge.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: You must install graphviz and restart your session to plot tree."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x4000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"PATH\"] += os.pathsep + 'c:/users/redmi/anaconda3/lib/site-packages'  \n",
    "# Replace this with the path to Graphviz on laptop system\n",
    "\n",
    "# Plot tree\n",
    "lgb.plot_tree(model, figsize=(30, 40), show_info=['split_gain'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Metric Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lgb\u001b[38;5;241m.\u001b[39mplot_metric(model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "lgb.plot_metric(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
